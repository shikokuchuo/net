[
  {
    "path": "posts/23-mirai-quality-of-life-updates/",
    "title": "mirai - Quality of Life Updates",
    "description": "Ten Small Improvements",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2024-06-25",
    "categories": [
      "R"
    ],
    "contents": "\n\n\n\nThe last couple of quarters have been somwhat of a whirlwind for mirai. Whether that’s been working with Joe Cheng (CTO, Posit and creator of the Shiny framework) to implement the next generation of promises, introducing mirai_map() as an ‘async-native’ map function, or reaching 1.0.0 release and being accepted for full presentations at useR!2024 and Posit::conf. But the flagship features can all wait to be reviewed in depth.\nHere, I want to recap on some of the little things that have changed since around v0.12 released in January of this year. Things that really improve the quality of life for new and loyal mirai users alike. Sometimes it’s these that make the biggest difference, as we strive to take a somewhat thoughtful approach to incoporating new features and requests. I’ve picked 10 items, in no particular order, with the only proviso being that they are small enough not to merit their own blog post.\n1. Minimalism\nThe print method for a mirai has been pared back to one line. There is simply no reason to take up any more screen real estate.\nMore recently, it actually indicates if a mirai has resoved or not. This is possible as the check is so optimised (on the nanosecond scale) that it doesn’t very well make sense not to include it.\n\n\n(m <- mirai({})) # unresolved\n\n< mirai [] >\n\n\n\n(call_mirai(m)) # resolved\n\n< mirai [$data] >\n\n2. Unseen Improvements\nSince the start of the year, the package has been made robust to memory leaks along error paths. We’re confident in making this claim as test coverage is 100% for the package - rounded up (:\nThis was a massive engineering effort over the Christmas break, mostly in the underlying nanonext package, that included delving into the depths of R’s C API for gems like R_UnwindProtect(), and verifying the results using ‘Valgrind’. The entire effort was inspired by this post by Hiroaki Yutani: https://yutani.rbind.io/post/dont-panic-we-can-unwind/\n3. More Signalling\nThose familiar with the operation of mirai know that it adopts a completely event-driven approach, relying on synchronization primitives and events, such as message completion, being signalled from different threads. There are no loops which constantly check for updates. This means we achieve both zero latency and no resource utilization while waiting, which was always a tradeoff between the two using the dated polling approach.\nBut even more signalling?! Well, actually the ability to pass a signal value such as tools::SIGINT to the ‘autoexit’ parameter of daemon(). This is a feature that makes mirai more fit for certain use cases.\ndaemons(8, autoexit = tools::SIGINT)\nThe default behaviour for daemons is that even if the host process ends, daemons finish what they are doing before exiting. This is perfect for tasks such as checkpointing deep learning models where you want such tasks to finish regardless of what happens in the main process, precisely because you know the main process is liable to instability.\nHowever for working on a lengthy linear pipeline performing Bayesian statistics on expensive cloud servers, you would want such processes to end immediately if the main process dies. This is now possible by supplying an appropriate interrupt.\n4. Less surprising by default\nThe ... and .args arguments to mirai() previously kind of fulfilled the same purpose. And .args could awkardly take both a named or unnamed list.\nNow, they have clearly delineated uses. In fact, for simplicity we now encourage only the use of ....\nThis is as using ... won’t give surprises.\nBy design, mirai evaluation occurs in a new clean environment, where .args parameters are put. For those used to working with scripts within the global environment and expecting behaviours to carry over in mirai evaluations, this could cause surprises when supplying functions defined with variables that live in the global environment. As ... parameters are explicitly placed into the global environment of the daemon processes, the expected behaviour then carries over.\nHowever, by enabling .... and .args to do different things, the interface becomes more parsimonious and allows mirai to retain the flexibility and best of both worlds. All while still trying to be a little less surprising by default…\n5. Environment convenience\nThe ... and .args arguments to mirai() now both accept an environment as the first/only argument.\nThis allows conveniently passing all the objects defined in a local environment or a script, without having to list each one individually. A pertinent use case is with Shiny ExtendedTask:\ntask <- shiny::ExtendedTask$new(\n  function(a, b, c, x, y, z) mirai({ a * b * c + x + y - z }, environment())\n)\nAll the variables defined by the anonymous function arguments are passed through to the mirai when it is invoked.\n6. Vectorization\nThe functions unresolved(), call_mirai(), collect_mirai() and stop_mirai() now all accept a list of mirai. This is ostensibly for compatibility with mirai_map(), but extends to any list of mirai objects.\nSo no need for any more statements like:\nlapply(list_of_mirai, .subset2, \"data\")\nThis is now a clean, efficient (and faster):\ncollect_mirai(list_of_mirai)\n7. The mirai [] method\nPreviously, collecting the value of a mirai involved a call to call_mirai(), which waits for the mirai to resolve, but then returns the mirai itself. So to access the data at $data requires:\n\n\nm <- mirai(TRUE)\ncall_mirai(m)$data\n\n[1] TRUE\n\nOf course, we also had to remember to use call_mirai_() if we wanted this operation to be user-interruptible.\nNow we recommend the use of x[] which waits for and returns the value of a mirai x directly.\n\n\nm <- mirai(TRUE)\nm[]\n\n[1] TRUE\n\nThis makes the user interface even more minimal. The function mirai() is all that is required. This method is also user-interruptible to avoid any potential surprises.\n8. The with() method for daemons()\nDesigned for a Shiny runApp() call, the with() method can be used to conveniently run any series of mirai calls with daemons settings which are then automatically torn down when they finish.\nThis can help to more clearly define intent within blocks of code. In the Shiny context, it can be confusing where to put the daemons() call in a Shiny app - at the top level or within the server component etc.\nThe recommended Shiny workflow is to first create a Shiny app object, and then run it like so:\napp <- shinyApp(server, ui, session)\nwith(daemons(8), runApp(app))\n9. Error stack traces\nImplementing a request by Joe Cheng, a ‘miraiError’ now returns the stack trace of the daemon process to aid debugging. It is simply available on the ‘miraiError’ object at $stack.trace.\n\n\nm <- mirai({func1 <- function() func2(); func2 <- function() func3(); func1()})\nm[]\n\n'miraiError' chr Error in func3(): could not find function \"func3\"\n\nm$data$stack.trace\n\n[[1]]\n[1] \"function() func2()\"\n\n[[2]]\n[1] \"func1()\"\n\nThis is elegantly implemented behind the scenes using a combination of R’s calling handler and restart system, direct descendants of R’s Common Lisp heritage.\n10. Retry and resilience\nAgain, aiming for behaviour to be less suprising, the built-in automatic retry mechanism in the underlying ‘NNG’ C library is now turned off by default. Disabling features? Well, sometimes ‘less is more’.\nPreviously, for the non-dispatcher case, the retry behaviour was governed by the argument ‘resilience’ at daemons(), with default TRUE. This unfortunately meant that if a piece of buggy code caused a crash, it would be re-tried and crash all connected daemons. This is now disabled for the non-dispatcher case, with the mirai returning an ‘errorValue’ instead.\nWhen using dispatcher, the behaviour is slightly different as the problematic code would be isolated at a particular daemon instance. This provided much more control over how to handle such errors, with the ability to manually cancel such tasks using saisei(). However a ‘retry’ argument has now been added at dispatcher() with a default of FALSE. This is as a mirai could remain unresolved indefinitely if retries are enabled. This is something that is not always obvious to check for, although possible by inspecting status().\nThis behavioural update will be completed with the imminent release of mirai version 1.1.1, closely co-ordinated with updates to crew by Will Landau, a package that extends mirai and integrates it as the high performance computing backend for targets reproducible workflows.\n And that’s it! A whistle-stop tour of lots of different types of improvement. All designed to ensure that mirai remains best in class for everything it does. If you have any comments or suggestions, please post in the issues or discussions at the package repository: https://github.com/shikokuchuo/mirai/\n\n\n\n",
    "preview": "posts/23-mirai-quality-of-life-updates/mirai-quality-of-life-updates_files/figure-html5/index-1.png",
    "last_modified": "2024-06-25T11:19:20+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/22-moju-kapu-modular-encapsulation/",
    "title": "Moju-kapu（モジュカプ）Modular Encapsulation",
    "description": "A New Software Design Paradigm",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2024-02-21",
    "categories": [
      "R"
    ],
    "contents": "\n\n\n\nIntroduction\nMoju-kapu （モジュカプ） is shorthand for modular encapsulation （モジュラーカプセル化）.\nIt is a software design paradigm which emphasises the inherent balance in building effective stand-alone tools that together form entire integrated systems. It requires modularity such that each piece of software is self-contained, contributing unique functionality in its own right, but at the same time extensible and readily encapsulated by other systems.\nMoju-kapu is about building out core functionality, and recognising the natural limits of a piece of software such that it does not become monolithic, but harks to the Unix philosophy of doing one thing and doing it well. However it extends this idea with providing interfaces for developers as well as end-users, to enable the software to be easily extended in foreseeable ways.\nA layered engineering approach is advocated, where functionality can be filled at any layer, with interfaces to solutions, existing or future, at others. It does not attempt to simplistically define software as modular tools, nor as empty encompassing frameworks.\nExample\n{mirai} 1 is a package implementing asynchronous evaluation for R 2 – fast parallel code execution and distributed computing. It follows the ‘moju-kapu’ paradigm by creating a tight core proposition, with extensions enabled by a complement of external interfaces.\nModular\nThe package has an inherently modular internal design. The adoption of ‘compute profiles’, allows each to keep its own internal state. In the terminology of the package, it allows different ‘daemons’ settings concurrently, where ‘daemons’ are background processes (local or remote) that accept computations.\nThis internal modularity allows it to scale massively, and fits workflows where certain computations need to be sent to specific workers with special resources such as GPUs or accelerators. It also allows segregating different types of usage such that the user interface may function independently of those created by other packages using {mirai} as a backend (see below).\nThis is functionality that is essential to {mirai} and implemented at its core.\nEncapsulation\nThe package has the following explicit external interfaces:\nuser interface - minimalist consisting mainly of two functions - mirai() and daemons().\ndeveloper interface - functions that provide an interface specfically for extension packages.\n‘parallel’ 3 interface - creates ‘cluster’ objects that provide a backend for the ‘parallel’ base R package.\n‘promises’ 4 interface - provides a method that enables ‘mirai’ to be used as ‘promises’.\nThe last two interfaces are not inherent to the functionality of the package itself, hence would not exist if modularity were the sole design goal. However, they provide the necessary interfaces for mirai to be encapsulated by packages that already provide fundamental building blocks in the R ecosystem. Putting in these interfaces enhances these existing packages by making them more performant, or extending their functionality to distributed computing etc.\nIt allows, for example, {shiny} 5 and {plumber} 6, both promises-powered packages, to easily scale and distribute long-running tasks to servers over the network.\nThe developer interface provides safe and easy (read-only) access to mirai internals (the modular compute profiles) for extension packages that provide alternative launchers of ‘daemon’ processes. This has been designed for use by extension packages, and has notably been used by {crew} 7, the new default for high-performance computing in {targets} 8.\n{crew} extends {mirai} to different computing environments such as traditional clusters or the cloud. It also has functionality for auto-scaling daemons according to demand, which is important due to the potential cost of resources in these high-powered environments. This is a key example of functionality being filled at the most appropriate layer - in this case {crew} where it is most applicable, rather than at {mirai} where it would be an under-utilised feature in the majority of contexts.\nConclusion\nBy adopting ‘moju-kapu’ as its overall design ethos, {mirai} serves a much wider section of the R ecosystem, and is inherently more impactful than it would be solely as a modular ‘tool’.\n\nGao (2024), mirai: Minimalist Async Evaluation Framework for R, https://doi.org/10.5281/zenodo.7912722, https://github.com/shikokuchuo/mirai↩︎\nR Core Team (2023), R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/↩︎\nhttps://shikokuchuo.net/mirai/articles/parallel.html↩︎\nhttps://shikokuchuo.net/mirai/articles/promises.html↩︎\nhttps://shikokuchuo.net/mirai/articles/shiny.html↩︎\nhttps://shikokuchuo.net/mirai/articles/plumber.html↩︎\nLandau WM (2023), crew: A Distributed Worker Launcher Framework, https://wlandau.github.io/crew/, https://github.com/wlandau/crew↩︎\nLandau, W. M., (2021), The targets R package: a dynamic Make-like function-oriented pipeline toolkit for reproducibility and high-performance computing. Journal of Open Source Software, 6(57), 2959, https://doi.org/10.21105/joss.02959↩︎\n",
    "preview": "posts/22-moju-kapu-modular-encapsulation/moju-kapu-modular-encapsulation_files/figure-html5/index-1.png",
    "last_modified": "2024-02-22T21:32:53+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 192
  },
  {
    "path": "posts/21-mirai-parallel-clusters/",
    "title": "mirai Parallel Clusters",
    "description": "Making parallel processing work (better) in R",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2024-01-29",
    "categories": [
      "R"
    ],
    "contents": "\nA surprise\nI came to write this post because I was surprised by its findings.\nThe seed for it came from a somewhat obscure source: the Tokyo.R slack channel.\nThis is actually a fairly vibrant R community. In any case, there was a post by an R user suprised to find parallel computation much slower than the sequential alternative - even though he had thousands, tens of thousands of ‘embarassingly parallel’ iterations to compute.\nHe demonstrated this with a simple benchmarking exercise, which showed a variety of parallel map functions from various packages (which shall remain nameless), each slower than the last, and (much) slower than the non-parallel versions.\nThe replies to this post could be anticipated, and mostly aimed to impart some of the received wisdom: namely that you need computations to be sufficiently complex to benefit from parallel processing, due to the extra overhead from sending and coordinating information to and from workers. For simple functions, it is just not worth the effort.\nAnd this is indeed the ‘received wisdom’…\nand I thought about it… and the benchmarking results continued to look really embarassing.\nThe implicit answer was just not particularly satisfying:\n\n‘sometimes it works, you just have to judge when’.\n\nAnd it didn’t really answer the original poster either - for he just attemped to expose the problem by using a simple example, not that his real usage was as simple.\nThe parallel methods just didn’t work. Or rather didn’t ‘just work’TM.\nAnd this is what sparked off The Investigation.\nThe Investigation\nIt didn’t seem right that there should be such a high bar before parallel computations become beneficial in R.\nMy starting point would be mirai, somewhat naturally (as I’m the author). I also knew that mirai would be fast, as it was designed to be minimalist.\nmirai? That’s みらい or Japanese for ‘future’. All you need to know for now is that it’s a package that can create its own special type of parallel clusters.\nI had not done such a benchmarking exercise before as performance itself was not its raison d’être. More than anything else, it was built as a reliable scheduler for distributed computing. It is the engine that powers crew, the high performance computing element of targets, where it is used in industrial-scale reproducible pipelines.\nAnd this is what I found:\nApplying the statistical function rpois() over 10,000 iterations:\n\n\nlibrary(parallel)\nlibrary(mirai)\n\nbase <- parallel::makeCluster(4)\nmirai <- mirai::make_cluster(4)\n\nx <- 1:10000\n\nres <- microbenchmark::microbenchmark(\n  parLapply(base, x, rpois, n = 1),\n  lapply(x, rpois, n = 1),\n  parLapply(mirai, x, rpois, n = 1)\n)\n\nggplot2::autoplot(res) + ggplot2::theme_minimal()\n\n\n\nUsing the ‘mirai’ cluster resulted in faster results than the simple non-parallel lapply(), which was then in turn much faster than the base default parallel cluster.\nFaster!\nI’m only showing the comparison with base R functions. They’re often the most performant after all. The other packages that had featured in the original benchmarking suffer from an even greater overhead than that of base R, so there’s little point showing them above.\nLet’s confirm with an even simpler function…\nApplying the base function sum() over 10,000 iterations:\n\n\nres <- microbenchmark::microbenchmark(\n  parLapply(base, x, sum),\n  lapply(x, sum),\n  parLapply(mirai, x, sum)\n)\n\nggplot2::autoplot(res) + ggplot2::theme_minimal()\n\n\n\nmirai holds its own! Not much faster than sequential, but not slower either.\nBut what if the data being transmitted back and forth is larger, would that make a difference? Well, let’s change up the original rpois() example, but instead of iterating over lamba, have it return increasingly large vectors instead.\nApplying the statistical function rpois() to generate random vectors around length 10,000:\n\n\nx <- 9900:10100\n\nres <- microbenchmark::microbenchmark(\n  parLapplyLB(base, x, rpois, lambda = 1),\n  lapply(x, rpois, lambda = 1),\n  parLapplyLB(mirai, x, rpois, lambda = 1)\n)\n\nggplot2::autoplot(res) + ggplot2::theme_minimal()\n\n\n\nThe advantage is maintained! 1\nSo ultimately, what does this all mean?\nWell, quite significantly, that virtually any place you have ‘embarassingly parallel’ code where you would use lapply() or purrr::map(), you can now confidently replace with a parallel parLapply() using a ‘mirai’ cluster.\nThe answer is no longer ‘sometimes it works, you just have to judge when’, but:\n\n‘yes, it works!’.\n\nWhat is this Magic\nmirai uses the latest NNG (Nanomsg Next Generation) technology, a lightweight messaging library and concurrency framework\n2 - which means that the communications layer is so fast that this no longer creates a bottleneck.\nThe package leverages new connection types such as IPC (inter-process communications), that are not available to base R. As part of R Project Sprint 2023, R Core invited participants to provide alternative commnunications backends for the parallel package, and ‘mirai’ clusters were born as a result.\nA ‘mirai’ cluster is simply another type of ‘parallel’ cluster, and are persistent background processes utilising cores on your own machine, or on other machines across the network (HPCs or even the cloud).\nI’ll leave it here for this post. You’re welcome to give mirai a try, it’s available on CRAN and at https://github.com/shikokuchuo/mirai.\n\nThe load-balanced version parLapplyLB() is used to show that this variant works equally well.↩︎\nThrough the nanonext package, a high-performance R binding.↩︎\n",
    "preview": "posts/21-mirai-parallel-clusters/mirai-parallel-clusters_files/figure-html5/rpois-1.png",
    "last_modified": "2024-01-29T11:54:23+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/20-ncurl-sessions/",
    "title": "nanonext - High Performance Persistent HTTP Sessions",
    "description": "ncurl sessions",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2023-01-26",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nncurl_session()\ntransact()\nTiming\nLinks\n\n\n\n\n\nShikokuchuo\n\nPersistent http(s) sessions is a new feature added in nanonext 0.7.3.\nThis allows for efficient polling by keeping an open connection with the server, transacting as and when needed.\nProvides an ideal, low-latency solution to requesting real time data over a REST API, especially when there are limits in place for the frequency of new connections.\nncurl_session()\nCreate a session (persistent connection):\n\n\nlibrary(nanonext)\nsess <- ncurl_session(\"https://httpbin.org/headers\")\n\n\ntransact()\nTransact over the session (repeatedly if required):\n\n\nres <- transact(sess)\nres\n\n$status\n[1] 200\n\n$headers\nNULL\n\n$raw\n  [1] 7b 0a 20 20 22 68 65 61 64 65 72 73 22 3a 20 7b 0a 20 20 20 20\n [22] 22 48 6f 73 74 22 3a 20 22 68 74 74 70 62 69 6e 2e 6f 72 67 22\n [43] 2c 20 0a 20 20 20 20 22 58 2d 41 6d 7a 6e 2d 54 72 61 63 65 2d\n [64] 49 64 22 3a 20 22 52 6f 6f 74 3d 31 2d 36 33 64 32 64 64 38 63\n [85] 2d 32 61 66 61 34 64 65 33 32 37 34 35 36 62 30 34 30 33 35 34\n[106] 34 63 33 39 22 0a 20 20 7d 0a 7d 0a\n\n$data\n[1] \"{\\n  \\\"headers\\\": {\\n    \\\"Host\\\": \\\"httpbin.org\\\", \\n    \\\"X-Amzn-Trace-Id\\\": \\\"Root=1-63d2dd8c-2afa4de327456b0403544c39\\\"\\n  }\\n}\\n\"\n\nTiming\nAllows much lower latencies in returning results:\n\n\nlibrary(microbenchmark)\n\nmicrobenchmark(transact(sess), ncurl(\"https://httpbin.org/headers\"))\n\nUnit: milliseconds\n                                 expr       min        lq     mean\n                       transact(sess)  78.14837  82.39269 160.0736\n ncurl(\"https://httpbin.org/headers\") 474.78558 488.71817 793.1671\n    median       uq        max neval\n  84.85723 140.6003   784.5898   100\n 498.19017 516.3694 15475.3540   100\n\nLinks\n{nanonext} package website: https://shikokuchuo.net/nanonext/\nOn CRAN: https://cran.r-project.org/package=nanonext\n{nanonext} features in the ‘Web Technologies’ CRAN Task View under ‘Core Tools For HTTP Requests’: https://cran.r-project.org/view=WebTechnologies\nand also in the ‘High Performance Computing’ CRAN Task View:\nhttps://cran.r-project.org/view=HighPerformanceComputing\n\n\n\n",
    "preview": "posts/20-ncurl-sessions/ncurl-sessions_files/figure-html5/index-1.png",
    "last_modified": "2023-01-26T20:10:34+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/19-nanonext-webtools/",
    "title": "nanonext - a web toolkit",
    "description": "async https and secure websocket client and cryptographic hashing",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2022-09-08",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nncurl - a minimalist (async) http(s) client\nstream - websocket client\nsha[224|256|384|512] - cryptographic hash and HMAC algorithms\nmessenger - console-based instant messaging\n\n\n\n\n\nShikokuchuo\n\nThe previous two articles have centered on the main uses which led to the creation of Nanonext - the desire to bridge code written in different languages, as well as the ability to perform actions concurrently.\nThis article aims to highlight the additional features that have been built around the core capabilities in the NNG library that actually make it a very good tool for interacting with the web.\nThis is especially relevant as version 0.5.5 just released to CRAN integrates the ‘mbedtls’ library providing TLS support for secure websites and websocket connections across all platforms.\nThe package has also made it into the ‘Web Technologies’ CRAN Task View under ‘Core Tools For HTTP Requests’: https://cran.r-project.org/view=WebTechnologies\n\n\nlibrary(nanonext)\n\n\nncurl - a minimalist (async) http(s) client\nFor normal use, it takes just the URL.\nIt can follow redirects.\n\n\nncurl(\"https://httpbin.org/headers\")\n\n$status\n[1] 200\n\n$headers\nNULL\n\n$raw\n  [1] 7b 0a 20 20 22 68 65 61 64 65 72 73 22 3a 20 7b 0a 20 20 20 20\n [22] 22 48 6f 73 74 22 3a 20 22 68 74 74 70 62 69 6e 2e 6f 72 67 22\n [43] 2c 20 0a 20 20 20 20 22 58 2d 41 6d 7a 6e 2d 54 72 61 63 65 2d\n [64] 49 64 22 3a 20 22 52 6f 6f 74 3d 31 2d 36 33 64 32 64 65 61 31\n [85] 2d 32 64 66 34 30 61 36 34 30 35 33 33 64 33 34 65 30 34 39 64\n[106] 37 61 30 63 22 0a 20 20 7d 0a 7d 0a\n\n$data\n[1] \"{\\n  \\\"headers\\\": {\\n    \\\"Host\\\": \\\"httpbin.org\\\", \\n    \\\"X-Amzn-Trace-Id\\\": \\\"Root=1-63d2dea1-2df40a640533d34e049d7a0c\\\"\\n  }\\n}\\n\"\n\nWhilst it is designed to be minimalist and easy to use, the real power however lies in its ability to use other methods such as POST or PUT, and the ability of the arguments ‘headers’ and ‘data’ to take arbitrary values that are sent in the HTTP request.\nThis makes it perfect as a client for making REST API calls, and is indeed a rather performant solution.\n\n\nres <- ncurl(\"http://httpbin.org/post\",\n             async = TRUE,\n             convert = FALSE,\n             method = \"POST\",\n             headers = c(`Content-Type` = \"application/json\", Authorization = \"Bearer APIKEY\"),\n             data = '{\"key\": \"value\"}',\n             response = c(\"Date\", \"Server\"))\n\n\nAbove:\n‘async’ is set to TRUE to return an ‘ncurlAio’ object immediately, with the request happening asynchronously. The data will be available once resolved, or if called explicitly (which will wait).\n‘convert’ is set to FALSE so time is not wasted converting the raw data to characters, which is useful when, for example, a JSON parser can directly parse the raw bytes.\n‘response’ is specified to return the requested response headers.\n\n\nres\n\n< ncurlAio >\n - $status for response status code\n - $headers for response headers\n - $raw for raw message\n - $data for message data\n\ncall_aio(res)$status\n\n[1] 200\n\nres$headers\n\n$Date\n[1] \"Thu, 26 Jan 2023 20:12:17 GMT\"\n\n$Server\n[1] \"gunicorn/19.9.0\"\n\nres$raw\n\n  [1] 7b 0a 20 20 22 61 72 67 73 22 3a 20 7b 7d 2c 20 0a 20 20 22 64\n [22] 61 74 61 22 3a 20 22 7b 5c 22 6b 65 79 5c 22 3a 20 5c 22 76 61\n [43] 6c 75 65 5c 22 7d 22 2c 20 0a 20 20 22 66 69 6c 65 73 22 3a 20\n [64] 7b 7d 2c 20 0a 20 20 22 66 6f 72 6d 22 3a 20 7b 7d 2c 20 0a 20\n [85] 20 22 68 65 61 64 65 72 73 22 3a 20 7b 0a 20 20 20 20 22 41 75\n[106] 74 68 6f 72 69 7a 61 74 69 6f 6e 22 3a 20 22 42 65 61 72 65 72\n[127] 20 41 50 49 4b 45 59 22 2c 20 0a 20 20 20 20 22 43 6f 6e 74 65\n[148] 6e 74 2d 4c 65 6e 67 74 68 22 3a 20 22 31 36 22 2c 20 0a 20 20\n[169] 20 20 22 43 6f 6e 74 65 6e 74 2d 54 79 70 65 22 3a 20 22 61 70\n[190] 70 6c 69 63 61 74 69 6f 6e 2f 6a 73 6f 6e 22 2c 20 0a 20 20 20\n[211] 20 22 48 6f 73 74 22 3a 20 22 68 74 74 70 62 69 6e 2e 6f 72 67\n[232] 22 2c 20 0a 20 20 20 20 22 58 2d 41 6d 7a 6e 2d 54 72 61 63 65\n[253] 2d 49 64 22 3a 20 22 52 6f 6f 74 3d 31 2d 36 33 64 32 64 65 61\n[274] 31 2d 35 66 62 35 36 64 66 38 31 61 31 65 30 33 64 32 31 32 61\n[295] 32 35 33 34 64 22 0a 20 20 7d 2c 20 0a 20 20 22 6a 73 6f 6e 22\n[316] 3a 20 7b 0a 20 20 20 20 22 6b 65 79 22 3a 20 22 76 61 6c 75 65\n[337] 22 0a 20 20 7d 2c 20 0a 20 20 22 6f 72 69 67 69 6e 22 3a 20 22\n[358] 31 38 35 2e 32 32 35 2e 34 35 2e 34 39 22 2c 20 0a 20 20 22 75\n[379] 72 6c 22 3a 20 22 68 74 74 70 3a 2f 2f 68 74 74 70 62 69 6e 2e\n[400] 6f 72 67 2f 70 6f 73 74 22 0a 7d 0a\n\nThe function is named ‘ncurl’ after the ubiquitous ‘curl’, but it uses a completely different technology stack, leveraging the ‘NNG’ and ‘MbedTLS’ libraries instead.\nstream - websocket client\nstream() exposes NNG’s low-level byte stream interface for communicating with raw sockets. This may be used for connecting to arbitrary non-NNG endpoints.\nPerhaps its most important use (in connection with the web at least), is for communicating with (secure) websocket servers. The argument textframes = TRUE can be specified where the websocket server uses text rather than binary frames, which is often the case.\n\n\n# official demo API key used below\ns <- stream(dial = \"wss://ws.eodhistoricaldata.com/ws/forex?api_token=OeAFFmMliFG5orCUuwAKQ8l4WWFQ67YX\",\n            textframes = TRUE)\ns\n\n< nanoStream >\n - type: dialer\n - url: wss://ws.eodhistoricaldata.com/ws/forex?api_token=OeAFFmMliFG5orCUuwAKQ8l4WWFQ67YX\n - textframes: TRUE\n\nsend() and recv(), as well as their asynchronous counterparts send_aio() and recv_aio() can be used on Streams in the same way as Sockets.\nThis affords a great deal of flexibility in ingesting, manipulating and processing streaming data.\n\n\ns |> recv(keep.raw = FALSE)\n\n[1] \"{\\\"status_code\\\":200,\\\"message\\\":\\\"Authorized\\\"}\"\n\ns |> send('{\"action\": \"subscribe\", \"symbols\": \"EURUSD\"}')\n\n[1] 0\n\ns |> recv(keep.raw = FALSE)\n\n[1] \"{\\\"s\\\":\\\"EURUSD\\\",\\\"a\\\":1.08901,\\\"b\\\":1.08894,\\\"dc\\\":\\\"-0.2792\\\",\\\"dd\\\":\\\"-0.0030\\\",\\\"ppms\\\":false,\\\"t\\\":1674763938000}\"\n\ns |> recv(keep.raw = FALSE)\n\n[1] \"{\\\"s\\\":\\\"EURUSD\\\",\\\"a\\\":1.08901,\\\"b\\\":1.08899,\\\"dc\\\":\\\"-0.2792\\\",\\\"dd\\\":\\\"-0.0030\\\",\\\"ppms\\\":false,\\\"t\\\":1674763938000}\"\n\nclose(s)\n\n\nsha[224|256|384|512] - cryptographic hash and HMAC algorithms\nAs ‘nanonext’ now links to the ‘mbedtls’ library as well as ‘NNG’, the series of SHA-2 crypographic hash functions have been added to the package: sha224(), sha256(), sha384() and sha512().\nThese call the secure, optimized implementations from the ‘MbedTLS’ library and return a hash as a raw vector. These can be compared directly for authentication. Alternatively, as.character() may be used to return a character string of the hash value.\nTo generate an HMAC (hash-based message authentication code), simply supply the value ‘key’ to use as the secret key. Many REST APIs require the request strings to be signed, and now the ‘nanonext’ package provides a fast and reliable method of generating a SHA-256 HMAC for this purpose.\n\n\nsha256(\"hello world!\")\n\n[1] \"7509e5bda0c762d2bac7f90d758b5b2263fa01ccbc542ab5e3df163be08e6ca9\"\n\nas.character(sha256(\"hello world!\"))\n\n[1] \"7509e5bda0c762d2bac7f90d758b5b2263fa01ccbc542ab5e3df163be08e6ca9\"\n\nsha256(\"hello world!\", key = \"MY_SECRET\")\n\n[1] \"d8f0e2d368ff632682d55e2c1ccd49c15f8a6a3862d8eb68f1906b6ee658890a\"\n\nmessenger - console-based instant messaging\nThere is also messenger() which is not so easy to demonstrate here as it is by nature interactive, but it is in effect a 2-way walkie talkie which can be connected to a TCP/IP or other socket address. This is a rather fun demonstration of how a multi-threaded application can be built using the NNG framework.\nWhilst this function has been around for quite a few versions of ‘nanonext’, the recent addition of authentication based on a pre-shared key makes it a somewhat viable solution rather than just something for fun. We encourage you to give it a try and play around with it.\n\n\n?messenger\n\n\nPackage website: https://shikokuchuo.net/nanonext/\nOn CRAN: https://cran.r-project.org/package=nanonext\n\n\n\n",
    "preview": "posts/19-nanonext-webtools/nanonext-webtools_files/figure-html5/index-1.png",
    "last_modified": "2023-01-26T20:13:38+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/18-reintroducing-mirai/",
    "title": "Re-introducing mirai - a minimalist async evaluation framework for R",
    "description": "Concurrent code execution with maximum flexibility and automatic resolution",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2022-04-18",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\n1. Two Functions -> One\nFunction\n2. Automatic Resolution\n3. Arbitrary expressions\n4. Daemons\nWrap-up\n\n\n\n\n\nShikokuchuo\n {mirai} is a minimalist async evaluation framework for R.\n未来 みらい mirai is Japanese for ‘future’.\nmirai provides\nan extremely simple and lightweight method for concurrent / parallel\ncode execution.\nSince the original ‘introduction’\narticle two months ago, mirai is currently in its fourth\nincarnation, hence the need for a re-introduction. In this time, the\npackage has also featured in RStudio’s Top\n40 New CRAN Packages for February 2022.\nWe outline some of the main visible innovations below, but suffice to\nsay that the backend (especially the code behind the nanonext package)\nhas been very much optimised over the course of this time as well.\n1. Two Functions -> One\nFunction\nOriginally, the package revolved around 2 functions -\neval_mirai() and call_mirai(). Those are still\nthere, and work the same way - however the package has managed to become\neven more minimalist with only one being required now.\nThis one function is simply called mirai().\n(eval_mirai() maps to it as an alias.)\nUsing mirai() returns a ‘mirai’ object immediately.\nA mirai evaluates an arbitrary expression asynchronously, resolving\nautomatically upon completion.\n2. Automatic Resolution\nYes, resolving automatically, hence call_mirai() is no\nlonger needed (although it can still sometimes be useful to call and\nwait for results).\nThe evaluated result of a mirai is stored at $data. If\nthe asynchronous operation has yet to complete then this will return an\n‘unresolved’ logical NA value. That is an actual NA value of type\nlogical classed as ‘unresolved’.\nAs soon as it resolves, then $data will return the\nactual value of the evaluated expression.\nEnter unresolved(), a helper function that can be used\nin control flow statements to allow you to do things before and after\nresolution of a mirai. This means that you never have to actually just\nwait on a mirai.\nThe code output below probably serves as a better demonstration than\na lengthy explanation:\nExample using a while loop:\n\n\nlibrary(mirai)\n\nm <- mirai({is.null(Sys.sleep(n)) && return(TRUE)}, n = 1)\nm$data\n\n\n'unresolved' logi NA\n\nwhile (unresolved(m)) {\n  cat(\"unresolved\\n\")\n  Sys.sleep(1)\n} \n\n\nunresolved\nunresolved\n\nm$data\n\n\n[1] TRUE\n\nEquivalent using a repeat\nloop:\n\n\nm <- mirai({is.null(Sys.sleep(n)) && return(TRUE)}, n = 1)\nm$data\n\n\n'unresolved' logi NA\n\nrepeat {\n  unresolved(m) || break\n  cat(\"unresolved\\n\")\n  Sys.sleep(1)\n} \n\n\nunresolved\nunresolved\n\nm$data\n\n\n[1] TRUE\n\n3. Arbitrary expressions\nYou may have noticed in the above examples that the expression being\nevaluated was wrapped in { }. mirai supports this being an\narbitrarily-long, possibly multi-line expression. Similarly there is no\nlimit to the number of arguments supplied to the call.\nTo supply objects that are already present in the calling\nenvironment, these may simply be passed in as per the below:\n\n\nmat <- matrix(c(1, 2, 3, 4), ncol = 2)\nmat\n\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\nm <- mirai({\n  x <- t(x)\n  as.data.frame(x)\n}, x = mat)\n\ncall_mirai(m)$data\n\n\n  V1 V2\n1  1  2\n2  3  4\n\n4. Daemons\nThe default behaviour is to just spin up background processes as\nrequired. This offers maximum simplicity and ease of use - no need to\nconsider the backend at all.\nFirst of all this is remarkable in itself, in that mirai simply works\non all platforms R can be installed - across Linux, Windows, Mac,\nSolaris etc. and this is down to the cross-platform support built in to\nthe underlying NNG C library that nanonext provides\na binding for.\nSecond, the startup time is relatively tiny as a completely clean\nbackground R process with ‘–vanilla’ settings is started each time.\nHowever for the highest performance applications, there is now the\noption to start up a set number of processes (daemons) upfront, and\nthese will be ready to wait for instructions, achieveing even more\nminimal latency.\nSetting daemons is as simple as:\n\n\ndaemons(8)\n#> [1] 8\n\n\n\n.. and 8 daemons are created.\nWrap-up\nWe presented above 4 key updates for the fourth version of mirai (v0.4.0). We\ninvite you to try it out for yourselves:\n\n\ninstall.packages(\"mirai\")\n\n\n\nAny issues/comments please feed back at Github: https://github.com/shikokuchuo/mirai\nPackage website: https://shikokuchuo.net/mirai/\n\n\n\n",
    "preview": "posts/18-reintroducing-mirai/reintroducing-mirai_files/figure-html5/index-1.png",
    "last_modified": "2022-04-18T11:06:03+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/17-nanonext-concurrency/",
    "title": "nanonext - how it provides a concurrency framework for R",
    "description": "True async with automatic resolution",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2022-03-18",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nAios\nRPC\nmirai\n\n\n\n\n\nShikokuchuo\nThe nanonext package,\nfeatured in RStudio’s Top\n40 New CRAN Packages for January 2022 has been steadily evolving,\nadding significant new features, with the aysnc ‘Aio’ interface now\nconsidered complete since release 0.3.0 hit CRAN earlier in March.\nHence, time to introduce why this is a ‘concurrency framework’ and\nnot ‘just’ messaging.\nnanonext is\na lightweight binding for the NNG (nanomsg next gen) C library, written\nin a combination of R and C with no package dependencies. For the\nexperts who need no further introduction, they may wish to skip straight\nto the pkgdown site which contains a more systematic exposition of the\nfeatures: https://shikokuchuo.net/nanonext/.\nAios\nThese are self-resolving objects containing the results of an async\noperation.\nThe purpose of this section is really to highlight that this is true\nasync - the real thing. No event loops, nor any other similar\nconstraints. This provides the freedom to be much more expressive when\ncoding. Below, we perform actions out of order - receive before we send\n- and it is all totally fine.\n\n\n# loading the package and creating sockets\nlibrary(nanonext)\ns1 <- socket(\"pair\", listen = \"inproc://nano\")\ns2 <- socket(\"pair\", dial = \"inproc://nano\")\n\n# an async receive is requested, but no messages are waiting (yet to be sent)\nmsg <- s2 |> recv_aio()\nmsg\n\n\n< recvAio >\n - $data for message data\n - $raw for raw message\n\nmsg$data\n\n\n'unresolved' logi NA\n\nsend_aio() and recv_aio() functions return\nimmediately with an ‘Aio’ object, but perform their operations async. An\n‘Aio’ object returns an ‘unresolved’ logical NA value whilst its\nasynchronous operation is ongoing. This is an actual NA value, and Shiny\nwill, for example, recognise it as being ‘non-truthy’.\nNext we perform a send, and the ‘Aio’ resolves immediately once we do\nthat. 1\n\n\nres <- s1 |> send_aio(data.frame(a = 1, b = 2))\n\n# now that a message has been sent, the 'recvAio' automatically resolves\nmsg$data\n\n\n  a b\n1 1 2\n\nmsg$raw\n\n\n  [1] 58 0a 00 00 00 03 00 04 01 03 00 03 05 00 00 00 00 05 55 54 46\n [22] 2d 38 00 00 03 13 00 00 00 02 00 00 00 0e 00 00 00 01 3f f0 00\n [43] 00 00 00 00 00 00 00 00 0e 00 00 00 01 40 00 00 00 00 00 00 00\n [64] 00 00 04 02 00 00 00 01 00 04 00 09 00 00 00 05 6e 61 6d 65 73\n [85] 00 00 00 10 00 00 00 02 00 04 00 09 00 00 00 01 61 00 04 00 09\n[106] 00 00 00 01 62 00 00 04 02 00 00 00 01 00 04 00 09 00 00 00 05\n[127] 63 6c 61 73 73 00 00 00 10 00 00 00 01 00 04 00 09 00 00 00 0a\n[148] 64 61 74 61 2e 66 72 61 6d 65 00 00 04 02 00 00 00 01 00 04 00\n[169] 09 00 00 00 09 72 6f 77 2e 6e 61 6d 65 73 00 00 00 0d 00 00 00\n[190] 02 80 00 00 00 ff ff ff ff 00 00 00 fe\n\nSo isn’t this still ‘just’ messaging?\nWell, we can start with introducing a little helper function\nunresolved(). This allows us to perform actions which\ndepend on resolution of the Aio (completion of the async operation),\nboth before and after. This means there is no need to ever wait (block)\nfor an Aio to resolve, as the below demonstrates:\n\n\nmsg <- recv_aio(s2)\n\n# unresolved() queries for resolution itself so no need to use it again within the while loop\nwhile (unresolved(msg)) {\n  # do real stuff here not just the toy actions below\n  cat(\"unresolved\")\n  send_aio(s1, \"resolved\")\n  Sys.sleep(0.1)  \n}\n\n\nunresolved\n\n# resolution of the Aio exits the while loop - now do the stuff which depends on its value\nmsg$data\n\n\n[1] \"resolved\"\n\nAlternatively, an Aio may also be called explicitly by wrapping it in\ncall_aio(). This will wait for completion of the Aio\n(blocking) if it is yet to resolve.\n\n\n# to access the resolved value directly (waiting if required)\ncall_aio(msg)$data\n\n\n[1] \"resolved\"\n\nThe above two methods provide full flexibility for handling async\noperations as desired.\n\n\n\nRPC\nSo we move closer to explaining how this is a ‘concurrency\nframework’. And this involves explaining a little about NNG’s\n‘scalability protocols’ - so-called as they are designed to be\nmasssively scalable.\nThese can be thought of as communications patterns built on top of\nraw bytestream connections. So a socket of a certain type will always\ninteract with another in a prescribed way. No matter the platform, and\nno matter the language binding.\nProbably the most classic pattern for NNG is the req/rep\n(request/reply). This is a guaranteed communications pattern that will\nnot drop messages, retrying under the hood if messages cannot be\ndelivered for whatever reason. This can be utilised to implement\n‘traditional’ RPC (remote prodecure calls), a bastion of\nsystems/distributed computing. 2\nThis is where a requestor (client) sends a message to an executor\n(server), which performs the requested action and sends back a reply.\n{nanonext} provides the convenience functions request() and\nreply() which implements this logic for use between 2 R\nprocesses, where the requestor supplies data to the reply node, to which\nit applies an arbitrary function before sending back the return\nvalue.\nThis can be meaningfully used to perform computationally-expensive\ncalculations or I/O-bound operations such as writing large amounts of\ndata to disk in a separate ‘server’ process running concurrently.\nServer process: reply() will wait for a message and\napply a function, in this case rnorm(), before sending back\nthe result.\n\n\n# This code block is run in a separate R process to knit this document\n\nlibrary(nanonext)\nrep <- socket(\"rep\", listen = \"tcp://127.0.0.1:6546\")\nctxp <- context(rep)\nreply(ctxp, execute = rnorm, send_mode = \"raw\") \n\n\n\nClient process: request() performs an async send and\nreceive request and returns immediately with an Aio object.\n\n\nlibrary(nanonext)\nreq <- socket(\"req\", dial = \"tcp://127.0.0.1:6546\")\nctxq <- context(req)\naio <- request(ctxq, data = 1e8, recv_mode = \"double\", keep.raw = FALSE)\n\n\n\nAt this point, the client can run additional code concurrent with the\nserver processing the request. The Aio will then resolve automatically\nor can be called as required.\n\n\ncall_aio(aio)$data |> str()\n\n\n num [1:100000000] 1.633 -0.204 -0.521 0.19 0.373 ...\n\nAnd this is how nanonext provides\na true concurrency framework. The package provides the necessary tools\nto implement anything from a walkie-talkie to distributed computing\nclusters and everything in between.\nmirai\nA small (tiny) package has also been released to CRAN in February\n2022 that exposes the functionality of executing arbitrary R expressions\nasynchronously for use on a single machine. It is called ‘mirai’, the Japanese\nfor ‘future’. Everything revolves around one single function. It is very\nminimalistic. Designed to be intuitive to use, a short intro can be\nfound here: https://shikokuchuo.net/mirai/.\n\nOr more precisely, the Aio will\nresolve the next time it is queried - but practically this is the same\nthing, as the value cannot be used unless it is queried. This is akin to\n‘Schrödinger’s Cat’ - if we never look into the box, we simply don’t\nknow the state, but as soon as we look, we will get a resolution one way\nor another. Here, if the value is never used, it could remain in a state\nof ‘superposition’ but as soon as it is required (even if we are only\nseeking metadata such as its length rather than the actual value), it\nwill resolve either to an ‘unresolved’ NA or its actual value.↩︎\nAlthough the generic term includes\n‘remote’, obviously everything can also happen on the same machine in\nseparate processes.↩︎\n",
    "preview": "posts/17-nanonext-concurrency/nanonext-concurrency_files/figure-html5/index-1.png",
    "last_modified": "2022-03-18T12:18:39+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/16-introducing-mirai/",
    "title": "Introducing mirai - a minimalist async evaluation framework for R",
    "description": "Concurrency and parallel code execution",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2022-02-18",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nDesign Notes\nUse Cases\nLinks\nUpdate\n\n\n\n\n\nShikokuchuo\n {mirai} is a minimalist async evaluation framework for R,\nreleased this week to CRAN.\n未来 みらい mirai is Japanese for ‘future’.\nIt provides an extremely simple and lightweight method for concurrent\n/ parallel code execution.\nDesign Notes\nWhilst frameworks for parallelisation exist for R, {mirai} is\ndesigned for simplicity.\nThe package provides just 2 functions:\neval_mirai() to evaluate async\ncall_mirai() to call the result\n{mirai} has a tiny pure R code base, relying on a single package -\n{nanonext}. {nanonext} itself is a lightweight wrapper for the NNG C\nlibrary with zero package dependencies.\nBackground R processes are created and evaluation occurs\nindependently. mirai employs nanonext/NNG as a concurrency framework - a\nblazing-fast, lightweight solution for moving data between these\nprocesses seamlessly. Crucially it provides a true cross-platform\nabstraction layer across Linux, Windows, MacOS, the BSDs, Solaris,\nIllumos etc. i.e. everywhere R can go. This means that we can just call\nthe above two functions without worrying about the underlying system\nimplementation.\nThis means there is no need to specify core counts, devise work plans\nand the such beforehand. Also no need to separate writing code that is\nready for parallel execution from how it is ultimately executed. Just\nwrap your expressions in eval_mirai() and run them in\nanother process.\nFor scripts, this provides the ultimate control as you can map\nspecific code to a specific process. For example if you have 8 model\nfits to run, you can send each one to it’s own process. This provides a\nsimpler and more robust solution than leaving it to the system to\ndecide, which also runs the risk of over-optimisation - you may wish to\nrefer to this classic presentation on Python’s GIL (global interpreter\nlock): http://www.dabeaz.com/python/GIL.pdf. R inherits similar\nlimitations being an interpreted language.\nIt can be equally handy for interactive work - if you have specified\na model, are now ready to fit it and know this will take an hour to run,\nsimply eval_mirai() and have it run in the background\nwhilst you continue with your work. When you need the results just\ncall_mirai() for the return value.\nUse Cases\nMinimise execution times by performing long-running tasks\nconcurrently in separate processes.\nEnsure execution flow of the main process is not blocked.\n\n\nlibrary(mirai)\n\n\n\nExample 1:\nCompute-intensive Operations\nMultiple long computes (model fits etc.) would take more time than if\nperformed concurrently on available computing cores.\nUse eval_mirai() to evaluate an expression in a separate\nR process asynchronously.\nAll named objects are passed through to a clean environment\nA ‘mirai’ object is returned immediately.\n\n\nmirai <- eval_mirai(rnorm(n) + m, n = 1e8, m = runif(1))\n\nmirai\n#> < mirai >\n#>  ~ use call_mirai() to resolve\n\n\n\nContinue running code concurrent to the async operation.\n\n\n# do more...\n\n\n\nUse call_mirai() to retrieve the evaluated result when\nrequired.\n\n\ncall_mirai(mirai)\n\nmirai\n#> < mirai >\n#>  - $value for evaluated result\n\nstr(mirai$value)\n#> num [1:100000000] 1.485 -0.804 0.965 -0.128 -0.555 ...\n\n\n\nExample 2: I/O-bound\nOperations\nProcessing high-frequency real-time data, writing results to\nfile/database can be slow and potentially disrupt the execution\nflow.\nCache data in memory and use eval_mirai() to perform\nperiodic write operations in a separate process.\nA ‘mirai’ object is returned immediately.\n\n\nmirai <- eval_mirai(write.csv(x, file = file), x = rnorm(1e8), file = tempfile())\n\n\n\nUse call_mirai() to confirm the operation has\ncompleted.\nThis will wait for the operation to complete if it is still\nongoing\n\n\ncall_mirai(mirai)$value\n#> NULL\n\n\n\nAbove, the return value is called directly. NULL is the expected\nreturn value for write.csv().\nLinks\n{mirai} website: https://shikokuchuo.net/mirai/ {mirai} on CRAN: https://cran.r-project.org/package=mirai\n{nanonext} website: https://shikokuchuo.net/nanonext/ {nanonext} on\nCRAN: https://cran.r-project.org/package=nanonext\nUpdate\nThe following article provides an update: re-introducting\nmirai\n\n\n\n",
    "preview": "posts/16-introducing-mirai/introducing-mirai_files/figure-html5/index-1.png",
    "last_modified": "2022-04-18T10:56:35+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/15-nanonext-exchange/",
    "title": "nanonext for Cross-language Data Exchange",
    "description": "A clean and robust approach to R / Python interoperability",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2022-02-14",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nLinks\n\n\n\n\n\nShikokuchuo\n{nanonext} is an R package available on CRAN which provides bindings to the C library NNG (Nanomsg Next Gen), a successor to ZeroMQ.\nDesigned for performance and reliability, the NNG library is written in C and {nanonext} is a lightweight wrapper depending on no other packages.\nIt provides a fast and reliable data interface between different programming languages where NNG has a binding, including C, C++, Java, Python, Go, Rust etc.\nThe following example demonstrates the exchange of numerical data between R and Python (NumPy), two of the most commonly-used languages for data science and machine learning.\nUsing a messaging interface provides a clean and robust approach that is light on resources and offers limited and identifiable points of failure. This is especially relevant when processing real-time data, as an example.\nThis approach can also serve as an interface / pipe between different processes written in the same or different languages, running on the same computer or distributed across networks, and is an enabler of modular software design as espoused by the Unix philosophy.\nCreate socket in Python using the NNG binding ‘pynng’:\n\nimport numpy as np\nimport pynng\nsocket = pynng.Pair0(listen=\"ipc:///tmp/nanonext\")\n\nCreate nano object in R using {nanonext}, then send a vector of ‘doubles’, specifying mode as ‘raw’:\n\n\nlibrary(nanonext)\nn <- nano(\"pair\", dial = \"ipc:///tmp/nanonext\")\nn$send(c(1.1, 2.2, 3.3, 4.4, 5.5), mode = \"raw\")\n#>  [1] 9a 99 99 99 99 99 f1 3f 9a 99 99 99 99 99 01 40 66 66 66 66 66 66 0a 40 9a\n#> [26] 99 99 99 99 99 11 40 00 00 00 00 00 00 16 40\n\n\n\nReceive in Python as a NumPy array of ‘floats’, and send back to R:\n\nraw = socket.recv()\narray = np.frombuffer(raw)\nprint(array)\n#> [1.1 2.2 3.3 4.4 5.5]\nmsg = array.tobytes()\nsocket.send(msg)\n\nReceive in R, specifying the receive mode as ‘double’:\n\n\nn$recv(mode = \"double\")\n#> $raw\n#>  [1] 9a 99 99 99 99 99 f1 3f 9a 99 99 99 99 99 01 40 66 66 66 66 66 66 0a 40 9a\n#> [26] 99 99 99 99 99 11 40 00 00 00 00 00 00 16 40\n#> \n#> $data\n#> [1] 1.1 2.2 3.3 4.4 5.5\n\n\n\nLinks\nnanonext on CRAN: https://cran.r-project.org/package=nanonext Package website: https://shikokuchuo.net/nanonext/\nNNG website: https://nng.nanomsg.org/ NNG documentation: https://nng.nanomsg.org/man/tip/\n\n\n\n",
    "preview": "posts/15-nanonext-exchange/nanonext-exchange_files/figure-html5/index-1.png",
    "last_modified": "2022-02-15T14:44:45+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/14-r-on-solaris/",
    "title": "Installing an R Build Environment on Solaris",
    "description": "Run R CMD check or devtools::check() on a local Solaris VM",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-08-23",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nSetup\nBonus\nPower off\n\n\n\n\n\nShikokuchuo\nSetup\nThe R-hub solarischeck repository1, provides a full set of instructions by Gábor Csárdi for setting up R on a Solaris system. However, due to the ever-evolving software landscape, the instructions as they stand are no longer likely to produce a working system.\nThis guide builds on and completes the set of instructions so that a full build system can be set up with relative ease, complete with ‘devtools’ installed and ready for package testing on a CRAN-like Solaris environment.\nWhere ‘Instructions’ are mentioned below, they refer to those found at the original solarischeck repository:\nhttps://github.com/r-hub/solarischeck/tree/master/packer.\n[1]\nFollow steps 1-3 of the Instructions, including installing the latest Packer version from its website. The website provides clear guidance on the best installation method - for example, for Ubuntu Linux users, a PPA is provided for a straightforward install process.\n[2]\nFollow step 4 of the Instructions and edit ‘solaris10.json’ to point to the locations of the downloaded Solaris 10 iso and Oracle Developer Studio tar.bz2.\nIn addition, find the following line in ‘solaris10.json’:\n\"iso_checksum_type\": \"sha1\",\nIt appears twice. Delete both of these lines.\n[3]\nOpen up a terminal and cd to where the ‘solaris10.json’ file is located. Execute the following command to create an updated Packer configuration from the json file:\n\npacker hcl2_upgrade solaris10.json\n\nYou should get a confirmation message such as:\nSuccessfully created solaris10.json.pkr.hcl. Exit 0\n[4]\nFollow step 5 of the Instructions and make sure VirtualBox or VMware is installed.\n[5]\nFrom where your solaris10.json is located, execute:\n\npacker build .\n\nThe automated build will now run for a while, with the console showing the commands as they are run.\nAs per step 7 of the Instructions, do not attempt to interact with the VM window. Even if it appears static, processes will be running in the background.\nWait for the build to finish.\n[6]\nComplete the remaining installation steps 8-10 from the Instructions.\nFor those using VirtualBox: you should have a successfully-imported virtual machine at this point. Before launching it, first choose ‘settings’. On the ‘system’ tab feel free to allocate some more base memory (staying within the recommended green band). On the ‘display tab’, similarly allocate some more video memory - this is important otherwise increasing the screen resolution later may fail.\n[7]\nLaunch the virtual machine and log in using the ‘rhub’ account as per the Instructions.\nChoose the Sun Java Desktop Environment (however much you are tempted to use the awesome CDE). Once you arrive at a desktop, right click and set the desired screen resolution. (Here, if not enough video memory was allocated in the previous step you may get a black screen. If you do not get back to a usable dektop, power off the VM and try again.)\n[8]\nOpen a terminal window and install the following packages from openCSW, the Solaris open source software repository, by issuing the following command:\n\nsudo pkgutil -y -i cmake gmake curl libcurl_dev libssh2_dev libssl_dev libxml2_dev libiconv_dev\n\nThese are utilities and system libraries that are required to install the various dependencies of ‘devtools’.\n[19]\n‘libgit2’ is required but not available on openCSW, and hence must be built. In a terminal window, execute the commands in the following instructions by Jeroen Ooms:\nhttps://gist.github.com/jeroen/4f13ff48596b449283ca98af7b95601d\nStart from # Download latest release as we have already installed the dependencies as part of the previous step.\n[10]\nFor the final step, load up a terminal window. Enter the following to set the environment variable:\n\nexport MAKE=gmake\n\nFrom the same terminal window, launch R:\n\nR\n\nAt the R prompt, proceed to install the ‘devtools’ package:\n\n\ninstall.packages(\"devtools\")\n\n\n\nYou will be prompted if you would like to use and create a personal library. Proceed with ‘yes’ both times.\nAll the dependencies of ‘devtools’ will now be downloaded and install will take a while.\nThe installation should complete successfully leaving you with a full R development environment on Solaris.\nBonus\nInstall the last released Firefox build 52.0esr for Solaris - this allows modern websites such as Github to load.\nOpen up a terminal and enter the following:\n\ncd Desktop\n\n# Download file\ncurl -OL https://ftp.mozilla.org/pub/firefox/releases/52.0esr/contrib/solaris_pkgadd/firefox-52.0esr.en-US.solaris-10-fcs-i386-pkg.bz2\n\n# Decompress file\nbzip2 -d firefox-52.0esr.en-US.solaris-10-fcs-i386-pkg.bz2\n\n# Install package\nsudo pkgadd -d ./firefox-52.0esr.en-US.solaris-10-fcs-i386-pkg\n\nRespond ‘yes’ to all install prompts.\nIt does not overwrite the bundled version, so set up a shortcut by right-clicking on the desktop, and select ‘Create Launcher’.\nFor ‘Name’ enter Firefox, for ‘Command’ enter /opt/sfw/lib/firefox/firefox\nDouble-click the new launcher icon on the desktop to bring up Firefox.\nPower off\nTo turn off the VM, open up a terminal window and issue:\n\nsudo poweroff\n\n–\n\nThis article (excluding the photograph) is licensed under CC BY 4.0\n\n\nCopyright, the R Consortium↩︎\n",
    "preview": "posts/14-r-on-solaris/r-on-solaris_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:48:23+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/13-reverting/",
    "title": "Reverting Git Commits",
    "description": "Procedure to roll back both local and remote changes",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-08-12",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nReverting Local Git Commits\nReverting Commits Pushed to Remote (e.g. Github)\n\n\n\n\n\nShikokuchuo\nReverting Local Git Commits\nYou have made a commit.\nYou discover a mistake or something you left out straight after the commit.\n\ngit reset HEAD~\n\nThis is a soft reset. Your changes are preserved. The commit is removed from the record.\nMake the additional changes you need. Add files. Commit.\nReverting Commits Pushed to Remote (e.g. Github)\nCopy your folder to a backup location.\nThe following is a hard reset, which rolls back to the previous commit. Changes since that commit will be lost. Force push it to the remote.\n\ngit reset HEAD^ --hard\ngit push origin -f\n\nBoth local and remote should now be in sync at the previous commit. You may check with:\n\ngit status\n\nIf you have Github Actions that are triggered by commits, they will be triggered again despite this being a roll-back. So go and stop those runs if necessary.\nNext, if you have another branch such as ‘gh-pages’ that builds automatically on each commit, roll back that branch as well so it keeps in sync. As this branch has been building on the remote, do a git pull to ensure that your local copy is up to date first before resetting.\n\ngit checkout gh-pages\ngit pull\n\ngit reset HEAD^ --hard\ngit push -f origin gh-pages\n\nCheck status. Switch back to ‘main’ branch (substitute whatever branch you were on).\n\ngit status\ngit checkout main\n\nCopy back the files with changes you made previously from your backup location.\nMake the additional changes you need. Add files. Commit.\n\n\n\n",
    "preview": "posts/13-reverting/reverting_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:47:16+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/12-oanda-studio/",
    "title": "R Shiny interface for the OANDA fxTrade API",
    "description": "ichimoku::oanda_studio()",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-07-26",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nAbout ichimoku\nAbout the OANDA fxTrade API\nScreenshots\nOther functions\nLinks and further information\n\n\n\n\n\nShikokuchuo\nAbout ichimoku\nThe ichimoku R package1 provides tools for creating and visualising Ichimoku Kinko Hyo (cloud chart) strategies.\nIt features in the Empirical Finance CRAN Task View, and was selected as one of RStudio’s Top 40 New CRAN Packages for May 2021.\nThe latest version incorporates an interface to the OANDA fxTrade API2.\nAbout the OANDA fxTrade API\nOANDA is an authoritative source of foreign exchange data utilised by both governments and global corporations alike. OANDA offers a few APIs, including its rates for business, but the fxTrade API is perhaps the most comprehensive, built upon its retail and professional trading offering of the same name. Access to the fxTrade API is free but requires registration for a practice/demo account.\nThe API can be used for retrieving historical and live streaming price data for major currencies, metals, commodities, government bonds and stock indices. It is a rich source of financial data with excellent availability, for instance daily OHLC pricing data for major forex pairs from the start of 2005, and data granularity ranging from 5 seconds to monthly.\nFor the total list of over 120 covered instruments please see here.\nScreenshots\nClick on an image to view in full resolution.\nShowcased here is the function oanda_studio(), the implementation in R Shiny. As a Shiny app, the function may be called without specifying any parameters; the full range of options can be selected interactively from within the web interface.\nData is live and updates at the specified refresh rate (default of every 5 secs).\nThe cursor infotip provides an innovative overview of the data directly from the chart (can be turned on or off as desired).\n\n\nlibrary(ichimoku)\n\noanda_studio()\n\n\n\n\nOf course arguments for customisation can also be specified within the call to oanda_studio() itself. Demonstrating some further options below with Soybean futures:\n\n\noanda_studio(\"SOYBN_USD\", granularity = \"M5\", refresh = 10, price = \"B\", theme = \"dark\")\n\n\n\n\nOther functions\nOther functions to access the OANDA fxTrade API are included in the ichimoku package. These are standard R functions for retrieving data in tabular form and charting (not reliant on Shiny), and include:\noanda() to retrieve price data\noanda_stream() to stream a live data feed\noanda_chart() to plot real-time ichimoku cloud charts\nLinks and further information\nichimoku R package site: https://shikokuchuo.net/ichimoku/\nichimoku OANDA fxTrade API vignette: https://shikokuchuo.net/ichimoku/articles/xoanda.html\n\nGao, C. (2021), ichimoku: Visualization and Tools for Ichimoku Kinko Hyo Strategies. R package version 1.0.0, https://CRAN.R-project.org/package=ichimoku.↩︎\n‘OANDA’ and ‘fxTrade’ are trademarks owned by OANDA Corporation, an entity unaffiliated with the ichimoku package.↩︎\n",
    "preview": "posts/12-oanda-studio/oanda-studio_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:46:04+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/11-dataframes/",
    "title": "Efficient R: Performant data.frame constructors",
    "description": "How and when to use an alternative to as.data.frame",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-07-23",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nAbout as.data.frame\nMatrix conversion benchmarking\nxts conversion benchmarking\nWhen to use performant constructors\nWhen to question the use of performant constructors\nWhat is a performant constructor\nFurther information\n\n\n\n\n\nShikokuchuo\nAbout as.data.frame\ndata.frame() or as.data.frame() are such ubiquitous functions that we rarely think twice about using them to create dataframes or to convert other objects to dataframes.\nHowever, they are slow. Extremely slow.\nThis is somewhat surprising considering how much they are used, and given that the ‘data.frame’ object is the de facto standard for tabular data in R, for their constructors to be so inefficient.\nHowever this is the direct result of the presence of a lot of error checking and validation code, which is perhaps understandable for something as widely used. It simply needs to handle a wide possible variety of inputs and so tries to do its best or fail gracefully.\nBelow, we demonstrate the inefficiencies of as.data.frame() versus efficient ‘data.frame’ constructors from the ‘ichimoku’ package1 coded for performance.\nFor benchmarking, the ‘microbenchmark’ package will be used. It is usual to compare the median times averaged over a large number of runs, and we will use 10,000 in the cases below.\nMatrix conversion benchmarking\nA 100x10 matrix of random data drawn from the normal distribution is created as the object ‘matrix’.\nThis will be converted into a dataframe using as.data.frame() and ichimoku::matrix_df().\n\n\nlibrary(ichimoku)\nlibrary(microbenchmark)\n\nmatrix <- matrix(rnorm(1000), ncol = 10, dimnames = list(1:100, letters[1:10]))\n\ndim(matrix)\n\n\n[1] 100  10\n\nhead(matrix)\n\n\n           a          b          c          d          e          f\n1 -0.1400286  1.1118323  0.4669602 -1.4488988 -0.7541324  0.9637862\n2  1.0460964 -0.7047356 -0.4437435  0.7018097  0.4328479  0.9859072\n3 -2.0406678  0.2809715 -0.2868613 -1.9068354 -1.2635379 -0.3884103\n4  1.4877548 -2.3801003 -1.0285516 -0.4433571 -0.9534238  1.4033954\n5  1.5941811 -1.1293828  1.3376018  1.1229029  1.0523098  1.3629215\n6  0.3723751 -1.6727550 -1.1478162 -1.7363323  2.0140197 -0.6120398\n           g          h          i          j\n1  0.9775267 -0.8609284  1.1481851 -0.8444851\n2  0.3858858 -0.9267438 -0.7355040 -0.6310779\n3 -0.1272062 -1.3729532  1.9566503  1.0197956\n4  1.0877965  0.7028592 -1.4809024 -1.8808421\n5 -0.2563864 -0.1795008  0.3667372 -1.1918655\n6  1.4115147 -0.9282505  0.0256846 -0.6860796\n\nmicrobenchmark(as.data.frame(matrix), matrix_df(matrix), times = 10000)\n\n\nUnit: microseconds\n                  expr    min      lq     mean  median      uq\n as.data.frame(matrix) 30.494 32.5955 38.57970 33.5535 35.5940\n     matrix_df(matrix)  6.353  7.1900 10.21914  7.6450  8.2785\n      max neval\n 12755.62 10000\n 11542.73 10000\n\nidentical(as.data.frame(matrix), matrix_df(matrix))\n\n\n[1] TRUE\n\nAs can be seen, the outputs are identical, but ichimoku::matrix_df(), which is designed to be a performant ‘data.frame’ constructor, is over 3x as fast.\nxts conversion benchmarking\nThe ‘xts’ format is a popular choice for large time series data as each observation is indexed by a unique valid timestamp.\nAs an example, we use the ichimoku() function from the ‘ichimoku’ package which creates ichimoku objects inheriting the ‘xts’ class. We run ichimoku() on the sample data contained within the package to create an ‘xts’ object ‘cloud’.2\nThis will be converted into a dataframe using as.data.frame() and ichimoku::xts_df().\n\n\nlibrary(ichimoku)\nlibrary(microbenchmark)\n\ncloud <- ichimoku(sample_ohlc_data)\nclass(cloud) <- c(\"xts\", \"zoo\")\n\nxts::is.xts(cloud)\n\n\n[1] TRUE\n\ndim(cloud)\n\n\n[1] 281  12\n\nprint(cloud[1:6], plot = FALSE)\n\n\n            open  high   low close cd tenkan kijun senkouA senkouB\n2020-01-02 123.0 123.1 122.5 122.7 -1     NA    NA      NA      NA\n2020-01-03 122.7 122.8 122.6 122.8  1     NA    NA      NA      NA\n2020-01-06 122.8 123.4 122.4 123.3  1     NA    NA      NA      NA\n2020-01-07 123.3 124.3 123.3 124.1  1     NA    NA      NA      NA\n2020-01-08 124.1 124.8 124.0 124.8  1     NA    NA      NA      NA\n2020-01-09 124.8 125.4 124.5 125.3  1     NA    NA      NA      NA\n           chikou cloudT cloudB\n2020-01-02  122.8     NA     NA\n2020-01-03  122.9     NA     NA\n2020-01-06  123.0     NA     NA\n2020-01-07  123.9     NA     NA\n2020-01-08  123.6     NA     NA\n2020-01-09  122.5     NA     NA\n\nmicrobenchmark(as.data.frame(cloud), xts_df(cloud), times = 10000)\n\n\nUnit: microseconds\n                 expr     min      lq      mean   median       uq\n as.data.frame(cloud) 234.909 243.014 270.20903 248.7585 267.1130\n        xts_df(cloud)  24.201  27.103  40.36881  28.7090  30.5855\n      max neval\n  7683.47 10000\n 59508.19 10000\n\nIt can be seen that ichimoku::xts_df(), which is designed to be a performant ‘data.frame’ constructor, is over 8x as fast.\n\n\ndf1 <- as.data.frame(cloud)\n\nis.data.frame(df1)\n\n\n[1] TRUE\n\nstr(df1)\n\n\n'data.frame':   281 obs. of  12 variables:\n $ open   : num  123 123 123 123 124 ...\n $ high   : num  123 123 123 124 125 ...\n $ low    : num  122 123 122 123 124 ...\n $ close  : num  123 123 123 124 125 ...\n $ cd     : num  -1 1 1 1 1 1 -1 0 -1 -1 ...\n $ tenkan : num  NA NA NA NA NA ...\n $ kijun  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ senkouA: num  NA NA NA NA NA NA NA NA NA NA ...\n $ senkouB: num  NA NA NA NA NA NA NA NA NA NA ...\n $ chikou : num  123 123 123 124 124 ...\n $ cloudT : num  NA NA NA NA NA NA NA NA NA NA ...\n $ cloudB : num  NA NA NA NA NA NA NA NA NA NA ...\n\ndf2 <- xts_df(cloud)\n\nis.data.frame(df2)\n\n\n[1] TRUE\n\nstr(df2)\n\n\n'data.frame':   281 obs. of  13 variables:\n $ index  : POSIXct, format: \"2020-01-02\" ...\n $ open   : num  123 123 123 123 124 ...\n $ high   : num  123 123 123 124 125 ...\n $ low    : num  122 123 122 123 124 ...\n $ close  : num  123 123 123 124 125 ...\n $ cd     : num  -1 1 1 1 1 1 -1 0 -1 -1 ...\n $ tenkan : num  NA NA NA NA NA ...\n $ kijun  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ senkouA: num  NA NA NA NA NA NA NA NA NA NA ...\n $ senkouB: num  NA NA NA NA NA NA NA NA NA NA ...\n $ chikou : num  123 123 123 124 124 ...\n $ cloudT : num  NA NA NA NA NA NA NA NA NA NA ...\n $ cloudB : num  NA NA NA NA NA NA NA NA NA NA ...\n\nThe outputs are slightly different as xts_df() preserves the date-time index of ‘xts’ objects as a new first column ‘index’ which is POSIXct in format. The default as.data.frame() constructor converts the index into the row names, which is not desirable as the dates are coerced to type ‘character’.\nSo it can be seen that in this case, not only is the performant constructor faster, it is also more fit for purpose.\nWhen to use performant constructors\nData which is not already a ‘data.frame’ object being plotted using ‘ggplot2’. For example if you have time series data in the ‘xts’ format, calling a ‘ggplot2’ plot method automatically converts the data into a dataframe behind the scenes as ggplot() only works with dataframes internally. Fortunately it does not use as.data.frame() but its own constructor ggplot2::fortify(). Benchmarked below, it is slightly faster than as.data.frame() but the performant constructor ichimoku::xts_df() is still around 5x as fast.\n\n\nmicrobenchmark(as.data.frame(cloud), ggplot2::fortify(cloud), xts_df(cloud), times = 10000)\n\n\nUnit: microseconds\n                    expr     min       lq      mean   median       uq\n    as.data.frame(cloud) 237.257 252.8185 297.82993 263.3445 290.8465\n ggplot2::fortify(cloud) 130.149 149.6695 176.68291 160.8120 178.8900\n           xts_df(cloud)  25.166  29.8525  38.59277  31.8160  34.9770\n      max neval\n 6863.294 10000\n 6107.186 10000\n 9592.124 10000\n\nIn a context where performance is critical. This is usually in interactive environments such as a Shiny app, perhaps with real time data where slow code can reduce responsiveness or cause bottlenecks in execution.\nWithin packages. It is usually safe to use performant constructors within functions or for internal unexported functions. If following programming best practices the input and output types for functions are kept consistent, and so the input to the constructor can be controlled and hence its function predictable. Setting appropriate unit tests can also catch any issues early.\nWhen to question the use of performant constructors\nFor user-facing functions. Having no validation or error-checking code means that a performant constructor may behave unpredictably on data that is not intended to be an input. Within a function, there is a specific or at most finite range of objects that a constructor can receive. When that limit is removed, if the input is not the intended input for a constructor then an error can be expected. As long as this is made clear to the user and there are adequate instructions on proper usage, in an environment where the occasional error message is acceptable, then the performant constructor can still be used.\nWhen the constructor needs to handle a range of input types. as.data.frame() is actually an S3 generic with a variety of methods for different object classes. If required to handle a variety of different types of input, it may be easier (if not more performant) to rely on as.data.frame() rather than write code which handles different scenarios.\nWhat is a performant constructor\nFirst of all, it is possible to directly use the functions matrix_df() and xts_df() which are exported from the ‘ichimoku’ package.\nWhat lies behind those functions? Some variation on the below:\n\n\n# The stucture underlying a data frame is simply a list\ndf <- list(vec1, vec2, vec3)\n\n# Set the following attributes to turn the list into a data frame:\nattributes(df) <- list(names = c(\"vec1\", \"vec2\", \"vec3\"),\n                       class = \"data.frame\",\n                       row.names = .set_row_names(length(vec1)))\n\n\n\nA data.frame is simply a list (where each element must be the same length).\nIt has an attribute ‘class’ which equals ‘data.frame’.\nIt must have row names, which can be set by the base R internal function .set_row_names() which takes a single argument, the number of rows.\nNote:\nThe vectors in the list (vec1, vec2, vec3, etc.) must be the same length, otherwise a corrupt data.frame warning will be generated.\nIf row names are missing then the data will still be present but dim() will show a 0-row dataframe and its print method will not work.\n.set_row_names() sets row names efficiently using a compact internal notation used by R. They can also be assigned an integer sequence, or a series of dates for example. However if not an integer vector, they are first coerced to type ‘character’.\nIn conclusion, dataframes are not complicated structures but internally represented by lists with a couple of enforced constraints.\n\n\nclass(df1)\n\n\n[1] \"data.frame\"\n\ntypeof(df1)\n\n\n[1] \"list\"\n\nFurther information\nDocumentation for the performant constructors discussed: https://shikokuchuo.net/ichimoku/articles/utilities.html#performant-dataframe-constructors.\n\nGao, C. (2021), ichimoku: Visualization and Tools for Ichimoku Kinko Hyo Strategies. R package version 1.2.2, https://CRAN.R-project.org/package=ichimoku.↩︎\nWe then remove the ‘ichimoku’ class from the object as ‘ichimoku’ now has an efficient ‘as.data.frame’ S3 method since version 1.2.4.↩︎\n",
    "preview": "posts/11-dataframes/dataframes_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T16:05:23+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/10-combinations/",
    "title": "Efficient R: Combinations using expand.grid",
    "description": "A faster way to generate combinations for mapply and vapply",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-06-17",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nIntroduction\nexpand.grid\nichimoku::grid_dup\nBenchmarking the results\nUse case: mapply() and vapply()\n\n\n\n\n\nShikokuchuo\nIntroduction\nExhaustive combinations of two identical vectors are often desired as function inputs to mapply/vapply(). Usually, the combn() function from the ‘utils’ package serves this purpose.\nutils::combn() outputs the unique set of combinations, so for the example below where the first 8 letters of the alphabet are used, the combination {a, b} appears, but {b, a} does not. Similarly the cases where the two elements are identical such as {a, a} also do not feature. It can be seen that there are 28 (or 8 choose 2) unique combinations for the vector of length 8.\n\n\nx <- letters[1:8]\nxlen <- length(x)\n\ncombn <- utils::combn(x, 2)\ncombn\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n[1,] \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"b\"  \"b\"  \"b\"   \"b\"   \"b\"  \n[2,] \"b\"  \"c\"  \"d\"  \"e\"  \"f\"  \"g\"  \"h\"  \"c\"  \"d\"  \"e\"   \"f\"   \"g\"  \n     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\n[1,] \"b\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"d\"   \"d\"   \"d\"   \"d\"  \n[2,] \"h\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"e\"   \"f\"   \"g\"   \"h\"  \n     [,23] [,24] [,25] [,26] [,27] [,28]\n[1,] \"e\"   \"e\"   \"e\"   \"f\"   \"f\"   \"g\"  \n[2,] \"f\"   \"g\"   \"h\"   \"g\"   \"h\"   \"h\"  \n\nexpand.grid\nexpand.grid() from the base package is a useful function in its own right, most well-known perhaps for its use in generating hyperparameter tuning grids in machine learning models.\nexpand.grid() produces a data frame in columns rather than a matrix in rows like utils::combn(). Hence just for demonstration purposes to compare like-for-like, a bit of manipulation is done below to make the output exactly the same. In real world usage the output of expand.grid() can be used ‘as is’ without the additional manipulation.\n\n\ngrid <- expand.grid(x, x, KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE)\ngrid <- t(as.matrix(grid))\ngrid <- rbind(grid[2,], grid[1,])\nunname(grid)\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n[1,] \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"b\"  \"b\"   \"b\"   \"b\"  \n[2,] \"a\"  \"b\"  \"c\"  \"d\"  \"e\"  \"f\"  \"g\"  \"h\"  \"a\"  \"b\"   \"c\"   \"d\"  \n     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\n[1,] \"b\"   \"b\"   \"b\"   \"b\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"  \n[2,] \"e\"   \"f\"   \"g\"   \"h\"   \"a\"   \"b\"   \"c\"   \"d\"   \"e\"   \"f\"  \n     [,23] [,24] [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32]\n[1,] \"c\"   \"c\"   \"d\"   \"d\"   \"d\"   \"d\"   \"d\"   \"d\"   \"d\"   \"d\"  \n[2,] \"g\"   \"h\"   \"a\"   \"b\"   \"c\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"  \n     [,33] [,34] [,35] [,36] [,37] [,38] [,39] [,40] [,41] [,42]\n[1,] \"e\"   \"e\"   \"e\"   \"e\"   \"e\"   \"e\"   \"e\"   \"e\"   \"f\"   \"f\"  \n[2,] \"a\"   \"b\"   \"c\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"a\"   \"b\"  \n     [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] [,51] [,52]\n[1,] \"f\"   \"f\"   \"f\"   \"f\"   \"f\"   \"f\"   \"g\"   \"g\"   \"g\"   \"g\"  \n[2,] \"c\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"a\"   \"b\"   \"c\"   \"d\"  \n     [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n[1,] \"g\"   \"g\"   \"g\"   \"g\"   \"h\"   \"h\"   \"h\"   \"h\"   \"h\"   \"h\"  \n[2,] \"e\"   \"f\"   \"g\"   \"h\"   \"a\"   \"b\"   \"c\"   \"d\"   \"e\"   \"f\"  \n     [,63] [,64]\n[1,] \"h\"   \"h\"  \n[2,] \"g\"   \"h\"  \n\nIt can be seen that the output of expand.grid() is simply all combinations, of which there are 8^2 = 64 in total.\nichimoku::grid_dup\nSo how to get from the output of expand.grid() to that of utils::combn()? The answer comes courtesy of a simple algorithm coded into the grid_dup() function from the ‘ichimoku’ package.1\nFrom the function documentation: ‘create a vector of element positions of duplicates in the output of expand.grid on 2 identical vectors’.\nUsing the function as per the below, ‘grid1’ contains all unique combinations and also those where the two elements are identical. This is sometimes the desired output if two of the same elements is still considered a unique combination, but their order of appearance does not matter.\n\n\nlibrary(ichimoku)\n\ngrid1 <- grid[, -grid_dup(xlen)]\ngrid1\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n[1,] \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"b\"  \"b\"   \"b\"   \"b\"  \n[2,] \"a\"  \"b\"  \"c\"  \"d\"  \"e\"  \"f\"  \"g\"  \"h\"  \"b\"  \"c\"   \"d\"   \"e\"  \n     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\n[1,] \"b\"   \"b\"   \"b\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"d\"  \n[2,] \"f\"   \"g\"   \"h\"   \"c\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"d\"  \n     [,23] [,24] [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32]\n[1,] \"d\"   \"d\"   \"d\"   \"d\"   \"e\"   \"e\"   \"e\"   \"e\"   \"f\"   \"f\"  \n[2,] \"e\"   \"f\"   \"g\"   \"h\"   \"e\"   \"f\"   \"g\"   \"h\"   \"f\"   \"g\"  \n     [,33] [,34] [,35] [,36]\n[1,] \"f\"   \"g\"   \"g\"   \"h\"  \n[2,] \"h\"   \"g\"   \"h\"   \"h\"  \n\nIf the ‘omit.id = TRUE’ argument is set for grid_dup(), identical elements are also removed. ‘grid2’ should then be the same as ‘combn’ obtained above, as confirmed by the result of identical() below.\n\n\ngrid2 <- grid[, -grid_dup(xlen, omit.id = TRUE)]\ngrid2\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n[1,] \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"b\"  \"b\"  \"b\"   \"b\"   \"b\"  \n[2,] \"b\"  \"c\"  \"d\"  \"e\"  \"f\"  \"g\"  \"h\"  \"c\"  \"d\"  \"e\"   \"f\"   \"g\"  \n     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\n[1,] \"b\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"d\"   \"d\"   \"d\"   \"d\"  \n[2,] \"h\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"e\"   \"f\"   \"g\"   \"h\"  \n     [,23] [,24] [,25] [,26] [,27] [,28]\n[1,] \"e\"   \"e\"   \"e\"   \"f\"   \"f\"   \"g\"  \n[2,] \"f\"   \"g\"   \"h\"   \"g\"   \"h\"   \"h\"  \n\nidentical(combn, grid2)\n\n\n[1] TRUE\n\nBenchmarking the results\n‘Microbenchmark’ can be used to benchmark the performance, where it is usual practice to compare median values.\nFor small vector lengths, expand.grid() is not as performant. However the absolute times are also small so any difference would not matter as much. When the vector length reaches 13, the custom algorithm using expand.grid()/grid_dup() starts to outperform.\nBy the time the vector length reaches 1,000, this implies total unique combinations of 499,500 and the custom algorithm is already c. 7x faster.\nIt should be noted that the custom algorithm is tailored for the special case of combn(x, m) where m = 2 and this is the reason why there can be such an outperformance. In programming, where the implementation has already been tuned to be the most efficient possible, it can be useful to think whether the algorithm or code logic can be adapted for the case required.\n\n\nfn_combn <- function(x) {\n  utils::combn(x, 2)\n}\n\nfn_grid <- function(x) {\n  expand.grid(x, x, KEEP.OUT.ATTRS = FALSE,\n              stringsAsFactors = FALSE)[-grid_dup(length(x), omit.id = TRUE), ]\n}\n\nmicrobenchmark::microbenchmark(fn_combn(1:13), fn_grid(1:13))\n\n\nUnit: microseconds\n           expr    min      lq     mean  median      uq      max\n fn_combn(1:13) 38.927 41.6245 51.37336 43.0385 45.0745  686.700\n  fn_grid(1:13) 35.883 38.2090 60.74484 39.6740 43.0570 1762.119\n neval\n   100\n   100\n\nmicrobenchmark::microbenchmark(fn_combn(1:1000), fn_grid(1:1000))\n\n\nUnit: milliseconds\n             expr       min       lq     mean    median        uq\n fn_combn(1:1000) 201.59798 207.6833 214.4459 210.29602 213.29315\n  fn_grid(1:1000)  27.23142  30.1157  35.8723  31.56724  34.42106\n       max neval\n 272.82774   100\n  90.80061   100\n\nUse case: mapply() and vapply()\nThis type of output is suitable for feeding into functions such as mapply() or vapply().\nA standard use for mapply is when multiple arguments have to be mapped into a function. Here ‘simplify = FALSE’ is set to have mapply return a list, and fed into do.call() with c() to create a vector. This is a safer and more performant method to create a vector than relying on the built-in simplification.\n\n\ndo.call(c, mapply(function(x, y) paste0(x, \"&\", y), \n                  grid2[1, ], grid2[2, ],\n                  SIMPLIFY = FALSE, USE.NAMES = FALSE))\n\n\n [1] \"a&b\" \"a&c\" \"a&d\" \"a&e\" \"a&f\" \"a&g\" \"a&h\" \"b&c\" \"b&d\" \"b&e\" \"b&f\"\n[12] \"b&g\" \"b&h\" \"c&d\" \"c&e\" \"c&f\" \"c&g\" \"c&h\" \"d&e\" \"d&f\" \"d&g\" \"d&h\"\n[23] \"e&f\" \"e&g\" \"e&h\" \"f&g\" \"f&h\" \"g&h\"\n\nAn equivalent example using vapply() is given below. vapply() is also a safe choice for programming as an output template is explicitly specified, here ‘character(1L)’, hence the returned values are all expected to be of type ‘character’ of length ‘1’ otherwise an error is thrown.\n\n\nvapply(seq_along(grid2[1L, ]),\n       function(i) paste0(grid2[1L, i], \"&\", grid2[2L, i]),\n       character(1L), USE.NAMES = FALSE)\n\n\n [1] \"a&b\" \"a&c\" \"a&d\" \"a&e\" \"a&f\" \"a&g\" \"a&h\" \"b&c\" \"b&d\" \"b&e\" \"b&f\"\n[12] \"b&g\" \"b&h\" \"c&d\" \"c&e\" \"c&f\" \"c&g\" \"c&h\" \"d&e\" \"d&f\" \"d&g\" \"d&h\"\n[23] \"e&f\" \"e&g\" \"e&h\" \"f&g\" \"f&h\" \"g&h\"\n\nOf the two however, mapply() is marginally faster and should normally be used when iteration is required over multiple arguments.\n\nGao, C. (2021), ichimoku: Visualization and Tools for Ichimoku Kinko Hyo Strategies. R package version 1.2.4, https://CRAN.R-project.org/package=ichimoku.↩︎\n",
    "preview": "posts/10-combinations/combinations_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:44:55+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/09-docall-lapply/",
    "title": "Efficient R: do.call / lapply",
    "description": "A distinctive coding style",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-28",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nUse case\nSetup\nLoop\ndo.call / lapply\nTidy data output\n\n\n\n\n\nShikokuchuo\nUse case\nThe use of the do.call / lapply() combination is a powerful way to leverage functional programming in R. In short, write a function that performs some actions and apply it to a list of inputs, which is then combined into a single object.\nLet us take an example, where we would like to calculate the ichimoku clouds for a selection of the major world stock indices, but also preserve the volume data, all in one tidy object.\nWe use the ‘ichimoku’ package1 which not only draws the ichimoku clouds, but also provides an interface to the OANDA fxTrade API which is a rich source of high-quality financial data (free but requires registration).\nSetup\nWe could set it up as per the below:\ntickers: a vector defining the stock symbols in our portfolio\nprocess(): a function that generates a row in a data frame or matrix\n\n\nlibrary(ichimoku)\n\ntickers <- c(\"DE30_EUR\", \"JP225_USD\", \"SPX500_USD\", \"UK100_GBP\")\n\nprocess <- function(x, from, to) {\n  # Use ichimoku::oanda() to retrieve data from the OANDA fxTrade API\n  pxdata <- oanda(x, from = from, to = to)\n  # Extract volume column\n  volume <- pxdata$volume\n  # Calculate the cloud by calling ichimoku::ichimoku()\n  cloud <- ichimoku(pxdata, ticker = x)\n  # Return a list of ticker, ichimoku cloud object, volume data\n  list(x, cloud, volume)\n}\n\n\n\n\nNote: the original pricing data is preserved within the ichimoku object.\nWe now want to apply our function to each element of ‘tickers’ in turn, and then for the results to be combined.\nLoop\nOne way to achieve this would be to iterate over ‘tickers’ using a loop:\n\n\n# Define a list to contain the loop output, specifying the length in advance as good practice\nportfolio <- vector(mode = \"list\", length = length(tickers))\n\n# Loop over each element in 'tickers' and save in pre-defined list\nfor (i in seq_along(tickers)) {\n  portfolio[[i]] <- process(tickers[i], from = \"2015-09-03\", to = \"2016-06-30\")\n}\n\n# Create output matrix by calling rbind on each element of the list\nportfolio <- do.call(rbind, portfolio)\n\nportfolio\n\n\n     [,1]         [,2]          [,3]       \n[1,] \"DE30_EUR\"   ichimoku,2808 integer,209\n[2,] \"JP225_USD\"  ichimoku,2856 integer,213\n[3,] \"SPX500_USD\" ichimoku,2856 integer,213\n[4,] \"UK100_GBP\"  ichimoku,2808 integer,209\n\nThis approach takes 3-4 lines of code.\nFurthermore, ‘i’ remains as a leftover object in the global environment.\nSomewhat messy.\ndo.call / lapply\nInstead we can use a do.call / lapply() combination to achieve the same result in one line:\n\n\nportfolio <- do.call(rbind, lapply(tickers, process, from = \"2015-09-03\", to = \"2016-06-30\"))\n\nportfolio\n\n\n     [,1]         [,2]          [,3]       \n[1,] \"DE30_EUR\"   ichimoku,2808 integer,209\n[2,] \"JP225_USD\"  ichimoku,2856 integer,213\n[3,] \"SPX500_USD\" ichimoku,2856 integer,213\n[4,] \"UK100_GBP\"  ichimoku,2808 integer,209\n\nThere are also no intermediate objects generated that clutter the global environment.\nTo explain:\nFirst lapply() applies to a list or list-like object (‘tickers’), a function (‘process’). The arguments to the function are supplied immediately afterwards. lapply always returns a list.\nThis is then fed into do.call(), which calls a function (‘rbind’) on a list of arguments (the output of ‘lapply’, a list). This creates a matrix.\nThe use of do.call / lapply() provides for a far more succinct and distinctive coding style.\nThe added bonus is that of the ‘apply’ family of functions, lapply() is almost always the fastest and most performant as the output type is fixed and it does not try to do things with names or simplify the output structure.\nFor a more structured format than a list, lapply() can be fed into a do.call() with:\nc() to form a vector\ncbind() or rbind() to form a matrix\nThe use of this type of combination is of particular benefit in programming where both performance and predictability of output types is paramount.\nTidy data output\n\n\nportfolio\n\n\n     [,1]         [,2]          [,3]       \n[1,] \"DE30_EUR\"   ichimoku,2808 integer,209\n[2,] \"JP225_USD\"  ichimoku,2856 integer,213\n[3,] \"SPX500_USD\" ichimoku,2856 integer,213\n[4,] \"UK100_GBP\"  ichimoku,2808 integer,209\n\n‘portfolio’ is a tidy matrix with a row for each ticker, and a column for each data type.\nWe can easily access any element of the matrix by specifying its index value, for example the ichimoku object for the S&P 500 Index by [3,2]. In the example below we run autostrat() on this object:\n\n\nautostrat(portfolio[3, 2][[1]], n = 1)\n\n\n                       [,1]               \nStrategy               \"cloudT > kijun\"   \n---------------------  \"----------\"       \nStrategy cuml return % 7.76               \nPer period mean ret %  0.0554             \nPeriods in market      74                 \nTotal trades           3                  \nAverage trade length   24.67              \nTrade success %        100                \nWorst trade ret %      0.81               \n---------------------  \"----------\"       \nBenchmark cuml ret %   3.7                \nPer period mean ret %  0.0269             \nPeriods in market      135                \n---------------------  \"----------\"       \nDirection              \"long\"             \nStart                  2015-12-21 22:00:00\nEnd                    2016-06-29 22:00:00\nTicker                 \"SPX500_USD\"       \n\n\nNote: Each element of the matrix is wrapped as a list so that they are of equal length. To access the underlying object, the ichimoku object in this case, we simply extract it using [[1]].\n2\n\nGao, C. (2021), ichimoku: Visualization and Tools for Ichimoku Kinko Hyo Strategies. R package version 1.1.0, https://CRAN.R-project.org/package=ichimoku. Note that since version 1.2.0 additional data such as volume may be retained within the ichimoku object itself.↩︎\nFurther examples: Youngju Nielsen of Sungkyunkwan University uses do.call / lapply to good effect in her course https://www.coursera.org/learn/the-fundamental-of-data-driven-investment/↩︎\n",
    "preview": "posts/09-docall-lapply/docall-lapply_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:43:26+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/08-ichimoku/",
    "title": "ichimoku",
    "description": "R package for Ichimoku Kinko Hyo cloud charts",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-19",
    "categories": [
      "R",
      "Quantitative Finance"
    ],
    "contents": "\n\nContents\nExample\nInstallation\nPackage\nIchimoku Kinko Hyo \nInterpretation\nContext\n\n\n\n\n\nShikokuchuo\nAn implementation in R of the Ichimoku Kinkō Hyō (一目均衡表) charting system, also commonly known as ‘cloud charts’.\nThe technique is a refinement on candlestick charting, originating from Japan and now in widespread use in technical analysis worldwide. Translating to ‘one-glance equilibrium chart’, it allows the price action and market structure of financial securities to be determined ‘at-a-glance’.\nExample\nLoad package and sample data:\n\n\nlibrary(ichimoku)\nTKR <- sample_ohlc_data\n\n\n\nichimoku() to generate the ichimoku object:\n\n\ncloud <- ichimoku(TKR)\nsummary(cloud)\n\n\nichimoku object with dimensions (281, 12) \n\n            Max: 2020-07-14 [139.7]\nStart: 2020-01-02 [123]   End: 2020-12-24 [136]\n            Min: 2020-05-13 [119.1]\n\nCloud periods: 9 26 52 \nPeriodicity: 1 days \nTicker: TKR\n\niplot() for fully-interactive cloud charts:\n\n\niplot(cloud)\n\n\n\n\nplot() for static cloud charts:\n\n\nplot(cloud, window = \"2020-05/\", theme = \"solarized\")\n\n\n\nplot(cloud, window = \"2020-05/\", theme = \"dark\")\n\n\n\nplot(cloud, window = \"2020-05/\", theme = \"mono\")\n\n\n\n\nInstallation\nInstall the released version of ichimoku from CRAN:\ninstall.packages(\"ichimoku\")\nOr the latest development version from rOpenSci R-universe:\ninstall.packages(\"ichimoku\", repos = \"https://shikokuchuo.r-universe.dev\")\nPackage\nWebsite: https://shikokuchuo.net/ichimoku/ 1\nIchimoku Kinko Hyo 2\nThe system consists of the following chart lines added to a candlestick chart:\n転換線 Tenkan-sen [conversion line]: the mid-point of the highest high and lowest low for the past 9 periods (including the current period)\n基準線 Kijun-sen [base line]: the mid-point of the highest high and lowest low for the past 26 periods (including the current period)\n先行スパン1 Senkou span A [leading span A]: the mid-point of Tenkan-sen and Kijun-sen plotted ahead 26 periods (including the current period)\n先行スパン2 Senkou span B [leading span B]: the mid-point of the highest high and lowest low for the past 52 periods (including the current period), plotted ahead 26 periods (including the current period)\n遅行スパン Chikou span [lagging span]: the current period closing price plotted behind 26 periods (including the current period)\nThe 雲 kumo [cloud] is the area bounded by Senkou span A and Senkou span B (usually shaded on a chart).\nInterpretation\nIchimoku Kinkō Hyō can be translated as ‘one-glance equilibrium chart’. It is designed to allow the price action and market structure of financial securities to be determined ‘at-a-glance’ in a highly visual fashion.\nFor example in a strongly upwards-trending market, the candlesticks will be above the Tenkan-sen, which will be above the Kijun-sen, which will be above the cloud, and the Chikou span may not have anything above it.\nThe lines and the cloud represent dynamic support and resistance zones relative to the price candles. Generally the thicker the cloud, the tougher the support/resistance. In our previous example, if the price now reverts downwards, it can expect support first at the Kijun-sen, then the Tenkan-sen and finally the cloud itself.\nMore subtle interpretations involve the Chikou span in particular and its action in relation to the cloud lines as well as the candles.\nContext\nIchimoku analysis is the latest refinement in candlestick charting techniques, which also originated from Japan. Developed by 一目山人 Ichimoku, Sanjin, the pen name of 細田吾一 Hosoda, Goichi, his work was published in 1969 as the seminal 「一目均衡表」 [ichimoku kinkou hyou]. It gained popularity in Japan especially after the publication of Sasaki’s 「一目均衡表の研究」 [ichimoku kinkouhyou no kenkyuu] in 1996, and is now widely-used in technical analysis worldwide.\nThe time periods have traditionally been calculated as 9, 26 and 52 based on manual data analysis performed in Japan in a pre-computer age where there was a 6-day working week resulting in 26 average trading days in a month. Although this bears little relevance to the current day, the use of these time periods has persisted as an ‘industry norm’ or ‘accepted practice’.\nTo use other periods would be meaningless in a sense as everyone uses these parameters and ‘market psychology’ can and often does create its own realities, independent of any fundamentals. However, there is no reason for the technique not to evolve, and to reflect changing trading realities perhaps other parameters will become more relevant in the collective psychology.\nFinally, the use originated with daily candlesticks, and the most valid interpretation remains for daily data. However, it is equally used today for both shorter intra-day, e.g. 4-hour or hourly, and longer, e.g. weekly or monthly, charts.\n\nGao, C. (2021), ichimoku: Visualization and Tools for Ichimoku Kinko Hyo Strategies. R package version 1.2.4, https://CRAN.R-project.org/package=ichimoku.↩︎\nSasaki, H. 佐々木 英信 (1996), 一目均衡表の研究 [ichimoku kinkouhyou no kenkyuu]. Tokyo, Japan: Toushi Radar.↩︎\n",
    "preview": "posts/08-ichimoku/ichimoku_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:42:35+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/07-learning/",
    "title": "Resources for learning",
    "description": "A curated selection of online MOOCs",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-14",
    "categories": [
      "Resources",
      "Learning"
    ],
    "contents": "\n\nContents\nCoursera Specializations\n\n\n\n\n\nShikokuchuo  Iyo Mishima station\nCoursera Specializations\n\n\nlibrary(magrittr)\ntibble::tribble(\n  ~Institution, ~`Course or Specialization`, ~URL,\n  \"Duke University\", \"Statistics with R\", \"https://www.coursera.org/specializations/statistics\",\n  \"Duke University\", \"Entrepreneurial Finance: Strategy and Innovation\", \"https://www.coursera.org/specializations/entrepreneurial-finance\",\n  \"John Hopkins University\", \"Mastering Software Development in R\", \"https://www.coursera.org/specializations/r\",\n  \"Sung Kyun Kwan University\", \"The Fundamentals of Data Driven Investment\" ,\"https://www.coursera.org/learn/the-fundamental-of-data-driven-investment\"\n) %>%\n  dplyr::mutate(URL = purrr::map_chr(URL, ~paste0(\"<a href='\", .x, \"'>\", .x, \"<\/a>\"))) %>%\n  DT::datatable(escape = FALSE)\n\n\n\n\n\n\n\n",
    "preview": "posts/07-learning/learning_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:41:09+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/06-datasets/",
    "title": "Datasets",
    "description": "For Econometrics and Machine Learning",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-05",
    "categories": [
      "Resources",
      "Data"
    ],
    "contents": "\n\nContents\nDatasets\n\n\n\n\n\nShikokuchuo\nDatasets\n\n\nlibrary(magrittr)\ntibble::tribble(\n  ~Source, ~URL, ~Package,\n  \"Fred\", \"https://fred.stlouisfed.org/\", \"Quantmod\",\n  \"Quandl\", \"https://www.quandl.com/\", \"Quandl\",\n  \"Yahoo Finance\", \"https://finance.yahoo.com/\", \"Quantmod\",\n  \"Damodaran NYU Stern\", \"http://people.stern.nyu.edu/adamodar/New_Home_Page/datacurrent.html\", \"\",\n  \"UCI Machine Learning Repository\", \"https://archive.ics.uci.edu/ml/index.php\", \"\",\n  \"Project Gutenberg\", \"https://www.gutenberg.org/\", \"gutenbergr\"\n) %>%\n  dplyr::mutate(URL = purrr::map_chr(URL, ~paste0(\"<a href='\", .x, \"'>\", .x, \"<\/a>\"))) %>%\n  DT::datatable(escape = FALSE)\n\n\n\n\n\n\n\n",
    "preview": "posts/06-datasets/datasets_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:40:44+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/04-distill/",
    "title": "Distill for R Markdown",
    "description": "Web publishing optimised for scientific and technical communication",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-04",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nCreated using Distill\nKey advantages\nInstallation\nDistill blog hosted on Github Pages step-by-step instructions\nReferences\n\n\n\n\n\nShikokuchuo\nCreated using Distill\nThis website was created using Distill for R Markdown, a web publishing format optimised for scientific and technical communication.\nKey advantages\nR markdown to run R code (and all the possibility that brings)\nUse markdown / html interchangeably\nNo dependency on Hugo or Jekyll, so no lock-in or need to maintain those stacks\nOut-of-the-box support for mobile\nClean and attractive defaults\nMainly “just works”\nInstallation\nInstall release version of Distill from CRAN:\n\n\ninstall.packages(\"distill\")\n\n\n\nDistill blog hosted on Github Pages step-by-step instructions\nCreate a new blog at /blog of your current working directory in R:\n\n\ndistill::create_blog(dir = \"blog\", title = \"My New Blog\", gh_pages = TRUE)\n\n\n\nMake some inital changes to _site.yml. Select the ‘build’ tab in RStudio and hit ‘Build Website’. This will generate the website. Note: building the website does not generate blog posts. Each time the website is re-built, only the .Rmd files in the base directory will be automatically re-generated.\nModify the yaml front matter and content of the example blog post. Then hit ‘Knit’ in RStudio to generate the post. Note: after every change made to posts or after creating a new post, you must knit each post separately. The listings page is then automatically updated.\nCreate README.md, license.txt and CNAME if using a customm domain.\nREADME.md and license.txt are optional but usual practice. CNAME is a single line text file containing the domain name.\n\nCreate a new repository at Github.\nTo set up git and add your new repository as a remote, bring up the command line, cd to your new blog directory and:\n\ngit init\ngit add .\ngit commit -m \"initial commit\"\ngit branch -M main\ngit remote add origin git@github.com:username/nameofnew.git\ngit push -u origin main\n\n\nReplace ‘username/nameofnew.git’ as appropriate.\nAt Github, under your new repository, go to Settings >> Pages, set your source branch to ‘main’, and folder to ‘docs’. Tick ‘Enforce HTTPS’ (recommended).  If using a custom domain name, it should be configured automatically if you have previously set up your DNS settings to point to Github’s servers.\nCongratulations, your new website should now be online!\nReferences\nThe Distill Reference: https://rstudio.github.io/distill/\nThe Definitive R Markdown Guide: https://bookdown.org/yihui/rmarkdown/\n\n\n\n",
    "preview": "posts/04-distill/distill_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:40:01+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/05-ghactions/",
    "title": "Github Actions with R",
    "description": "Deploy and automate your code to the cloud",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-04",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nGithub Actions with R\nReference\n\n\n\n\n\nShikokuchuo\nGithub Actions with R\nSet up a cron job to run your R scripts at specified times.\nEnabled with a simple yaml configuration file.\nSave the following as main.yml in .github/workflows of your Github repository:\n\nname: Action\non:\n  schedule:\n    - cron: '30 22 * * 1-5'\njobs:\n  render:\n    runs-on: windows-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up R\n        uses: r-lib/actions/setup-r@v1\n      - name: Install dependencies\n        run: |\n          install.packages(c(\"magrittr\", \"purrr\"), type = \"win.binary\")\n        shell: Rscript {0}\n      - name: Script\n        run: Rscript nameofscript.R\n      - name: Commit files\n        run: |\n          git config --local user.name github-actions\n          git config --local user.email \"actions@github.com\"\n          git add docs/*\n          git commit -am \"commit on $(date)\"\n          git push origin main\n        env:\n          REPO_KEY: ${{secrets.GITHUB_TOKEN}}\n          username: github-actions\n\nThis example cron job runs every Mon-Fri at 22.30.\nCustomize your R packages to install.\nMake sure to change nameofscript.R to your actual script name.\nAssumes your script writes files to the ‘docs’ directory, change if necessary.\nAssumes your repository branch is ‘main’, change if necessary.\nNote that this script is run on a Windows VM using Windows R binary packages. This is currently much faster than building a lot of dependencies on Linux (which is also prone to failure).\nTo generate R Markdown documents (or for that matter render a Distill website), you will want to add the following step after ‘Set up R’:\n\n      - name: Set up Pandoc\n        uses: r-lib/actions/setup-pandoc@v1\n\nReference\nThe Github Actions with R reference: https://orchid00.github.io/actions_sandbox/\n\n\n\n",
    "preview": "posts/05-ghactions/ghactions_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:40:22+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/03-rselenium/",
    "title": "R | Selenium",
    "description": "Programmatically drive a web browser",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-03",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nUse case\nInitial setup\nRunning Selenium Webdriver\nRSelenium quickstart code\nReference\n\n\n\n\n\nShikokuchuo\nUse case\nWhenever you need to programmatically drive a web browser.\nMost often:\nto scrape information behind a login screen\nwhen the http server does not return a simple html document\nInitial setup\nPrerequisites: JRE or JDK installed on your system, Mozilla Firefox\nInstall the RSelenium package from CRAN:\n\n\ninstall.packages(\"RSelenium\")\n\n\n\nGo to https://selenium-release.storage.googleapis.com/index.html\nDownload selenium-server-standalone-4.0.0-alpha-2.jar (or whatever is the latest ‘selenium-server-standalone’ file)\nGo to https://github.com/mozilla/geckodriver\nDownload the latest Mozilla geckodriver release, and place in same directory as the jar file\nRunning Selenium Webdriver\nAt the terminal, first cd to the directory where your two new files are saved, then run:\n\njava -jar selenium-server-standalone-4.0.0-alpha-2.jar\n\nThe selenium server must be up and running before attempting to execute the R code below.\nRSelenium quickstart code\n\n\nlibrary(RSelenium)\nlibrary(keyring)\nlibrary(rvest)\nlibrary(magrittr)\n\n# Start Selenium Session\nremDr <- remoteDriver(\n  remoteServerAddr = \"localhost\",\n  port = 4444L,\n  browserName = \"firefox\"\n)\n\nremDr$open()\n\n# Navigate to login page\nremDr$navigate(\"https://website.com/login\")\nSys.sleep(5) # Give page time to load\n\n# Find 'username' element and send 'saved_user' as input\nwebElem1 <- remDr$findElement(using = \"xpath\", \"//input[@name = 'username']\")\nwebElem1$sendKeysToElement(list(key_get(\"saved_user\")))\n\n# Find 'password' element and send 'saved_pass' and 'enter' keystroke as input\nwebElem2 <- remDr$findElement(using = \"xpath\", \"//input[@name = 'password']\")\nwebElem2$sendKeysToElement(list(key_get(\"saved_pass\"), key = \"enter\"))\nSys.sleep(5) # Give page time to load\n\n# Navigate to desired page and download source\nremDr$navigate(\"https://website.com/somepage\")\nSys.sleep(5) # Give page time to load\nhtml <- remDr$getPageSource()[[1]] %>% read_html()\n\n# Use further rvest commands to extract required data\n# ...\n\n# End Selenium Session\nremDr$close()\n\n\n\nCustomise the URLs as required.\nCustomise the xpath to locate the desired input fields as they are actually named on your site.\n‘saved_user’ and ‘saved_pass’ are values already stored using the keyring package and retrieved here using the ‘key_get’ command. It is never a good idea to store plain text credentials in an R script.\nReference\nBasic vignette: https://docs.ropensci.org/RSelenium/articles/basics.html\n\n\n\n",
    "preview": "posts/03-rselenium/rselenium_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:39:42+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/02-resources/",
    "title": "Resources for global sustainability",
    "description": "A compendium",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-02",
    "categories": [
      "Resources",
      "Sustainability"
    ],
    "contents": "\n\nContents\nStockholm Resilience Center\nSvalbard Global Seed Vault\nThe National Academies of Sciences, Engineering, and Medicine\nOpenlearn, The Open University\nTED\n\n\n\n\n\nDawn over Shikokuchuo\nStockholm Resilience Center\nSustainability science for biosphere stewardship, Stockholm University\nVideo: Our future in the Anthropocene biosphere\n\n\nSvalbard Global Seed Vault\nSafeguarding Seeds for the Future\nEstablished and funded by the Norwegian Ministry of Agriculture and Food.\nProvides safe, free and long-term storage of seed duplicates from all genebanks and nations participating in the global community’s joint effort to ensure the world’s future food supply.\nThe facility serves a humanitarian purpose and is part of the international system for conserving plant genetic diversity guided by the UN organisation for Food and Agriculture (FAO).\nhttps://www.seedvault.no/\nThe National Academies of Sciences, Engineering, and Medicine\nMore than 100 leading scientists including many Nobel Prize winners issued a statement following two days of scientific deliberations at the first Nobel Prize Summit, 26-28 April 2021.\nExcerpts from the statement:\n\nGlobal heating and habitat loss amount to nothing less than a vast and\nuncontrolled experiment on Earth’s life-support system.\n\nTime is running out to prevent irreversible changes.\n\nThe remaining carbon budget for a 67% probability of not exceeding 1.5°C global\nwarming will be exhausted before 2030. \n\nGlobal sustainability offers the only viable path to human safety, equity,\nhealth, and progress.\n\nHumanity is waking up late to the challenges and opportunities of active\nplanetary stewardship. But we *are* waking up.\n\nFull text: https://www.nationalacademies.org/news/2021/04/nobel-prize-laureates-and-other-experts-issue-urgent-call-for-action-after-our-planet-our-future-summit\nOpenlearn, The Open University\nGreta Thunberg: A Year to change the World\nEncounters with some of the world’s leading scientists and economists allow the series to examine what the latest science tells us about what can be done to avert the worst effects of climate change.\nhttps://www.open.edu/openlearn/tv-radio-events/tv/greta-thunberg-year-change-the-world\nTED\nStephen Hawking\nQuestioning the universe  TED February 2008\n\n\n\n\n\n\n\nTranscript: 09:06 | Stephen Hawking: I think it quite likely that we are the only civilization within several hundred light years; otherwise we would have heard radio waves. The alternative is that civilizations don’t last very long, but destroy themselves.\n\nKatharine Hayhoe\nThe most important thing you can do to fight climate change: talk about it  TEDWomen November 2018, also featured at useR!2021 the R conference July 2021\n\n\n\n\n\n\n\n\n\n",
    "preview": "posts/02-resources/resources_files/figure-html5/index-1.png",
    "last_modified": "2022-02-13T15:39:21+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/01-authenticating/",
    "title": "Authenticating photography using cryptographic hashing",
    "description": "A proof of concept using R",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-01",
    "categories": [
      "Photography",
      "Cryptography"
    ],
    "contents": "\n\nContents\nReproducible R code and authentification\nAs applied to a digital photography workflow\n\nReproducible R code and authentification\nR is an open source programming language popular amongst statisticians and data scientists. The power of the R framework is enhanced through the tens of thousands of packages contributed by the open source community that extends and enhances R. 1\nThe below code is a simple proof of concept of using cryptographic hashing as a method for authentification of original photographic files. The code simply retrieves the files in a certain folder and loads them into R using the imager 2 package and plots them, here on the page, but it could easily be another output device such as writing to jpeg or pdf. At the same time, the original file is run through a sha256 cryptographic hash from the openssl 3 package. sha256 is a one-way algorithm that takes an input and generates a hexadecimal sequence 64 long. As the input file may be arbitrarily large, it can easily be seen that the information loss in arriving at the hash precludes the possibility of going in the other direction i.e. retrieving the original data from the hash. The properties of the hashing algorithm include that small changes to the input file can result in completely different hash values. The chances of collision i.e. two different data files generating the exact same hash is vanishingly small.\n\n\nphotos <- file.path(\"_images\", list.files(\"_images\"))\ndevelop <- function(x) {\n  plot(imager::load.image(x), axes = FALSE)\n  paste0(openssl::sha256(file(x)))\n}\npar(mar = c(0, 0, 0, 0))\ndata.frame(sha256 = do.call(rbind, lapply(photos, develop)))\n\n\n\n                                                            sha256\n1 cba0450d38b74f2585868d2aa026a96de735a8f73a54889366d62bbdfdcc8661\n2 a63b055e11765cf36fa065be413b0bb5deb89d6cfba0c9feac7b9946e9c76ece\n3 f06eb35ea2bea1166e3147d30a846069fa5fd969717185d3e27821cea9257999\n4 0e6cc2bf63313153c6f3aa3206a0dc1d3eb41e6a5a570b48ea5021e437672f99\n\n\nNote: sha256 hashes are of the original files. Saving and hashing the images on this page would produce completely different hashes.\nThe output image along with the sha256 hash of the original can then be published together. The photographer is then able to freely share their work, which does not then need to be downsized, degraded or watermarked, as long as the data of the original file has undergone some form of transformation (that is not trivially reversible) to produce the output. The hash is the proof of authenticity of the original, which only the original artist possesses.\nTo prove authorship, the artist just needs to run the above function again, which would produce the same output and same hash values, and is an example of the benefits of reproducibility in writing R code.\nAs applied to a digital photography workflow\nEquivalent to the example demonstrated here, the workflow of digital photographers is often to take a RAW camera file, and perform edits using photo processing software 4, before generating an output. Software generally keeps the RAW file intact as a form of “digital negative”, but adds the edits in a layer stored separately either as a “sidecar” file or in a database etc. depending on the software. Photographers often take the output and store a best quality version as their “master”.\nOur approach would differ in treating the RAW file as the “original”, which allows a high-quality output to then be published along with the sha256 of the RAW file. The artist retains the RAW file, along with the sidecar file and software that generates the output, as proof of authorship. This works of course only where the artist can ensure reproducibility of the output, and using open source software where the edits are stored transparently in a human-readable format would afford greater confidence in such a workflow.\n\nThe largest listing of packages may be found at The Comprehensive R Archive Network: https://cloud.r-project.org/↩︎\nimager R package: https://dahtah.github.io/imager/↩︎\nopenssl R package: https://github.com/jeroen/openssl↩︎\nA popular example of such photo-editing software is the open source Darktable https://www.darktable.org/↩︎\n",
    "preview": "posts/01-authenticating/authenticating_files/figure-html5/index-1.png",
    "last_modified": "2022-02-14T22:50:38+00:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]

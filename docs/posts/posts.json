[
  {
    "path": "posts/10-combinations/",
    "title": "Combinations using expand.grid",
    "description": "A faster way to generate combinations for mapply and vapply",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-06-17",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nIntroduction\nexpand.grid\nichimoku::duplicate\nBenchmarking the results\nUse case: mapply and vapply\n\n\n\n                                                            sha256\n1 96e41b3b0fa827b7c9c1f4a7765667064026f9448a78327415264112f7f54dbe\n\n\nShikokuchuo\nIntroduction\nIt seems that there is no base R function to generate exhaustive combinations of two identical vectors, sometimes desired as function inputs to mapply/vapply. The ‘combn’ function from the ‘utils’ package is required.\n‘combn’ outputs the unique set of combinations, so for the example below where the first 8 letters of the alphabet are used, the combination {a, b} appears, but {b, a} does not. Similarly the cases where the two elements are identical such as {a, a} also do not feature. It can be seen that there are 28 (or 8 choose 2) unique combinations for the vector of length 8.\n\n\nx <- letters[1:8]\nxlen <- length(x)\n\ncombn <- utils::combn(x, 2)\ncombn\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n[1,] \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"b\"  \"b\"  \"b\"   \"b\"   \"b\"  \n[2,] \"b\"  \"c\"  \"d\"  \"e\"  \"f\"  \"g\"  \"h\"  \"c\"  \"d\"  \"e\"   \"f\"   \"g\"  \n     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\n[1,] \"b\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"d\"   \"d\"   \"d\"   \"d\"  \n[2,] \"h\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"e\"   \"f\"   \"g\"   \"h\"  \n     [,23] [,24] [,25] [,26] [,27] [,28]\n[1,] \"e\"   \"e\"   \"e\"   \"f\"   \"f\"   \"g\"  \n[2,] \"f\"   \"g\"   \"h\"   \"g\"   \"h\"   \"h\"  \n\nexpand.grid\n‘expand.grid’ from the base package is a useful function in its own right, most well-known perhaps for its use in generating hyperparameter tuning grids in machine learning models.\n‘expand.grid’ produces a data frame in columns rather than a matrix in rows like ‘combn’. Hence just for demonstration purposes to compare like-for-like, a bit of manipulation is done below to make the output exactly the same format. In real world usage the output of expand.grid can just be used ‘as is’.\n\n\ngrid <- expand.grid(x, x, KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE)\ngrid <- t(as.matrix(grid))\ngrid <- rbind(grid[2,], grid[1,])\nrownames(grid) <- NULL\ngrid\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n[1,] \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"b\"  \"b\"   \"b\"   \"b\"  \n[2,] \"a\"  \"b\"  \"c\"  \"d\"  \"e\"  \"f\"  \"g\"  \"h\"  \"a\"  \"b\"   \"c\"   \"d\"  \n     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\n[1,] \"b\"   \"b\"   \"b\"   \"b\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"  \n[2,] \"e\"   \"f\"   \"g\"   \"h\"   \"a\"   \"b\"   \"c\"   \"d\"   \"e\"   \"f\"  \n     [,23] [,24] [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32]\n[1,] \"c\"   \"c\"   \"d\"   \"d\"   \"d\"   \"d\"   \"d\"   \"d\"   \"d\"   \"d\"  \n[2,] \"g\"   \"h\"   \"a\"   \"b\"   \"c\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"  \n     [,33] [,34] [,35] [,36] [,37] [,38] [,39] [,40] [,41] [,42]\n[1,] \"e\"   \"e\"   \"e\"   \"e\"   \"e\"   \"e\"   \"e\"   \"e\"   \"f\"   \"f\"  \n[2,] \"a\"   \"b\"   \"c\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"a\"   \"b\"  \n     [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] [,51] [,52]\n[1,] \"f\"   \"f\"   \"f\"   \"f\"   \"f\"   \"f\"   \"g\"   \"g\"   \"g\"   \"g\"  \n[2,] \"c\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"a\"   \"b\"   \"c\"   \"d\"  \n     [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n[1,] \"g\"   \"g\"   \"g\"   \"g\"   \"h\"   \"h\"   \"h\"   \"h\"   \"h\"   \"h\"  \n[2,] \"e\"   \"f\"   \"g\"   \"h\"   \"a\"   \"b\"   \"c\"   \"d\"   \"e\"   \"f\"  \n     [,63] [,64]\n[1,] \"h\"   \"h\"  \n[2,] \"g\"   \"h\"  \n\nIt can be seen that the output of ‘expand.grid’ is simply all combinations, of which there are 8^2 = 64 in total.\nichimoku::duplicate\nSo how to get from the output of ‘expand.grid’ to that of ‘combn’? Well, with the help of a simple algorithm, which has been coded into the ‘duplicate’ function from the ‘ichimoku’ package, expressly for this purpose.\nFrom the function documentation: ‘create a vector of element positions of duplicates in the output of expand.grid on 2 identical vectors’.\nFeel free to inspect the code behind the function, but it is simply a case of codifying the sequence of duplicates into a formula.\nUsing the function as per the below, ‘grid1’ contains all unique combinations and also those where the two elements are identical. This is sometimes the desired output if two of the same elements is still considered a unique combination, and simply that the order does not matter.\n\n\nlibrary(ichimoku)\n\ngrid1 <- grid[, -duplicate(xlen)]\ngrid1\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n[1,] \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"b\"  \"b\"   \"b\"   \"b\"  \n[2,] \"a\"  \"b\"  \"c\"  \"d\"  \"e\"  \"f\"  \"g\"  \"h\"  \"b\"  \"c\"   \"d\"   \"e\"  \n     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\n[1,] \"b\"   \"b\"   \"b\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"d\"  \n[2,] \"f\"   \"g\"   \"h\"   \"c\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"d\"  \n     [,23] [,24] [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32]\n[1,] \"d\"   \"d\"   \"d\"   \"d\"   \"e\"   \"e\"   \"e\"   \"e\"   \"f\"   \"f\"  \n[2,] \"e\"   \"f\"   \"g\"   \"h\"   \"e\"   \"f\"   \"g\"   \"h\"   \"f\"   \"g\"  \n     [,33] [,34] [,35] [,36]\n[1,] \"f\"   \"g\"   \"g\"   \"h\"  \n[2,] \"h\"   \"g\"   \"h\"   \"h\"  \n\nIf the ‘identical = TRUE’ argument is set for ‘duplicate’, identical elements are also removed. ‘grid2’ should then be the same as ‘combn’ obtained above.\nIndeed it can be seen that both ‘identical’ and ‘all.equal’ return TRUE.\n\n\ngrid2 <- grid[, -duplicate(xlen, identical = TRUE)]\ngrid2\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n[1,] \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"b\"  \"b\"  \"b\"   \"b\"   \"b\"  \n[2,] \"b\"  \"c\"  \"d\"  \"e\"  \"f\"  \"g\"  \"h\"  \"c\"  \"d\"  \"e\"   \"f\"   \"g\"  \n     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\n[1,] \"b\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"d\"   \"d\"   \"d\"   \"d\"  \n[2,] \"h\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"e\"   \"f\"   \"g\"   \"h\"  \n     [,23] [,24] [,25] [,26] [,27] [,28]\n[1,] \"e\"   \"e\"   \"e\"   \"f\"   \"f\"   \"g\"  \n[2,] \"f\"   \"g\"   \"h\"   \"g\"   \"h\"   \"h\"  \n\nidentical(combn, grid2)\n\n\n[1] TRUE\n\nall.equal(combn, grid2)\n\n\n[1] TRUE\n\nBenchmarking the results\n‘Microbenchmark’ can be used to benchmark the performance, where it is usual practice to compare median values.\nFor small vector lengths, expand.grid is not as performant. This is somewhat to be expected given the overhead of working with data frames rather than matrices. However the absolute times are also small so any difference would not matter as much.\nWhen the vector length reaches 16, the custom algorithm using expand.grid/duplicate starts to outperform.\nBy the time the vector length reaches 1,000, this implies total unique combinations of 499,500 and the custom algorithm is already over 7x faster.\nIt should be noted that the custom algorithm is tailored for the special case of combn(x, m) where m = 2 and that is most likely why there can be such an outperformance.\n\n\nfn_combn <- function(x) {\n  utils::combn(x, 2)\n}\n\nfn_grid <- function(x) {\n  expand.grid(x, x, KEEP.OUT.ATTRS = FALSE,\n              stringsAsFactors = FALSE)[-duplicate(length(x), identical = TRUE), ]\n}\n\nmicrobenchmark::microbenchmark(fn_combn(1:16), fn_grid(1:16))\n\n\nUnit: microseconds\n           expr    min     lq     mean  median      uq      max neval\n fn_combn(1:16) 55.549 57.146 70.16476 59.4785 62.8215  722.054   100\n  fn_grid(1:16) 52.158 55.204 81.48794 57.4825 61.8935 1932.823   100\n\nmicrobenchmark::microbenchmark(fn_combn(1:1000), fn_grid(1:1000))\n\n\nUnit: milliseconds\n             expr       min        lq      mean    median        uq\n fn_combn(1:1000) 200.44342 264.46170 263.43520 269.72900 273.17069\n  fn_grid(1:1000)  27.39799  36.71321  40.75667  38.29204  39.91588\n       max neval\n 330.84411   100\n  97.69563   100\n\nUse case: mapply and vapply\nThis type of output is suitable for feeding into functions such as ‘mapply’ or ‘vapply’.\nA standard use for mapply is when multiple arguments have to be mapped into a function. Here ‘simplify = FALSE’ is set to have mapply return a list, and fed into ‘do.call’ with ‘c’ to create a vector. This is a safer and more performant method to create a vector than relying on the built-in simplification.\n\n\ndo.call(c, mapply(function(x, y) paste0(x, \"&\", y), \n                  grid2[1, ], grid2[2, ],\n                  SIMPLIFY = FALSE, USE.NAMES = FALSE))\n\n\n [1] \"a&b\" \"a&c\" \"a&d\" \"a&e\" \"a&f\" \"a&g\" \"a&h\" \"b&c\" \"b&d\" \"b&e\" \"b&f\"\n[12] \"b&g\" \"b&h\" \"c&d\" \"c&e\" \"c&f\" \"c&g\" \"c&h\" \"d&e\" \"d&f\" \"d&g\" \"d&h\"\n[23] \"e&f\" \"e&g\" \"e&h\" \"f&g\" \"f&h\" \"g&h\"\n\nAn equivalent example using ‘vapply’ is given below. ‘vapply’ is also a safe choice for programming as an output template is explicitly specified, here ‘character(1L)’, hence the returned values are all expected to be of type ‘character’ of length ‘1’ otherwise an error is thrown.\n\n\nvapply(seq_along(grid2[1L, ]),\n       function(i) paste0(grid2[1L, i], \"&\", grid2[2L, i]),\n       character(1L), USE.NAMES = FALSE)\n\n\n [1] \"a&b\" \"a&c\" \"a&d\" \"a&e\" \"a&f\" \"a&g\" \"a&h\" \"b&c\" \"b&d\" \"b&e\" \"b&f\"\n[12] \"b&g\" \"b&h\" \"c&d\" \"c&e\" \"c&f\" \"c&g\" \"c&h\" \"d&e\" \"d&f\" \"d&g\" \"d&h\"\n[23] \"e&f\" \"e&g\" \"e&h\" \"f&g\" \"f&h\" \"g&h\"\n\n\n\n\n",
    "preview": "posts/10-combinations/combinations_files/figure-html5/index-1.png",
    "last_modified": "2021-06-17T22:15:33+01:00",
    "input_file": "combinations.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/09-docall-lapply/",
    "title": "do.call / lapply",
    "description": "A distinctive coding style for R",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-28",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nUse case\nSetup\nLoop\ndo.call / lapply\nTidy data output\n\n\n\n                                                            sha256\n1 2074954df14cc65b017b3e9d4b291353151672d450f2b623acc2a5d253767e42\n\n\nShikokuchuo\nUse case\nThe use of the do.call / lapply combination is a powerful way to leverage functional programming in R. In short, you write a function that performs some actions and apply it to a list of inputs, which can then be fed into a function that combines everything into a single object.\nLet us take an example, where we would like to calculate the ichimoku clouds for a portfolio of stocks, but also preserve the volume data, all in one tidy object.\nSetup\nWe could set it up as per the below:\ntickers: a vector defining the stock symbols in our portfolio\nprocess: a function that generates a row in a data frame or matrix\n\n\nlibrary(ichimoku)\n\ntickers <- c(\"C\", \"MS\", \"JPM\", \"GS\")\n\nprocess <- function(x) {\n  # Use the 'quantmod' package to download pricing data\n  pxdata <- quantmod::getSymbols(x, from = \"2020-04-15\", to = \"2021-05-27\", auto.assign = FALSE)\n  # Extract volume column\n  volume <- pxdata[, grep(\"Volume\", colnames(pxdata))]\n  # Calculate the cloud by calling ichimoku() from the 'ichimoku' package\n  cloud <- ichimoku(pxdata, ticker = x)\n  # Return a list of ticker, ichimoku cloud object, volume data\n  list(x, cloud, volume)\n}\n\n\n\n\nNote: the original pricing data is preserved within the ichimoku object.\nWe now want to apply our function to each element of ‘tickers’ in turn, and then for the results to be combined.\nLoop\nOne way to achieve this would be to iterate over ‘tickers’ using a loop:\n\n\n# Define a list to contain the loop output, specifying the length in advance as good practice\nout <- vector(mode = \"list\", length = length(tickers))\n\n# Loop over each element in 'tickers' and save in pre-defined list\nfor(i in seq_along(tickers)) out[[i]] <- process(tickers[i])\n\n# Create output matrix by calling rbind on each element of the list\nportfolio <- do.call(rbind, out)\n\nportfolio\n\n\n     [,1]  [,2]        [,3]   \n[1,] \"C\"   ichimoku,11 xts,282\n[2,] \"MS\"  ichimoku,11 xts,282\n[3,] \"JPM\" ichimoku,11 xts,282\n[4,] \"GS\"  ichimoku,11 xts,282\n\nThis approach takes 3 lines of code.\nFurthermore, ‘i’ and ‘out’ remain as leftover objects in the global environment.\nSomewhat messy.\ndo.call / lapply\nInstead we can use a do.call / lapply combination to achieve the same result in one line:\n\n\nportfolio <- do.call(rbind, lapply(tickers, process))\n\nportfolio\n\n\n     [,1]  [,2]        [,3]   \n[1,] \"C\"   ichimoku,11 xts,282\n[2,] \"MS\"  ichimoku,11 xts,282\n[3,] \"JPM\" ichimoku,11 xts,282\n[4,] \"GS\"  ichimoku,11 xts,282\n\nThere are also no intermediate objects generated that clutter the global environment.\nTo explain:\nFirst lapply applies to a list or list-like object (‘tickers’), a function (‘process’). lapply always returns a list.\nThis can then be fed into do.call, which calls a function (‘rbind’) on a list of arguments (the output of lapply i.e. the lists returned by ‘process’).\nThe use of do.call / lapply provides for a far more succinct and distinctive coding style.\nTidy data output\n\n\nportfolio\n\n\n     [,1]  [,2]        [,3]   \n[1,] \"C\"   ichimoku,11 xts,282\n[2,] \"MS\"  ichimoku,11 xts,282\n[3,] \"JPM\" ichimoku,11 xts,282\n[4,] \"GS\"  ichimoku,11 xts,282\n\n‘portfolio’ is a tidy matrix with a row for each ticker, and a column for each data type.\nWe can easily access any element of the matrix by specifying its index value, for example the ichimoku cloud for MS by [2,2]:\n\n\nplot(portfolio[2,2][[1]])\n\n\n\n\n\nNote: Each element of the matrix is wrapped as a list so that they are of equal length. To access the underlying object, the ichimoku cloud in this case, we simply extract it using [[1]].\n1\n\nFurther examples: Youngju Nielsen of Sungkyunkwan University uses do.call / lapply to good effect in her course https://www.coursera.org/learn/the-fundamental-of-data-driven-investment/↩︎\n",
    "preview": "posts/09-docall-lapply/docall-lapply_files/figure-html5/index-1.png",
    "last_modified": "2021-06-08T21:19:34+01:00",
    "input_file": "docall-lapply.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/08-ichimoku/",
    "title": "ichimoku",
    "description": "R package for Ichimoku Kinko Hyo cloud charts",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-19",
    "categories": [
      "R",
      "Quantitative Finance"
    ],
    "contents": "\n\nContents\nExample\nInstallation\nPackage site\nIchimoku Kinko Hyo\nInterpretation\nContext\n\n\n\n                                                            sha256\n1 9b787ca60956d571ad9686d55815fcff38fce9d550ccb1310c0b9c11dfa8069e\n\n\nShikokuchuo\nAn implementation in R of the Ichimoku Kinkō Hyō (一目均衡表) charting system, also commonly known as ‘cloud charts’.\nThe technique is a refinement on candlestick charting originating from Japan, now in widespread use in technical analysis worldwide. Translating to ‘one-glance equilibrium chart’, it allows the price action and market structure of financial securities to be determined ‘at-a-glance’.\nExample\nFor both publication-ready and fully-interactive charts for analysis.\nSimply ichimoku() and plot().\n\n\nlibrary(ichimoku)\nTKR <- sample_ohlc_data\n\ncloud <- ichimoku(TKR)\n\nplot(cloud, from = \"2020-05-01\", to = \"2020-12-03\")\n\n\n\nplot(cloud, from = \"2020-05-01\", to = \"2020-12-03\", theme = \"dark\")\n\n\n\n\nInstallation\nInstall the released version of ichimoku from CRAN:\ninstall.packages(\"ichimoku\")\nOr install the development version of ichimoku from GitHub with:\ndevtools::install_github(\"shikokuchuo/ichimoku\")\nPackage site\nHosted ourselves at: https://shikokuchuo.net/ichimoku/\nIchimoku Kinko Hyo\nThe system consists of the following chart lines added to a candlestick chart:\nTenkan-sen (転換線): [conversion line] the mid-point of the highest high and lowest low for the past 9 periods.\nKijun-sen (基準線): [base line] the mid-point of the highest high and lowest low for the past 26 periods.\nSenkou span A (先行帶A): [leading span A] the mid-point of Tenkan-sen and Kijun-sen plotted ahead 26 periods.\nSenkou span B (先行帶B): [leading span B] the mid-point of the highest high and lowest low for the past 52 periods, plotted ahead 26 periods.\nChikou span (遲行帶): [lagging span] the current closing price plotted 26 periods behind.\nThe kumo (雲) [cloud] is the area between Senkou span A and Senkou span B (usually shaded on a chart).\nInterpretation\nIchimoku Kinkō Hyō translates roughly to ‘one-glance equilibrium chart’. It is designed to allow the price action and market structure of financial securities to be determined ‘at-a-glance’ in a highly visual fashion.\nFor example in a strongly upwards-trending market, the candlesticks will be above the Tenkan-sen, which will be above the Kijun-sen, which will be above the cloud, and the Chikou span may not have anything above it.\nThe lines and the cloud represent dynamic support and resistance zones relative to the price candles. Generally the thicker the cloud, the tougher the support/resistance. In our previous example, if the price now reverts downwards, it can expect support first at the Kijun-sen, then the Tenkan-sen and finally the cloud itself.\nMore subtle interpretations involve the Chikou span in particular and its action in relation to the cloud lines as well as the candles.\nContext\nIchimoku analysis is the latest evolution in refining candlestick charting techniques, which also originated from Japan in the 18th century. Actually developed during the mid-20th century, it gained popularity especially from the late 1990s onwards, and is now used on trading floors worldwide.\nThe time periods have traditionally been calculated as 9, 26 and 52 based on manual data analysis performed in Japan in a pre-computer age where there was a 6-day working week resulting in 26 average trading days in a month. Although this bears little relevance to the current day, the use of these time periods has persisted as an ‘industry norm’ or ‘accepted practice’.\nTo use other periods would be meaningless in a sense as everyone uses these parameters and ‘market psychology’ can and often does create its own realities, independent of any fundamentals. However, there is no reason for the technique not to evolve, and to reflect changing trading realities perhaps other parameters will become more relevant in the collective psychology.\nFinally, the use originated with daily candlesticks, and the most valid interpretation remains for daily data. However, it is equally used today for both shorter intra-day, e.g. 4-hour or hourly, and longer, e.g. weekly or monthly, charts.\n\n\n\n",
    "preview": "posts/08-ichimoku/ichimoku_files/figure-html5/index-1.png",
    "last_modified": "2021-06-08T21:42:17+01:00",
    "input_file": "ichimoku.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/07-learning/",
    "title": "Resources for learning",
    "description": "A curated selection of online MOOCs",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-14",
    "categories": [
      "Resources",
      "Learning"
    ],
    "contents": "\n\nContents\nCoursera Specializations\n\n\n\n                                                            sha256\n1 deebda75318682cfdc1bb7fe67d313e387a27754afc8edabf60d4fd812495dfb\n\n\nShikokuchuo  Iyo Mishima station\nCoursera Specializations\n\n\nlibrary(magrittr)\ntibble::tribble(\n  ~Institution, ~`Course or Specialization`, ~URL,\n  \"Duke University\", \"Statistics with R\", \"https://www.coursera.org/specializations/statistics\",\n  \"Duke University\", \"Entrepreneurial Finance: Strategy and Innovation\", \"https://www.coursera.org/specializations/entrepreneurial-finance\",\n  \"John Hopkins University\", \"Mastering Software Development in R\", \"https://www.coursera.org/specializations/r\",\n  \"Sung Kyun Kwan University\", \"The Fundamentals of Data Driven Investment\" ,\"https://www.coursera.org/learn/the-fundamental-of-data-driven-investment\"\n) %>%\n  dplyr::mutate(URL = purrr::map_chr(URL, ~paste0(\"<a href='\", .x, \"'>\", .x, \"<\/a>\"))) %>%\n  DT::datatable(escape = FALSE)\n\n\n\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\"],[\"Duke University\",\"Duke University\",\"John Hopkins University\",\"Sung Kyun Kwan University\"],[\"Statistics with R\",\"Entrepreneurial Finance: Strategy and Innovation\",\"Mastering Software Development in R\",\"The Fundamentals of Data Driven Investment\"],[\"<a href='https://www.coursera.org/specializations/statistics'>https://www.coursera.org/specializations/statistics<\\/a>\",\"<a href='https://www.coursera.org/specializations/entrepreneurial-finance'>https://www.coursera.org/specializations/entrepreneurial-finance<\\/a>\",\"<a href='https://www.coursera.org/specializations/r'>https://www.coursera.org/specializations/r<\\/a>\",\"<a href='https://www.coursera.org/learn/the-fundamental-of-data-driven-investment'>https://www.coursera.org/learn/the-fundamental-of-data-driven-investment<\\/a>\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Institution<\\/th>\\n      <th>Course or Specialization<\\/th>\\n      <th>URL<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"columnDefs\":[{\"orderable\":false,\"targets\":0}]}},\"evals\":[],\"jsHooks\":[]}\n\n\n\n",
    "preview": "posts/07-learning/learning_files/figure-html5/index-1.png",
    "last_modified": "2021-06-08T21:18:04+01:00",
    "input_file": "learning.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/06-datasets/",
    "title": "Datasets",
    "description": "For Econometrics and Machine Learning",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-05",
    "categories": [
      "Resources",
      "Data"
    ],
    "contents": "\n\nContents\nDatasets\n\n\n\n                                                            sha256\n1 1124bc02f0f74585e8f434a918970cf6671530e263eff4f1aa330a2b54c93873\n\n\nShikokuchuo\nDatasets\n\n\nlibrary(magrittr)\ntibble::tribble(\n  ~Source, ~URL, ~Package,\n  \"Fred\", \"https://fred.stlouisfed.org/\", \"Quantmod\",\n  \"Quandl\", \"https://www.quandl.com/\", \"Quandl\",\n  \"Yahoo Finance\", \"https://finance.yahoo.com/\", \"Quantmod\",\n  \"Damodaran NYU Stern\", \"http://people.stern.nyu.edu/adamodar/New_Home_Page/datacurrent.html\", \"\",\n  \"UCI Machine Learning Repository\", \"https://archive.ics.uci.edu/ml/index.php\", \"\",\n  \"Project Gutenberg\", \"https://www.gutenberg.org/\", \"gutenbergr\"\n) %>%\n  dplyr::mutate(URL = purrr::map_chr(URL, ~paste0(\"<a href='\", .x, \"'>\", .x, \"<\/a>\"))) %>%\n  DT::datatable(escape = FALSE)\n\n\n\n{\"x\":{\"filter\":\"none\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],[\"Fred\",\"Quandl\",\"Yahoo Finance\",\"Damodaran NYU Stern\",\"UCI Machine Learning Repository\",\"Project Gutenberg\"],[\"<a href='https://fred.stlouisfed.org/'>https://fred.stlouisfed.org/<\\/a>\",\"<a href='https://www.quandl.com/'>https://www.quandl.com/<\\/a>\",\"<a href='https://finance.yahoo.com/'>https://finance.yahoo.com/<\\/a>\",\"<a href='http://people.stern.nyu.edu/adamodar/New_Home_Page/datacurrent.html'>http://people.stern.nyu.edu/adamodar/New_Home_Page/datacurrent.html<\\/a>\",\"<a href='https://archive.ics.uci.edu/ml/index.php'>https://archive.ics.uci.edu/ml/index.php<\\/a>\",\"<a href='https://www.gutenberg.org/'>https://www.gutenberg.org/<\\/a>\"],[\"Quantmod\",\"Quandl\",\"Quantmod\",\"\",\"\",\"gutenbergr\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Source<\\/th>\\n      <th>URL<\\/th>\\n      <th>Package<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"columnDefs\":[{\"orderable\":false,\"targets\":0}]}},\"evals\":[],\"jsHooks\":[]}\n\n\n\n",
    "preview": "posts/06-datasets/datasets_files/figure-html5/index-1.png",
    "last_modified": "2021-06-08T21:15:30+01:00",
    "input_file": "datasets.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/04-distill/",
    "title": "Distill for R Markdown",
    "description": "Web publishing optimised for scientific and technical communication",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-04",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nCreated using Distill\nKey advantages\nInstallation\nDistill blog hosted on Github Pages step-by-step instructions\nReferences\n\n\n\n                                                            sha256\n1 db79682f8bee39d7ed9231200fd076ebed92a4471a9f3ce611d0a5a28bb984a3\n\n\nShikokuchuo\nCreated using Distill\nThis website was created using Distill for R Markdown, a web publishing format optimised for scientific and technical communication.\nKey advantages\nR markdown to run R code (and all the possibility that brings)\nUse markdown / html interchangeably\nNo dependency on Hugo or Jekyll, so no lock-in or need to maintain those stacks\nOut-of-the-box support for mobile\nClean and attractive defaults\nMainly “just works”\nInstallation\nInstall release version of Distill from CRAN:\n\n\ninstall.packages(\"distill\")\n\n\n\nDistill blog hosted on Github Pages step-by-step instructions\nCreate a new blog at /blog of your current working directory in R:\n\n\ndistill::create_blog(dir = \"blog\", title = \"My New Blog\", gh_pages = TRUE)\n\n\n\nMake some inital changes to _site.yml. Select the ‘build’ tab in RStudio and hit ‘Build Website’. This will generate the website. Note: building the website does not generate blog posts. Each time the website is re-built, only the .Rmd files in the base directory will be automatically re-generated.\nModify the yaml front matter and content of the example blog post. Then hit ‘Knit’ in RStudio to generate the post. Note: after every change made to posts or after creating a new post, you must knit each post separately. The listings page is then automatically updated.\nCreate README.md and CNAME in /blog for your Github repository.\nREADME.md is optional but usual practice. CNAME is a text file containing the domain name if using a custom domain.\n\nCreate a new repository at Github.\nTo set up git and add your new repository as a remote, bring up the command line, cd to your /blog directory and:\n\ngit init\ngit add .\ngit commit -m \"initial commit\"\ngit branch -M main\ngit remote add origin git@github.com:username/nameofnew.git\ngit push -u origin main\n\n\nReplace ‘username/nameofnew.git’ as appropriate.\nAt Github, under your new repository, go to Settings >> Pages, set your source branch to ‘main’, and folder to ‘docs’. Optionally tick ‘Enforce HTTPS’.  Your custom domain name should be configured automatically if you have previously set up your DNS settings to point to Github’s servers.\nCongratulations, your new website should now be online!\nReferences\nThe Distill Reference: https://rstudio.github.io/distill/\nThe Definitive R Markdown Guide: https://bookdown.org/yihui/rmarkdown/\n\n\n\n",
    "preview": "posts/04-distill/distill_files/figure-html5/index-1.png",
    "last_modified": "2021-06-08T21:14:16+01:00",
    "input_file": "distill.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/05-ghactions/",
    "title": "Github Actions with R",
    "description": "Deploy and automate your code to the cloud",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-04",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nGithub Actions with R\nReference\n\n\n\n                                                            sha256\n1 6f5b37d9b73dcd70f3c8b68eabbe00c4a709f2a3e694d964121af145105f1655\n\n\nShikokuchuo\nGithub Actions with R\nSet up a cron job to run your R scripts at specified times.\nEnabled with a simple yaml configuration file.\nSave the following as main.yml in .github/workflows of your Github repository:\n\nname: Raction\non:\n  schedule:\n    - cron: '30 22 * * 1-5'\njobs:\n  render:\n    runs-on: windows-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up R\n        uses: r-lib/actions/setup-r@v1\n      - name: Install dependencies\n        run: |\n          install.packages(c(\"magrittr\", \"purrr\"), type = \"win.binary\")\n        shell: Rscript {0}\n      - name: Script\n        run: Rscript nameofscript.R\n      - name: Commit files\n        run: |\n          git config --local user.name github-actions\n          git config --local user.email \"actions@github.com\"\n          git add output/*\n          git commit -am \"commit on $(date)\"\n          git push origin main\n        env:\n          REPO_KEY: ${{secrets.GITHUB_TOKEN}}\n          username: github-actions\n\nThis example cron job runs every Mon-Fri at 22.30.\nCustomize your R packages to install.\nMake sure to change nameofscript.R to your actual script name.\nAssumes your script writes files to the ‘output’ directory, change if necessary.\nAssumes your repository branch is ‘main’, change if necessary.\nNote that this script is run on a Windows VM using Windows R binary packages. This is currently much faster than building a lot of dependencies on Linux (which is also prone to failure).\nReference\nThe Github Actions with R reference: https://orchid00.github.io/actions_sandbox/\n\n\n\n",
    "preview": "posts/05-ghactions/ghactions_files/figure-html5/index-1.png",
    "last_modified": "2021-06-08T21:14:33+01:00",
    "input_file": "ghactions.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/03-rselenium/",
    "title": "R | Selenium",
    "description": "Programmatically drive a web browser",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-03",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nUse case\nInitial setup\nRunning Selenium Webdriver\nRSelenium quickstart code\nReference\n\n\n\n                                                            sha256\n1 809e2e2a3967742faea6f9e11e0a4c533511f9710ac41812dcbcae3c78913cac\n\n\nShikokuchuo\nUse case\nWhenever you need to programmatically drive a web browser.\nMost often:\nto scrape information behind a login screen\nwhen the http server does not return a simple html document\nInitial setup\nPrerequisites: JRE or JDK installed on your system, Mozilla Firefox\nInstall the RSelenium package from CRAN:\n\n\ninstall.packages(\"RSelenium\")\n\n\n\nGo to https://selenium-release.storage.googleapis.com/index.html\nDownload selenium-server-standalone-4.0.0-alpha-2.jar (or whatever is the latest ‘selenium-server-standalone’ file)\nGo to https://github.com/mozilla/geckodriver\nDownload the latest Mozilla geckodriver release, and place in same directory as the jar file\nRunning Selenium Webdriver\nAt the terminal, first cd to the directory where your two new files are saved, then run:\n\njava -jar selenium-server-standalone-4.0.0-alpha-2.jar\n\nThe selenium server must be up and running before attempting to execute the R code below.\nRSelenium quickstart code\n\n\nlibrary(RSelenium)\nlibrary(keyring)\nlibrary(rvest)\nlibrary(magrittr)\n\n# Start Selenium Session\nremDr <- remoteDriver(\n  remoteServerAddr = \"localhost\",\n  port = 4444L,\n  browserName = \"firefox\"\n)\n\nremDr$open()\n\n# Navigate to login page\nremDr$navigate(\"https://website.com/login\")\nSys.sleep(5) # Give page time to load\n\n# Find 'username' element and send 'saved_user' as input\nwebElem1 <- remDr$findElement(using = \"xpath\", \"//input[@name = 'username']\")\nwebElem1$sendKeysToElement(list(key_get(\"saved_user\")))\n\n# Find 'password' element and send 'saved_pass' and 'enter' keystroke as input\nwebElem2 <- remDr$findElement(using = \"xpath\", \"//input[@name = 'password']\")\nwebElem2$sendKeysToElement(list(key_get(\"saved_pass\"), key = \"enter\"))\nSys.sleep(5) # Give page time to load\n\n# Navigate to desired page and download source\nremDr$navigate(\"https://website.com/somepage\")\nSys.sleep(5) # Give page time to load\nhtml <- remDr$getPageSource()[[1]] %>% read_html()\n\n# Use further rvest commands to extract required data\n# ...\n\n# End Selenium Session\nremDr$close()\n\n\n\nCustomise the URLs as required.\nCustomise the xpath to locate the desired input fields as they are actually named on your site.\n‘saved_user’ and ‘saved_pass’ are values already stored using the keyring package and retrieved here using the ‘key_get’ command. It is never a good idea to store plain text credentials in an R script.\nReference\nBasic vignette: https://docs.ropensci.org/RSelenium/articles/basics.html\n\n\n\n",
    "preview": "posts/03-rselenium/rselenium_files/figure-html5/index-1.png",
    "last_modified": "2021-06-08T21:14:00+01:00",
    "input_file": "rselenium.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/02-resources/",
    "title": "Resources for global sustainability",
    "description": "A compendium",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-02",
    "categories": [
      "Resources",
      "Sustainability"
    ],
    "contents": "\n\nContents\nStockholm Resilience Center\nSvalbard Global Seed Vault\nThe National Academies of Sciences, Engineering, and Medicine\nOpenlearn, The Open University\nTED\nUI design x data science x climate change\n\n\n\n                                                            sha256\n1 3018cd1a5f671835e3116c2e2c6f937cf335b630cecc7de5d59b4059cff16999\n\n\nDawn over Shikokuchuo\nStockholm Resilience Center\nSustainability science for biosphere stewardship, Stockholm University\nVideo: Our future in the Anthropocene biosphere\n\n\nSvalbard Global Seed Vault\nSafeguarding Seeds for the Future\nEstablished and funded by the Norwegian Ministry of Agriculture and Food.\nProvides safe, free and long-term storage of seed duplicates from all genebanks and nations participating in the global community’s joint effort to ensure the world’s future food supply.\nThe facility serves a humanitarian purpose and is part of the international system for conserving plant genetic diversity guided by the UN organisation for Food and Agriculture (FAO).\nhttps://www.seedvault.no/\nThe National Academies of Sciences, Engineering, and Medicine\nMore than 100 leading scientists including many Nobel Prize winners issued a statement following two days of scientific deliberations at the first Nobel Prize Summit, 26-28 April 2021.\nExcerpts from the statement:\n\nGlobal heating and habitat loss amount to nothing less than a vast and\nuncontrolled experiment on Earth’s life-support system.\n\nTime is running out to prevent irreversible changes.\n\nThe remaining carbon budget for a 67% probability of not exceeding 1.5°C global\nwarming will be exhausted before 2030. \n\nGlobal sustainability offers the only viable path to human safety, equity,\nhealth, and progress.\n\nHumanity is waking up late to the challenges and opportunities of active\nplanetary stewardship. But we *are* waking up.\n\nFull text: https://www.nationalacademies.org/news/2021/04/nobel-prize-laureates-and-other-experts-issue-urgent-call-for-action-after-our-planet-our-future-summit\nOpenlearn, The Open University\nGreta Thunberg: A Year to change the World\nEncounters with some of the world’s leading scientists and economists allow the series to examine what the latest science tells us about what can be done to avert the worst effects of climate change.\nhttps://www.open.edu/openlearn/tv-radio-events/tv/greta-thunberg-year-change-the-world\nTED\nStephen Hawking Questioning the universe  TED February 2008\n\n\n\n\n\n\n\nTranscript: 09:06 | Stephen Hawking: I think it quite likely that we are the only civilization within several hundred light years; otherwise we would have heard radio waves. The alternative is that civilizations don’t last very long, but destroy themselves.\nUI design x data science x climate change\nWhat can a technologist do about climate change?\nBret Victor: A personal view.\nhttp://worrydream.com/ClimateChange/\n\n\n\n",
    "preview": "posts/02-resources/resources_files/figure-html5/index-1.png",
    "last_modified": "2021-06-08T21:13:39+01:00",
    "input_file": "resources.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/01-authenticating/",
    "title": "Authenticating photography using cryptographic hashing",
    "description": "A proof of concept using R",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-01",
    "categories": [
      "Photography",
      "Cryptography"
    ],
    "contents": "\n\nContents\nReproducible R code and authentification\nAs applied to a digital photography workflow\n\nReproducible R code and authentification\nR is an open source programming language popular amongst statisticians and data scientists. The power of the R framework is enhanced through the tens of thousands of packages contributed by the open source community that extends and enhances R. 1\nThe below code is a simple proof of concept of using cryptographic hashing as a method for authentification of original photographic files. The code simply retrieves the files in a certain folder and loads them into R using the imager 2 package and plots them, here on the page, but it could easily be another output device such as writing to jpeg or pdf. At the same time, the original file is run through a sha256 cryptographic hash from the openssl 3 package. sha256 is a one-way algorithm that takes an input and generates a hexadecimal sequence 64 long. As the input file may be arbitrarily large, it can easily be seen that the information loss in arriving at the hash precludes the possibility of going in the other direction i.e. retrieving the original data from the hash. The properties of the hashing algorithm include that small changes to the input file can result in completely different hash values. The chances of collision i.e. two different data files generating the exact same hash is vanishingly small.\n\n\nphotos <- file.path(\"_images\", list.files(\"_images\"))\ndevelop <- function(x) {\n  plot(imager::load.image(x), axes = FALSE)\n  paste0(openssl::sha256(file(x)))\n}\npar(mar = c(0, 0, 0, 0))\ndata.frame(sha256 = do.call(rbind, lapply(photos, develop)))\n\n\n\n                                                            sha256\n1 cba0450d38b74f2585868d2aa026a96de735a8f73a54889366d62bbdfdcc8661\n2 a63b055e11765cf36fa065be413b0bb5deb89d6cfba0c9feac7b9946e9c76ece\n3 f06eb35ea2bea1166e3147d30a846069fa5fd969717185d3e27821cea9257999\n4 0e6cc2bf63313153c6f3aa3206a0dc1d3eb41e6a5a570b48ea5021e437672f99\n\n\nNote: sha256 hashes are of the original files. Saving and hashing the images on this page would produce completely different hashes.\nThe output image along with the sha256 hash of the original can then be published together. The photographer is then able to freely share their work, which does not then need to be downsized, degraded or watermarked, as long as the data of the original file has undergone some form of transformation (that is not trivially reversible) to produce the output. The hash is the proof of authenticity of the original, which only the original artist possesses.\nTo prove authorship, the artist just needs to run the above function again, which would produce the same output and same hash values, and is an example of the benefits of reproducibility in writing R code.\nAs applied to a digital photography workflow\nEquivalent to the example demonstrated here, the workflow of digital photographers is often to take a RAW camera file, and perform edits using photo processing software 4, before generating an output. Software generally keeps the RAW file intact as a form of “digital negative”, but adds the edits in a layer stored separately either as a “sidecar” file or in a database etc. depending on the software. Photographers often take the output and store a best quality version as their “master”.\nOur approach would differ in treating the RAW file as the “original”, which allows a high-quality output to then be published along with the sha256 of the RAW file. The artist retains the RAW file, along with the sidecar file and software that generates the output, as proof of authorship. This works of course only where the artist can ensure reproducibility of the output, and using open source software where the edits are stored transparently in a human-readable format would afford greater confidence in such a workflow.\n\nThe largest listing of packages may be found at The Comprehensive R Archive Network: https://cloud.r-project.org/↩︎\nimager R package: https://dahtah.github.io/imager/↩︎\nopenssl R package: https://github.com/jeroen/openssl↩︎\nA popular example of such photo-editing software is the open source Darktable https://www.darktable.org/↩︎\n",
    "preview": "posts/01-authenticating/authenticating_files/figure-html5/index-1.png",
    "last_modified": "2021-06-08T21:13:00+01:00",
    "input_file": "authenticating.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  }
]

[
  {
    "path": "posts/14-r-on-solaris/",
    "title": "Installing an R Build Environment on Solaris",
    "description": "Run R CMD check or devtools::check() on a local Solaris VM",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-08-23",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nSetup\nBonus\nPower off\n\n\n\n                                                            sha256\n1 6019ae519a7e66506bedd541440c2eb115163b6e0ea4c2b77538bfd64639b669\n\n\nShikokuchuo\nSetup\nThe R-hub solarischeck repository1, provides a full set of instructions by Gábor Csárdi for setting up R on a Solaris system. However, due to the ever-evolving software landscape, the instructions as they stand are no longer likely to produce a working system.\nThis guide builds on and completes the set of instructions so that a full build system can be set up with relative ease, complete with ‘devtools’ installed and ready for package testing on a CRAN-like Solaris environment.\nWhere ‘Instructions’ are mentioned below, they refer to those found at the original solarischeck repository:\nhttps://github.com/r-hub/solarischeck/tree/master/packer.\n[1]\nFollow steps 1-3 of the Instructions, including installing the latest Packer version from its website. The website provides clear guidance on the best installation method - for example, for Ubuntu Linux users, a PPA is provided for a straightforward install process.\n[2]\nFollow step 4 of the Instructions and edit ‘solaris10.json’ to point to the locations of the downloaded Solaris 10 iso and Oracle Developer Studio tar.bz2.\nIn addition, find the following line in ‘solaris10.json’:\n\"iso_checksum_type\": \"sha1\",\nIt appears twice. Delete both of these lines.\n[3]\nOpen up a terminal and cd to where the ‘solaris10.json’ file is located. Execute the following command to create an updated Packer configuration from the json file:\n\npacker hcl2_upgrade solaris10.json\n\nYou should get a confirmation message such as:\nSuccessfully created solaris10.json.pkr.hcl. Exit 0\n[4]\nFollow step 5 of the Instructions and make sure VirtualBox or VMware is installed.\n[5]\nFrom where your solaris10.json is located, execute:\n\npacker build .\n\nThe automated build will now run for a while, with the console showing the commands as they are run.\nAs per step 7 of the Instructions, do not attempt to interact with the VM window. Even if it appears static, processes will be running in the background.\nWait for the build to finish.\n[6]\nComplete the remaining installation steps 8-10 from the Instructions.\nFor those using VirtualBox: you should have a successfully-imported virtual machine at this point. Before launching it, first choose ‘settings’. On the ‘system’ tab feel free to allocate some more base memory (staying within the recommended green band). On the ‘display tab’, similarly allocate some more video memory - this is important otherwise increasing the screen resolution later may fail.\n[7]\nLaunch the virtual machine and log in using the ‘rhub’ account as per the Instructions.\nChoose the Sun Java Desktop Environment (however much you are tempted to use the awesome CDE). Once you arrive at a desktop, right click and set the desired screen resolution. (Here, if not enough video memory was allocated in the previous step you may get a black screen. If you do not get back to a usable dektop, power off the VM and try again.)\n[8]\nOpen a terminal window and install the following packages from openCSW, the Solaris open source software repository, by issuing the following command:\n\nsudo pkgutil -y -i cmake gmake curl libcurl_dev libssh2_dev libssl_dev libxml2_dev libiconv_dev\n\nThese are utilities and system libraries that are required to install the various dependencies of ‘devtools’.\n[19]\n‘libgit2’ is required but not available on openCSW, and hence must be built. In a terminal window, execute the commands in the following instructions by Jeroen Ooms:\nhttps://gist.github.com/jeroen/4f13ff48596b449283ca98af7b95601d\nStart from # Download latest release as we have already installed the dependencies as part of the previous step.\n[10]\nFor the final step, load up a terminal window. Enter the following to set the environment variable:\n\nexport MAKE=gmake\n\nFrom the same terminal window, launch R:\n\nR\n\nAt the R prompt, proceed to install the ‘devtools’ package:\n\n\ninstall.packages(\"devtools\")\n\n\n\nYou will be prompted if you would like to use and create a personal library. Proceed with ‘yes’ both times.\nAll the dependencies of ‘devtools’ will now be downloaded and install will take a while.\nThe installation should complete successfully leaving you with a full R development environment on Solaris.\nBonus\nInstall the last released Firefox build 52.0esr for Solaris - this allows modern websites such as Github to load.\nOpen up a terminal and enter the following:\n\ncd Desktop\n\n# Download file\ncurl -OL https://ftp.mozilla.org/pub/firefox/releases/52.0esr/contrib/solaris_pkgadd/firefox-52.0esr.en-US.solaris-10-fcs-i386-pkg.bz2\n\n# Decompress file\nbzip2 -d firefox-52.0esr.en-US.solaris-10-fcs-i386-pkg.bz2\n\n# Install package\nsudo pkgadd -d ./firefox-52.0esr.en-US.solaris-10-fcs-i386-pkg\n\nRespond ‘yes’ to all install prompts.\nIt does not overwrite the bundled version, so set up a shortcut by right-clicking on the desktop, and select ‘Create Launcher’.\nFor ‘Name’ enter Firefox, for ‘Command’ enter /opt/sfw/lib/firefox/firefox\nDouble-click the new launcher icon on the desktop to bring up Firefox.\nPower off\nTo turn off the VM, open up a terminal window and issue:\n\nsudo poweroff\n\n–\n\nThis article (excluding the photograph) is licensed under CC BY 4.0\n\n\nCopyright, the R Consortium↩︎\n",
    "preview": "posts/14-r-on-solaris/r-on-solaris_files/figure-html5/index-1.png",
    "last_modified": "2021-09-25T15:01:34+01:00",
    "input_file": "r-on-solaris.knit.md",
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/13-reverting/",
    "title": "Reverting Git Commits",
    "description": "Procedure to roll back both local and remote changes",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-08-12",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nReverting Local Git Commits\nReverting Commits Pushed to Remote (e.g. Github)\n\n\n\n                                                            sha256\n1 010e16069f8858640c2bb9af4a2293b720161b71d9d6e1f375c30237ea2b4123\n\n\nShikokuchuo\nReverting Local Git Commits\nYou have made a commit.\nYou discover a mistake or something you left out straight after the commit.\n\ngit reset HEAD~\n\nThis is a soft reset. Your changes are preserved. The commit is removed from the record.\nMake the additional changes you need. Add files. Commit.\nReverting Commits Pushed to Remote (e.g. Github)\nCopy your folder to a backup location.\nThe following is a hard reset, which rolls back to the previous commit. Changes since that commit will be lost. Force push it to the remote.\n\ngit reset HEAD^ --hard\ngit push origin -f\n\nBoth local and remote should now be in sync at the previous commit. You may check with:\n\ngit status\n\nIf you have Github Actions that are triggered by commits, they will be triggered again despite this being a roll-back. So go and stop those runs if necessary.\nNext, if you have another branch such as ‘gh-pages’ that builds automatically on each commit, roll back that branch as well so it keeps in sync. As this branch has been building on the remote, do a git pull to ensure that your local copy is up to date first before resetting.\n\ngit checkout gh-pages\ngit pull\n\ngit reset HEAD^ --hard\ngit push -f origin gh-pages\n\nCheck status. Switch back to ‘main’ branch (substitute whatever branch you were on).\n\ngit status\ngit checkout main\n\nCopy back the files with changes you made previously from your backup location.\nMake the additional changes you need. Add files. Commit.\n\n\n\n",
    "preview": "posts/13-reverting/reverting_files/figure-html5/index-1.png",
    "last_modified": "2021-09-24T13:14:42+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/12-oanda-studio/",
    "title": "R Shiny interface for the OANDA fxTrade API",
    "description": "ichimoku::oanda_studio()",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-07-26",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nAbout ichimoku\nAbout the OANDA fxTrade API\nScreenshots\nOther functions\nLinks and further information\n\n\n\n                                                            sha256\n1 478ec2042047eb285ec4d30177a825af0f8b106a38ac1faeb863c6c1c9df407f\n\n\nShikokuchuo\nAbout ichimoku\nThe ichimoku R package1 provides tools for creating and visualising Ichimoku Kinko Hyo (cloud chart) strategies.\nIt features in the Empirical Finance CRAN Task View, and was selected as one of RStudio’s Top 40 New CRAN Packages for May 2021.\nThe latest version incorporates an interface to the OANDA fxTrade API2.\nAbout the OANDA fxTrade API\nOANDA is an authoritative source of foreign exchange data utilised by both governments and global corporations alike. OANDA offers a few APIs, including its rates for business, but the fxTrade API is perhaps the most comprehensive, built upon its retail and professional trading offering of the same name. Access to the fxTrade API is free but requires registration for a practice/demo account.\nThe API can be used for retrieving historical and live streaming price data for major currencies, metals, commodities, government bonds and stock indices. It is a rich source of financial data with excellent availability, for instance daily OHLC pricing data for major forex pairs from the start of 2005, and data granularity ranging from 5 seconds to monthly.\nFor the total list of over 120 covered instruments please see here.\nScreenshots\nClick on an image to view in full resolution.\nShowcased here is the function oanda_studio(), the implementation in R Shiny. As a Shiny app, the function may be called without specifying any parameters; the full range of options can be selected interactively from within the web interface.\nData is live and updates at the specified refresh rate (default of every 5 secs).\nThe cursor infotip provides an innovative overview of the data directly from the chart (can be turned on or off as desired).\n\n\nlibrary(ichimoku)\n\noanda_studio()\n\n\n\n\nOf course arguments for customisation can also be specified within the call to oanda_studio() itself. Demonstrating some further options below with Soybean futures:\n\n\noanda_studio(\"SOYBN_USD\", granularity = \"M5\", refresh = 10, price = \"B\", theme = \"dark\")\n\n\n\n\nOther functions\nOther functions to access the OANDA fxTrade API are included in the ichimoku package. These are standard R functions for retrieving data in tabular form and charting (not reliant on Shiny), and include:\noanda() to retrieve price data\noanda_stream() to stream a live data feed\noanda_chart() to plot real-time ichimoku cloud charts\nLinks and further information\nichimoku R package site: https://shikokuchuo.net/ichimoku/\nichimoku OANDA fxTrade API vignette: https://shikokuchuo.net/ichimoku/articles/xoanda.html\nOANDA fxTrade API developer website: https://developer.oanda.com/\n\nGao, C. (2021), ichimoku: Visualization and Tools for Ichimoku Kinko Hyo Strategies. R package version 1.0.0, https://CRAN.R-project.org/package=ichimoku.↩︎\n‘OANDA’ and ‘fxTrade’ are trademarks owned by OANDA Corporation, an entity unaffiliated with the ichimoku package.↩︎\n",
    "preview": "posts/12-oanda-studio/oanda-studio_files/figure-html5/index-1.png",
    "last_modified": "2021-09-24T13:14:31+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/11-dataframes/",
    "title": "Efficient R: Performant data.frame constructors",
    "description": "How and when to use an alternative to as.data.frame",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-07-23",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nAbout as.data.frame\nMatrix conversion benchmarking\nxts conversion benchmarking\nWhen to use performant constructors\nWhen to question the use of performant constructors\nWhat is a performant constructor\nFurther information\n\n\n\n                                                            sha256\n1 eb5d71529ab540bc4865c181a1129e03186e0959c76196a9fbc0c2a16c767856\n\n\nShikokuchuo\nAbout as.data.frame\ndata.frame() or as.data.frame() are such ubiquitous functions that we rarely think twice about using them to create dataframes or to convert other objects to dataframes.\nHowever, they are slow. Extremely slow.\nThis is somewhat surprising considering how much they are used, and given that the ‘data.frame’ object is the de facto standard for tabular data in R, for their constructors to be so inefficient.\nHowever this is the direct result of the presence of a lot of error checking and validation code, which is perhaps understandable for something as widely used. You simply don’t know what is going to be thrown at the function and so it needs to try to do its best or fail gracefully.\nBelow, we demonstrate the inefficiencies of as.data.frame() versus efficient ‘data.frame’ constructors from the ‘ichimoku’ package1 coded for performance.\nFor benchmarking, the ‘microbenchmark’ package will be used. It is usual to compare the median times averaged over a large number of runs, and we will use 10,000 in the cases below.\nMatrix conversion benchmarking\nA 100x10 matrix of random data drawn from the normal distribution is created as the object ‘matrix’.\nThis will be converted into a dataframe using as.data.frame() and ichimoku::matrix_df().\n\n\nlibrary(ichimoku)\nlibrary(microbenchmark)\n\nmatrix <- matrix(rnorm(1000), ncol = 10, dimnames = list(1:100, letters[1:10]))\n\ndim(matrix)\n\n\n[1] 100  10\n\nhead(matrix)\n\n\n           a          b           c           d           e\n1 -0.2564852  0.7065331 -1.73133951  0.05643682  0.52054933\n2  0.9036232  1.6269398 -0.07857159 -1.57186551 -0.08464559\n3  0.8849394 -0.3802827  0.03348258 -1.07886340 -0.26355599\n4 -0.2841184 -1.0277239  1.52750383  0.08231787 -0.56077348\n5  0.3104276 -1.3066767 -0.81179648  0.21132226  1.10502326\n6 -1.2867371  0.8099163  0.09008239  0.05038630  2.47439035\n             f           g           h          i          j\n1  0.484407401  0.23559747 -0.24583719 -0.3275139  0.6017835\n2 -0.209997322 -1.24024709 -1.45803294  0.4938343  1.9149495\n3  0.006305845 -0.86170345 -0.06429787 -0.7433562  0.1498485\n4  0.347062188 -0.02291366 -0.09300306 -1.4511336  0.1043861\n5  1.632073100  1.33351170 -0.80941778 -0.3703048 -1.0557398\n6  1.326092683 -0.42321475 -0.88635606 -0.3311546 -0.3282137\n\nmicrobenchmark(as.data.frame(matrix), matrix_df(matrix), times = 10000)\n\n\nUnit: microseconds\n                  expr    min     lq     mean  median      uq\n as.data.frame(matrix) 30.828 32.635 40.90986 33.7885 36.6595\n     matrix_df(matrix)  8.102  8.903 10.89592  9.3485 10.1190\n      max neval\n 11598.99 10000\n 10479.24 10000\n\nidentical(as.data.frame(matrix), matrix_df(matrix))\n\n\n[1] TRUE\n\nAs can be seen, the outputs are identical, but ichimoku::matrix_df(), which is designed to be a performant ‘data.frame’ constructor, is over 3x as fast.\nxts conversion benchmarking\nThe ‘xts’ format is a popular choice for large time series data as each observation is indexed by a unique valid timestamp.\nAs an example, we use the ichimoku() function from the ‘ichimoku’ package which creates ichimoku objects inheriting the ‘xts’ class. We run ichimoku() on the sample data contained within the package to create an ‘xts’ object ‘cloud’.\nThis will be converted into a dataframe using as.data.frame() and ichimoku::xts_df().\n\n\nlibrary(ichimoku)\nlibrary(microbenchmark)\n\ncloud <- ichimoku(sample_ohlc_data)\n\nxts::is.xts(cloud)\n\n\n[1] TRUE\n\ndim(cloud)\n\n\n[1] 281  12\n\nprint(cloud[1:6], plot = FALSE)\n\n\n            open  high   low close cd tenkan kijun senkouA senkouB\n2020-01-02 123.0 123.1 122.5 122.7 -1     NA    NA      NA      NA\n2020-01-03 122.7 122.8 122.6 122.8  1     NA    NA      NA      NA\n2020-01-06 122.8 123.4 122.4 123.3  1     NA    NA      NA      NA\n2020-01-07 123.3 124.3 123.3 124.1  1     NA    NA      NA      NA\n2020-01-08 124.1 124.8 124.0 124.8  1     NA    NA      NA      NA\n2020-01-09 124.8 125.4 124.5 125.3  1     NA    NA      NA      NA\n           chikou cloudT cloudB\n2020-01-02  122.8     NA     NA\n2020-01-03  122.9     NA     NA\n2020-01-06  123.0     NA     NA\n2020-01-07  123.9     NA     NA\n2020-01-08  123.6     NA     NA\n2020-01-09  122.5     NA     NA\n\nmicrobenchmark(as.data.frame(cloud), xts_df(cloud), times = 10000)\n\n\nUnit: microseconds\n                 expr     min      lq      mean  median      uq\n as.data.frame(cloud) 230.137 237.105 262.46329 240.932 249.302\n        xts_df(cloud)  24.468  27.592  34.79507  28.971  30.801\n       max neval\n 54374.991 10000\n  6955.761 10000\n\nIt can be seen that ichimoku::xts_df(), which is designed to be a performant ‘data.frame’ constructor, is over 8x as fast.\n\n\ndf1 <- as.data.frame(cloud)\n\nis.data.frame(df1)\n\n\n[1] TRUE\n\nstr(df1)\n\n\n'data.frame':   281 obs. of  12 variables:\n $ open   : num  123 123 123 123 124 ...\n $ high   : num  123 123 123 124 125 ...\n $ low    : num  122 123 122 123 124 ...\n $ close  : num  123 123 123 124 125 ...\n $ cd     : num  -1 1 1 1 1 1 -1 0 -1 -1 ...\n $ tenkan : num  NA NA NA NA NA ...\n $ kijun  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ senkouA: num  NA NA NA NA NA NA NA NA NA NA ...\n $ senkouB: num  NA NA NA NA NA NA NA NA NA NA ...\n $ chikou : num  123 123 123 124 124 ...\n $ cloudT : num  NA NA NA NA NA NA NA NA NA NA ...\n $ cloudB : num  NA NA NA NA NA NA NA NA NA NA ...\n\ndf2 <- xts_df(cloud)\n\nis.data.frame(df2)\n\n\n[1] TRUE\n\nstr(df2)\n\n\n'data.frame':   281 obs. of  13 variables:\n $ index  : POSIXct, format: \"2020-01-02\" ...\n $ open   : num  123 123 123 123 124 ...\n $ high   : num  123 123 123 124 125 ...\n $ low    : num  122 123 122 123 124 ...\n $ close  : num  123 123 123 124 125 ...\n $ cd     : num  -1 1 1 1 1 1 -1 0 -1 -1 ...\n $ tenkan : num  NA NA NA NA NA ...\n $ kijun  : num  NA NA NA NA NA NA NA NA NA NA ...\n $ senkouA: num  NA NA NA NA NA NA NA NA NA NA ...\n $ senkouB: num  NA NA NA NA NA NA NA NA NA NA ...\n $ chikou : num  123 123 123 124 124 ...\n $ cloudT : num  NA NA NA NA NA NA NA NA NA NA ...\n $ cloudB : num  NA NA NA NA NA NA NA NA NA NA ...\n\nThe outputs are slightly different as xts_df() preserves the date-time index of ‘xts’ objects as a new first column ‘index’ which is POSIXct in format. The default as.data.frame() constructor converts the index into the row names, which is not desirable as the dates are coerced to type ‘character’.\nSo it can be seen that in this case, not only is the performant constructor faster, it is also more fit for purpose.\nWhen to use performant constructors\nData which is not already a ‘data.frame’ object being plotted using ‘ggplot2’. For example if you have time series data in the ‘xts’ format, calling a ‘ggplot2’ plot method automatically converts the data into a dataframe behind the scenes as ggplot() only works with dataframes internally. Fortunately it does not use as.data.frame() but its own constructor ggplot2::fortify(). Benchmarked below, it is slightly faster than as.data.frame() but the performant constructor ichimoku::xts_df() is still around 5x as fast.\n\n\nmicrobenchmark(as.data.frame(cloud), ggplot2::fortify(cloud), xts_df(cloud), times = 10000)\n\n\nUnit: microseconds\n                    expr     min       lq      mean   median       uq\n    as.data.frame(cloud) 232.363 243.0635 266.82726 248.3045 255.3375\n ggplot2::fortify(cloud) 130.024 147.1080 165.09396 154.7440 164.6180\n           xts_df(cloud)  25.169  29.0380  35.60568  30.7110  32.4305\n      max neval\n 6013.988 10000\n 6050.913 10000\n 7530.210 10000\n\nIn a context where performance is critical. This is usually in interactive environments such as a Shiny app, perhaps with real time data where slow code can reduce responsiveness or cause bottlenecks in execution.\nWithin packages. It is usually safe to use performant constructors within functions or for internal unexported functions. If following programming best practices the input and output types for functions are kept consistent, and so the input to the constructor can be controlled and hence its function predictable. Setting appropriate unit tests can also catch any issues early.\nWhen to question the use of performant constructors\nFor user-facing functions. Having no validation or error-checking code means that a performant constructor may behave unpredictably on data that is not intended to be an input. Within a function, there is a specific or at most finite range of objects that a constructor can receive. When that limit is removed, if the input is not the intended input for a constructor then an error can be expected. As long as this is made clear to the user and there are adequate instructions on proper usage, in an environment where the occasional error message is acceptable, then the performant constructor can still be used.\nWhen the constructor needs to handle a range of input types. as.data.frame() is actually an S3 generic with a variety of methods for different object classes. If required to handle a variety of different types of input, it may be easier (if not more performant) to rely on as.data.frame() rather than write code which handles different scenarios.\nWhat is a performant constructor\nFirst of all, it is possible to directly use the functions matrix_df() and xts_df() which are exported from the ‘ichimoku’ package.\nWhat lies behind those functions? Some variation on the below:\n\n\n# The stucture underlying a data frame is simply a list\ndf <- list(vec1, vec2, vec3)\n\n# Set the following attributes to turn the list into a data frame:\nattributes(df) <- list(names = c(\"vec1\", \"vec2\", \"vec3\"),\n                       class = \"data.frame\",\n                       row.names = .set_row_names(length(vec1)))\n\n\n\nA data.frame is simply a list (where each element must be the same length).\nIt has an attribute ‘class’ which equals ‘data.frame’.\nIt must have row names, which can be set by the base R internal function .set_row_names() which takes a single argument, the number of rows.\nNote:\nThe vectors in the list (vec1, vec2, vec3, etc.) must be the same length, otherwise a corrupt data.frame warning will be generated.\nIf row names are missing then the data will still be present but dim() will show a 0-row dataframe and its print method will not work.\n.set_row_names() sets row names efficiently using a compact internal notation used by R. They can also be assigned an integer sequence, or a series of dates for example. However if not an integer vector, they are first coerced to type ‘character’.\nIn conclusion, dataframes are not complicated structures but internally represented by lists with a couple of enforced constraints.\n\n\nclass(df1)\n\n\n[1] \"data.frame\"\n\ntypeof(df1)\n\n\n[1] \"list\"\n\nFurther information\nDocumentation for the performant constructors discussed: https://shikokuchuo.net/ichimoku/articles/utilities.html#performant-dataframe-constructors.\n\nGao, C. (2021), ichimoku: Visualization and Tools for Ichimoku Kinko Hyo Strategies. R package version 1.2.1, https://CRAN.R-project.org/package=ichimoku.↩︎\n",
    "preview": "posts/11-dataframes/dataframes_files/figure-html5/index-1.png",
    "last_modified": "2021-09-25T10:27:47+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/10-combinations/",
    "title": "Efficient R: Combinations using expand.grid",
    "description": "A faster way to generate combinations for mapply and vapply",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-06-17",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nIntroduction\nexpand.grid\nichimoku::grid_dup\nBenchmarking the results\nUse case: mapply() and vapply()\n\n\n\n                                                            sha256\n1 96e41b3b0fa827b7c9c1f4a7765667064026f9448a78327415264112f7f54dbe\n\n\nShikokuchuo\nIntroduction\nIt seems that there is no base R function to generate exhaustive combinations of two identical vectors, sometimes desired as function inputs to mapply/vapply(). The combn() function from the ‘utils’ package is required.\nutils::combn() outputs the unique set of combinations, so for the example below where the first 8 letters of the alphabet are used, the combination {a, b} appears, but {b, a} does not. Similarly the cases where the two elements are identical such as {a, a} also do not feature. It can be seen that there are 28 (or 8 choose 2) unique combinations for the vector of length 8.\n\n\nx <- letters[1:8]\nxlen <- length(x)\n\ncombn <- utils::combn(x, 2)\ncombn\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n[1,] \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"b\"  \"b\"  \"b\"   \"b\"   \"b\"  \n[2,] \"b\"  \"c\"  \"d\"  \"e\"  \"f\"  \"g\"  \"h\"  \"c\"  \"d\"  \"e\"   \"f\"   \"g\"  \n     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\n[1,] \"b\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"d\"   \"d\"   \"d\"   \"d\"  \n[2,] \"h\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"e\"   \"f\"   \"g\"   \"h\"  \n     [,23] [,24] [,25] [,26] [,27] [,28]\n[1,] \"e\"   \"e\"   \"e\"   \"f\"   \"f\"   \"g\"  \n[2,] \"f\"   \"g\"   \"h\"   \"g\"   \"h\"   \"h\"  \n\nexpand.grid\nexpand.grid() from the base package is a useful function in its own right, most well-known perhaps for its use in generating hyperparameter tuning grids in machine learning models.\nexpand.grid() produces a data frame in columns rather than a matrix in rows like utils::combn(). Hence just for demonstration purposes to compare like-for-like, a bit of manipulation is done below to make the output exactly the same. In real world usage the output of expand.grid() can be used ‘as is’ without the additional manipulation.\n\n\ngrid <- expand.grid(x, x, KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE)\ngrid <- t(as.matrix(grid))\ngrid <- rbind(grid[2,], grid[1,])\nrownames(grid) <- NULL\ngrid\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n[1,] \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"b\"  \"b\"   \"b\"   \"b\"  \n[2,] \"a\"  \"b\"  \"c\"  \"d\"  \"e\"  \"f\"  \"g\"  \"h\"  \"a\"  \"b\"   \"c\"   \"d\"  \n     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\n[1,] \"b\"   \"b\"   \"b\"   \"b\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"  \n[2,] \"e\"   \"f\"   \"g\"   \"h\"   \"a\"   \"b\"   \"c\"   \"d\"   \"e\"   \"f\"  \n     [,23] [,24] [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32]\n[1,] \"c\"   \"c\"   \"d\"   \"d\"   \"d\"   \"d\"   \"d\"   \"d\"   \"d\"   \"d\"  \n[2,] \"g\"   \"h\"   \"a\"   \"b\"   \"c\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"  \n     [,33] [,34] [,35] [,36] [,37] [,38] [,39] [,40] [,41] [,42]\n[1,] \"e\"   \"e\"   \"e\"   \"e\"   \"e\"   \"e\"   \"e\"   \"e\"   \"f\"   \"f\"  \n[2,] \"a\"   \"b\"   \"c\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"a\"   \"b\"  \n     [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] [,51] [,52]\n[1,] \"f\"   \"f\"   \"f\"   \"f\"   \"f\"   \"f\"   \"g\"   \"g\"   \"g\"   \"g\"  \n[2,] \"c\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"a\"   \"b\"   \"c\"   \"d\"  \n     [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62]\n[1,] \"g\"   \"g\"   \"g\"   \"g\"   \"h\"   \"h\"   \"h\"   \"h\"   \"h\"   \"h\"  \n[2,] \"e\"   \"f\"   \"g\"   \"h\"   \"a\"   \"b\"   \"c\"   \"d\"   \"e\"   \"f\"  \n     [,63] [,64]\n[1,] \"h\"   \"h\"  \n[2,] \"g\"   \"h\"  \n\nIt can be seen that the output of expand.grid() is simply all combinations, of which there are 8^2 = 64 in total.\nichimoku::grid_dup\nSo how to get from the output of expand.grid() to that of utils::combn()? Well, with the help of a simple algorithm, which has been coded into the grid_dup() function from the ‘ichimoku’ package.1\nFrom the function documentation: ‘create a vector of element positions of duplicates in the output of expand.grid on 2 identical vectors’.\nUsing the function as per the below, ‘grid1’ contains all unique combinations and also those where the two elements are identical. This is sometimes the desired output if two of the same elements is still considered a unique combination, and simply that the order of appearance does not matter.\n\n\nlibrary(ichimoku)\n\ngrid1 <- grid[, -grid_dup(xlen)]\ngrid1\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n[1,] \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"b\"  \"b\"   \"b\"   \"b\"  \n[2,] \"a\"  \"b\"  \"c\"  \"d\"  \"e\"  \"f\"  \"g\"  \"h\"  \"b\"  \"c\"   \"d\"   \"e\"  \n     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\n[1,] \"b\"   \"b\"   \"b\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"d\"  \n[2,] \"f\"   \"g\"   \"h\"   \"c\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"d\"  \n     [,23] [,24] [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32]\n[1,] \"d\"   \"d\"   \"d\"   \"d\"   \"e\"   \"e\"   \"e\"   \"e\"   \"f\"   \"f\"  \n[2,] \"e\"   \"f\"   \"g\"   \"h\"   \"e\"   \"f\"   \"g\"   \"h\"   \"f\"   \"g\"  \n     [,33] [,34] [,35] [,36]\n[1,] \"f\"   \"g\"   \"g\"   \"h\"  \n[2,] \"h\"   \"g\"   \"h\"   \"h\"  \n\nIf the ‘omit.id = TRUE’ argument is set for grid_dup(), identical elements are also removed. ‘grid2’ should then be the same as ‘combn’ obtained above.\nIndeed it can be seen that both identical() and all.equal() below return TRUE.\n\n\ngrid2 <- grid[, -grid_dup(xlen, omit.id = TRUE)]\ngrid2\n\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n[1,] \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"a\"  \"b\"  \"b\"  \"b\"   \"b\"   \"b\"  \n[2,] \"b\"  \"c\"  \"d\"  \"e\"  \"f\"  \"g\"  \"h\"  \"c\"  \"d\"  \"e\"   \"f\"   \"g\"  \n     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]\n[1,] \"b\"   \"c\"   \"c\"   \"c\"   \"c\"   \"c\"   \"d\"   \"d\"   \"d\"   \"d\"  \n[2,] \"h\"   \"d\"   \"e\"   \"f\"   \"g\"   \"h\"   \"e\"   \"f\"   \"g\"   \"h\"  \n     [,23] [,24] [,25] [,26] [,27] [,28]\n[1,] \"e\"   \"e\"   \"e\"   \"f\"   \"f\"   \"g\"  \n[2,] \"f\"   \"g\"   \"h\"   \"g\"   \"h\"   \"h\"  \n\nidentical(combn, grid2) && all.equal(combn, grid2)\n\n\n[1] TRUE\n\nBenchmarking the results\n‘Microbenchmark’ can be used to benchmark the performance, where it is usual practice to compare median values.\nFor small vector lengths, expand.grid() is not as performant. However the absolute times are also small so any difference would not matter as much. When the vector length reaches 13, the custom algorithm using expand.grid()/grid_dup() starts to outperform.\nBy the time the vector length reaches 1,000, this implies total unique combinations of 499,500 and the custom algorithm is already over 7x faster.\nIt should be noted that the custom algorithm is tailored for the special case of combn(x, m) where m = 2 and this is the reason why there can be such an outperformance. In programming, where the implementation has already been tuned to be the most efficient possible, it can be useful to think whether the algorithm or code logic can be adapted for the case required.\n\n\nfn_combn <- function(x) {\n  utils::combn(x, 2)\n}\n\nfn_grid <- function(x) {\n  expand.grid(x, x, KEEP.OUT.ATTRS = FALSE,\n              stringsAsFactors = FALSE)[-grid_dup(length(x), omit.id = TRUE), ]\n}\n\nmicrobenchmark::microbenchmark(fn_combn(1:13), fn_grid(1:13))\n\n\nUnit: microseconds\n           expr    min      lq     mean median      uq      max neval\n fn_combn(1:13) 38.659 41.2165 55.68889 43.143 45.6180 1087.231   100\n  fn_grid(1:13) 36.384 39.0440 62.25098 41.099 43.8595 1836.859   100\n\nmicrobenchmark::microbenchmark(fn_combn(1:1000), fn_grid(1:1000))\n\n\nUnit: milliseconds\n             expr       min        lq     mean    median        uq\n fn_combn(1:1000) 211.81676 271.15583 275.6196 273.43943 275.25424\n  fn_grid(1:1000)  29.13142  36.05212  42.0961  37.19412  40.05095\n      max neval\n 332.7417   100\n 100.0834   100\n\nUse case: mapply() and vapply()\nThis type of output is suitable for feeding into functions such as mapply() or vapply().\nA standard use for mapply is when multiple arguments have to be mapped into a function. Here ‘simplify = FALSE’ is set to have mapply return a list, and fed into do.call() with c() to create a vector. This is a safer and more performant method to create a vector than relying on the built-in simplification.\n\n\ndo.call(c, mapply(function(x, y) paste0(x, \"&\", y), \n                  grid2[1, ], grid2[2, ],\n                  SIMPLIFY = FALSE, USE.NAMES = FALSE))\n\n\n [1] \"a&b\" \"a&c\" \"a&d\" \"a&e\" \"a&f\" \"a&g\" \"a&h\" \"b&c\" \"b&d\" \"b&e\" \"b&f\"\n[12] \"b&g\" \"b&h\" \"c&d\" \"c&e\" \"c&f\" \"c&g\" \"c&h\" \"d&e\" \"d&f\" \"d&g\" \"d&h\"\n[23] \"e&f\" \"e&g\" \"e&h\" \"f&g\" \"f&h\" \"g&h\"\n\nAn equivalent example using vapply() is given below. vapply() is also a safe choice for programming as an output template is explicitly specified, here ‘character(1L)’, hence the returned values are all expected to be of type ‘character’ of length ‘1’ otherwise an error is thrown.\n\n\nvapply(seq_along(grid2[1L, ]),\n       function(i) paste0(grid2[1L, i], \"&\", grid2[2L, i]),\n       character(1L), USE.NAMES = FALSE)\n\n\n [1] \"a&b\" \"a&c\" \"a&d\" \"a&e\" \"a&f\" \"a&g\" \"a&h\" \"b&c\" \"b&d\" \"b&e\" \"b&f\"\n[12] \"b&g\" \"b&h\" \"c&d\" \"c&e\" \"c&f\" \"c&g\" \"c&h\" \"d&e\" \"d&f\" \"d&g\" \"d&h\"\n[23] \"e&f\" \"e&g\" \"e&h\" \"f&g\" \"f&h\" \"g&h\"\n\nOf the two however, mapply() is marginally faster and should normally be used when iteration is required over multiple arguments.\n\nGao, C. (2021), ichimoku: Visualization and Tools for Ichimoku Kinko Hyo Strategies. R package version 1.2.1, https://CRAN.R-project.org/package=ichimoku.↩︎\n",
    "preview": "posts/10-combinations/combinations_files/figure-html5/index-1.png",
    "last_modified": "2021-09-24T13:11:28+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/09-docall-lapply/",
    "title": "Efficient R: do.call / lapply",
    "description": "A distinctive coding style",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-28",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nUse case\nSetup\nLoop\ndo.call / lapply\nTidy data output\n\n\n\n                                                            sha256\n1 2074954df14cc65b017b3e9d4b291353151672d450f2b623acc2a5d253767e42\n\n\nShikokuchuo\nUse case\nThe use of the do.call / lapply() combination is a powerful way to leverage functional programming in R. In short, you write a function that performs some actions and apply it to a list of inputs, which can then be fed into a function that combines everything into a single object.\nLet us take an example, where we would like to calculate the ichimoku clouds for a selection of the major world stock indices, but also preserve the volume data, all in one tidy object.\nWe use the ‘ichimoku’ package1 which not only draws the ichimoku clouds, but also provides an interface to the OANDA fxTrade API which is a rich source of high-quality financial data (free but requires registration).\nSetup\nWe could set it up as per the below:\ntickers: a vector defining the stock symbols in our portfolio\nprocess(): a function that generates a row in a data frame or matrix\n\n\nlibrary(ichimoku)\n\ntickers <- c(\"DE30_EUR\", \"JP225_USD\", \"SPX500_USD\", \"UK100_GBP\")\n\nprocess <- function(x, from, to) {\n  # Use ichimoku::oanda() to retrieve data from the OANDA fxTrade API\n  pxdata <- oanda(x, from = from, to = to)\n  # Extract volume column\n  volume <- pxdata$volume\n  # Calculate the cloud by calling ichimoku::ichimoku()\n  cloud <- ichimoku(pxdata, ticker = x)\n  # Return a list of ticker, ichimoku cloud object, volume data\n  list(x, cloud, volume)\n}\n\n\n\n\nNote: the original pricing data is preserved within the ichimoku object.\nWe now want to apply our function to each element of ‘tickers’ in turn, and then for the results to be combined.\nLoop\nOne way to achieve this would be to iterate over ‘tickers’ using a loop:\n\n\n# Define a list to contain the loop output, specifying the length in advance as good practice\nportfolio <- vector(mode = \"list\", length = length(tickers))\n\n# Loop over each element in 'tickers' and save in pre-defined list\nfor (i in seq_along(tickers)) {\n  portfolio[[i]] <- process(tickers[i], from = \"2015-09-03\", to = \"2016-06-30\")\n}\n\n# Create output matrix by calling rbind on each element of the list\nportfolio <- do.call(rbind, portfolio)\n\nportfolio\n\n\n     [,1]         [,2]          [,3]       \n[1,] \"DE30_EUR\"   ichimoku,2808 integer,209\n[2,] \"JP225_USD\"  ichimoku,2856 integer,213\n[3,] \"SPX500_USD\" ichimoku,2856 integer,213\n[4,] \"UK100_GBP\"  ichimoku,2808 integer,209\n\nThis approach takes 3-4 lines of code.\nFurthermore, ‘i’ remains as a leftover object in the global environment.\nSomewhat messy.\ndo.call / lapply\nInstead we can use a do.call / lapply() combination to achieve the same result in one line:\n\n\nportfolio <- do.call(rbind, lapply(tickers, process, from = \"2015-09-03\", to = \"2016-06-30\"))\n\nportfolio\n\n\n     [,1]         [,2]          [,3]       \n[1,] \"DE30_EUR\"   ichimoku,2808 integer,209\n[2,] \"JP225_USD\"  ichimoku,2856 integer,213\n[3,] \"SPX500_USD\" ichimoku,2856 integer,213\n[4,] \"UK100_GBP\"  ichimoku,2808 integer,209\n\nThere are also no intermediate objects generated that clutter the global environment.\nTo explain:\nFirst lapply() applies to a list or list-like object (‘tickers’), a function (‘process’). The arguments to the function are supplied immediately afterwards. lapply always returns a list.\nThis can then be fed into do.call(), which calls a function (‘rbind’) on a list of arguments (the output of ‘lapply’, which is a list). This creates a matrix.\nThe use of do.call / lapply() provides for a far more succinct and distinctive coding style.\nThe added bonus is that of the ‘apply’ family of functions, lapply() is almost always the fastest and most performant as the output type is fixed and it does not try to do things with names or simplify the output structure.\nFor a more structured format rather than a list, lapply() can be fed into a do.call() with:\nc() to form a vector\ncbind() or rbind() to form a matrix\nThe use of this type of combination is of particular benefit in programming where both performance and predictability of output types is paramount.\nTidy data output\n\n\nportfolio\n\n\n     [,1]         [,2]          [,3]       \n[1,] \"DE30_EUR\"   ichimoku,2808 integer,209\n[2,] \"JP225_USD\"  ichimoku,2856 integer,213\n[3,] \"SPX500_USD\" ichimoku,2856 integer,213\n[4,] \"UK100_GBP\"  ichimoku,2808 integer,209\n\n‘portfolio’ is a tidy matrix with a row for each ticker, and a column for each data type.\nWe can easily access any element of the matrix by specifying its index value, for example the ichimoku object for the S&P 500 Index by [3,2]. In the example below we run autostrat() on this object:\n\n\nautostrat(portfolio[3, 2][[1]], n = 1)\n\n\n                       [,1]               \nStrategy               \"cloudT > kijun\"   \n---------------------  \"----------\"       \nStrategy cuml return % 7.76               \nPer period mean ret %  0.0554             \nPeriods in market      74                 \nTotal trades           3                  \nAverage trade length   24.67              \nTrade success %        100                \nWorst trade ret %      0.81               \n---------------------  \"----------\"       \nBenchmark cuml ret %   3.7                \nPer period mean ret %  0.0269             \nPeriods in market      135                \n---------------------  \"----------\"       \nDirection              \"long\"             \nStart                  2015-12-21 22:00:00\nEnd                    2016-06-29 22:00:00\nTicker                 \"SPX500_USD\"       \n\n\nNote: Each element of the matrix is wrapped as a list so that they are of equal length. To access the underlying object, the ichimoku object in this case, we simply extract it using [[1]].\n2\n\nGao, C. (2021), ichimoku: Visualization and Tools for Ichimoku Kinko Hyo Strategies. R package version 1.0.0, https://CRAN.R-project.org/package=ichimoku.↩︎\nFurther examples: Youngju Nielsen of Sungkyunkwan University uses do.call / lapply to good effect in her course https://www.coursera.org/learn/the-fundamental-of-data-driven-investment/↩︎\n",
    "preview": "posts/09-docall-lapply/docall-lapply_files/figure-html5/index-1.png",
    "last_modified": "2021-09-24T13:07:39+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/08-ichimoku/",
    "title": "ichimoku",
    "description": "R package for Ichimoku Kinko Hyo cloud charts",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-19",
    "categories": [
      "R",
      "Quantitative Finance"
    ],
    "contents": "\n\nContents\nExample\nInstallation\nPackage site\nIchimoku Kinko Hyo \nInterpretation\nContext\n\n\n\n                                                            sha256\n1 9b787ca60956d571ad9686d55815fcff38fce9d550ccb1310c0b9c11dfa8069e\n\n\nShikokuchuo\nAn implementation in R of the Ichimoku Kinkō Hyō (一目均衡表) charting system, also commonly known as ‘cloud charts’.\nThe technique is a refinement on candlestick charting originating from Japan, now in widespread use in technical analysis worldwide. Translating to ‘one-glance equilibrium chart’, it allows the price action and market structure of financial securities to be determined ‘at-a-glance’.\nExample\nLoad package and sample data:\n\n\nlibrary(ichimoku)\nTKR <- sample_ohlc_data\n\n\n\nichimoku() to generate the ichimoku object:\n\n\ncloud <- ichimoku(TKR)\n\n\n\niplot() for fully-interactive cloud charts:\n\n\niplot(cloud)\n\n\n\n\nplot() for production-quality static cloud charts:\n\n\nplot(cloud, window = \"2020-04/\", theme = \"solarized\")\n\n\n\nplot(cloud, window = \"2020-04/\", theme = \"dark\")\n\n\n\nplot(cloud, window = \"2020-04/\", theme = \"mono\")\n\n\n\n\nInstallation\nInstall the released version of ichimoku from CRAN:\ninstall.packages(\"ichimoku\")\nOr the latest development version from rOpenSci R-universe binaries:\ninstall.packages(\"ichimoku\", repos = \"https://shikokuchuo.r-universe.dev\")\nOr the latest development version from the Github source:\ndevtools::install_github(\"shikokuchuo/ichimoku\")\nPackage site\nHosted ourselves at: https://shikokuchuo.net/ichimoku/ 1\nIchimoku Kinko Hyo 2\nThe system consists of the following chart lines added to a candlestick chart:\n転換線 Tenkan-sen [conversion line]: the mid-point of the highest high and lowest low for the past 9 periods (including the current period)\n基準線 Kijun-sen [base line]: the mid-point of the highest high and lowest low for the past 26 periods (including the current period)\n先行スパン1 Senkou span A [leading span A]: the mid-point of Tenkan-sen and Kijun-sen plotted ahead 26 periods (including the current period)\n先行スパン2 Senkou span B [leading span B]: the mid-point of the highest high and lowest low for the past 52 periods (including the current period), plotted ahead 26 periods (including the current period)\n遅行スパン Chikou span [lagging span]: the current period closing price plotted behind 26 periods (including the current period)\nThe 雲 kumo [cloud] is the area bounded by Senkou span A and Senkou span B (usually shaded on a chart).\nInterpretation\nIchimoku Kinkō Hyō can be translated as ‘one-glance equilibrium chart’. It is designed to allow the price action and market structure of financial securities to be determined ‘at-a-glance’ in a highly visual fashion.\nFor example in a strongly upwards-trending market, the candlesticks will be above the Tenkan-sen, which will be above the Kijun-sen, which will be above the cloud, and the Chikou span may not have anything above it.\nThe lines and the cloud represent dynamic support and resistance zones relative to the price candles. Generally the thicker the cloud, the tougher the support/resistance. In our previous example, if the price now reverts downwards, it can expect support first at the Kijun-sen, then the Tenkan-sen and finally the cloud itself.\nMore subtle interpretations involve the Chikou span in particular and its action in relation to the cloud lines as well as the candles.\nContext\nIchimoku analysis is the latest refinement in candlestick charting techniques, which also originated from Japan back in the 18th century. Developed earlier in the 20th century by 一目山人 Ichimoku, Sanjin, the pen name of 細田吾一 Hosoda, Goichi, his work was finally published in 1969 as the seminal 「一目均衡表」 [ichimoku kinkou hyou]. It gained popularity especially after the publication of Sasaki’s 「一目均衡表の研究」 [ichimoku kinkouhyou no kenkyuu] in 1996, and is now widely-used in technical analysis worldwide.\nThe time periods have traditionally been calculated as 9, 26 and 52 based on manual data analysis performed in Japan in a pre-computer age where there was a 6-day working week resulting in 26 average trading days in a month. Although this bears little relevance to the current day, the use of these time periods has persisted as an ‘industry norm’ or ‘accepted practice’.\nTo use other periods would be meaningless in a sense as everyone uses these parameters and ‘market psychology’ can and often does create its own realities, independent of any fundamentals. However, there is no reason for the technique not to evolve, and to reflect changing trading realities perhaps other parameters will become more relevant in the collective psychology.\nFinally, the use originated with daily candlesticks, and the most valid interpretation remains for daily data. However, it is equally used today for both shorter intra-day, e.g. 4-hour or hourly, and longer, e.g. weekly or monthly, charts.\n\nGao, C. (2021), ichimoku: Visualization and Tools for Ichimoku Kinko Hyo Strategies. R package version 1.0.0, https://CRAN.R-project.org/package=ichimoku.↩︎\nSasaki, H. 佐々木 英信 (1996), 一目均衡表の研究 [ichimoku kinkouhyou no kenkyuu]. Tokyo, Japan: Toushi Radar.↩︎\n",
    "preview": "posts/08-ichimoku/ichimoku_files/figure-html5/index-1.png",
    "last_modified": "2021-09-24T13:04:05+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/07-learning/",
    "title": "Resources for learning",
    "description": "A curated selection of online MOOCs",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-14",
    "categories": [
      "Resources",
      "Learning"
    ],
    "contents": "\n\nContents\nCoursera Specializations\n\n\n\n                                                            sha256\n1 deebda75318682cfdc1bb7fe67d313e387a27754afc8edabf60d4fd812495dfb\n\n\nShikokuchuo  Iyo Mishima station\nCoursera Specializations\n\n\nlibrary(magrittr)\ntibble::tribble(\n  ~Institution, ~`Course or Specialization`, ~URL,\n  \"Duke University\", \"Statistics with R\", \"https://www.coursera.org/specializations/statistics\",\n  \"Duke University\", \"Entrepreneurial Finance: Strategy and Innovation\", \"https://www.coursera.org/specializations/entrepreneurial-finance\",\n  \"John Hopkins University\", \"Mastering Software Development in R\", \"https://www.coursera.org/specializations/r\",\n  \"Sung Kyun Kwan University\", \"The Fundamentals of Data Driven Investment\" ,\"https://www.coursera.org/learn/the-fundamental-of-data-driven-investment\"\n) %>%\n  dplyr::mutate(URL = purrr::map_chr(URL, ~paste0(\"<a href='\", .x, \"'>\", .x, \"<\/a>\"))) %>%\n  DT::datatable(escape = FALSE)\n\n\n\n{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\"],[\"Duke University\",\"Duke University\",\"John Hopkins University\",\"Sung Kyun Kwan University\"],[\"Statistics with R\",\"Entrepreneurial Finance: Strategy and Innovation\",\"Mastering Software Development in R\",\"The Fundamentals of Data Driven Investment\"],[\"<a href='https://www.coursera.org/specializations/statistics'>https://www.coursera.org/specializations/statistics<\\/a>\",\"<a href='https://www.coursera.org/specializations/entrepreneurial-finance'>https://www.coursera.org/specializations/entrepreneurial-finance<\\/a>\",\"<a href='https://www.coursera.org/specializations/r'>https://www.coursera.org/specializations/r<\\/a>\",\"<a href='https://www.coursera.org/learn/the-fundamental-of-data-driven-investment'>https://www.coursera.org/learn/the-fundamental-of-data-driven-investment<\\/a>\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Institution<\\/th>\\n      <th>Course or Specialization<\\/th>\\n      <th>URL<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"columnDefs\":[{\"orderable\":false,\"targets\":0}]}},\"evals\":[],\"jsHooks\":[]}\n\n\n\n",
    "preview": "posts/07-learning/learning_files/figure-html5/index-1.png",
    "last_modified": "2021-09-24T13:03:52+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/06-datasets/",
    "title": "Datasets",
    "description": "For Econometrics and Machine Learning",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-05",
    "categories": [
      "Resources",
      "Data"
    ],
    "contents": "\n\nContents\nDatasets\n\n\n\n                                                            sha256\n1 1124bc02f0f74585e8f434a918970cf6671530e263eff4f1aa330a2b54c93873\n\n\nShikokuchuo\nDatasets\n\n\nlibrary(magrittr)\ntibble::tribble(\n  ~Source, ~URL, ~Package,\n  \"Fred\", \"https://fred.stlouisfed.org/\", \"Quantmod\",\n  \"Quandl\", \"https://www.quandl.com/\", \"Quandl\",\n  \"Yahoo Finance\", \"https://finance.yahoo.com/\", \"Quantmod\",\n  \"Damodaran NYU Stern\", \"http://people.stern.nyu.edu/adamodar/New_Home_Page/datacurrent.html\", \"\",\n  \"UCI Machine Learning Repository\", \"https://archive.ics.uci.edu/ml/index.php\", \"\",\n  \"Project Gutenberg\", \"https://www.gutenberg.org/\", \"gutenbergr\"\n) %>%\n  dplyr::mutate(URL = purrr::map_chr(URL, ~paste0(\"<a href='\", .x, \"'>\", .x, \"<\/a>\"))) %>%\n  DT::datatable(escape = FALSE)\n\n\n\n{\"x\":{\"filter\":\"none\",\"vertical\":false,\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"],[\"Fred\",\"Quandl\",\"Yahoo Finance\",\"Damodaran NYU Stern\",\"UCI Machine Learning Repository\",\"Project Gutenberg\"],[\"<a href='https://fred.stlouisfed.org/'>https://fred.stlouisfed.org/<\\/a>\",\"<a href='https://www.quandl.com/'>https://www.quandl.com/<\\/a>\",\"<a href='https://finance.yahoo.com/'>https://finance.yahoo.com/<\\/a>\",\"<a href='http://people.stern.nyu.edu/adamodar/New_Home_Page/datacurrent.html'>http://people.stern.nyu.edu/adamodar/New_Home_Page/datacurrent.html<\\/a>\",\"<a href='https://archive.ics.uci.edu/ml/index.php'>https://archive.ics.uci.edu/ml/index.php<\\/a>\",\"<a href='https://www.gutenberg.org/'>https://www.gutenberg.org/<\\/a>\"],[\"Quantmod\",\"Quandl\",\"Quantmod\",\"\",\"\",\"gutenbergr\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Source<\\/th>\\n      <th>URL<\\/th>\\n      <th>Package<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"columnDefs\":[{\"orderable\":false,\"targets\":0}]}},\"evals\":[],\"jsHooks\":[]}\n\n\n\n",
    "preview": "posts/06-datasets/datasets_files/figure-html5/index-1.png",
    "last_modified": "2021-09-24T13:03:42+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/04-distill/",
    "title": "Distill for R Markdown",
    "description": "Web publishing optimised for scientific and technical communication",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-04",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nCreated using Distill\nKey advantages\nInstallation\nDistill blog hosted on Github Pages step-by-step instructions\nReferences\n\n\n\n                                                            sha256\n1 db79682f8bee39d7ed9231200fd076ebed92a4471a9f3ce611d0a5a28bb984a3\n\n\nShikokuchuo\nCreated using Distill\nThis website was created using Distill for R Markdown, a web publishing format optimised for scientific and technical communication.\nKey advantages\nR markdown to run R code (and all the possibility that brings)\nUse markdown / html interchangeably\nNo dependency on Hugo or Jekyll, so no lock-in or need to maintain those stacks\nOut-of-the-box support for mobile\nClean and attractive defaults\nMainly “just works”\nInstallation\nInstall release version of Distill from CRAN:\n\n\ninstall.packages(\"distill\")\n\n\n\nDistill blog hosted on Github Pages step-by-step instructions\nCreate a new blog at /blog of your current working directory in R:\n\n\ndistill::create_blog(dir = \"blog\", title = \"My New Blog\", gh_pages = TRUE)\n\n\n\nMake some inital changes to _site.yml. Select the ‘build’ tab in RStudio and hit ‘Build Website’. This will generate the website. Note: building the website does not generate blog posts. Each time the website is re-built, only the .Rmd files in the base directory will be automatically re-generated.\nModify the yaml front matter and content of the example blog post. Then hit ‘Knit’ in RStudio to generate the post. Note: after every change made to posts or after creating a new post, you must knit each post separately. The listings page is then automatically updated.\nCreate README.md, license.txt and CNAME if using a customm domain.\nREADME.md and license.txt are optional but usual practice. CNAME is a single line text file containing the domain name.\n\nCreate a new repository at Github.\nTo set up git and add your new repository as a remote, bring up the command line, cd to your new blog directory and:\n\ngit init\ngit add .\ngit commit -m \"initial commit\"\ngit branch -M main\ngit remote add origin git@github.com:username/nameofnew.git\ngit push -u origin main\n\n\nReplace ‘username/nameofnew.git’ as appropriate.\nAt Github, under your new repository, go to Settings >> Pages, set your source branch to ‘main’, and folder to ‘docs’. Tick ‘Enforce HTTPS’ (recommended).  If using a custom domain name, it should be configured automatically if you have previously set up your DNS settings to point to Github’s servers.\nCongratulations, your new website should now be online!\nReferences\nThe Distill Reference: https://rstudio.github.io/distill/\nThe Definitive R Markdown Guide: https://bookdown.org/yihui/rmarkdown/\n\n\n\n",
    "preview": "posts/04-distill/distill_files/figure-html5/index-1.png",
    "last_modified": "2021-09-24T13:03:10+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/05-ghactions/",
    "title": "Github Actions with R",
    "description": "Deploy and automate your code to the cloud",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-04",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nGithub Actions with R\nReference\n\n\n\n                                                            sha256\n1 6f5b37d9b73dcd70f3c8b68eabbe00c4a709f2a3e694d964121af145105f1655\n\n\nShikokuchuo\nGithub Actions with R\nSet up a cron job to run your R scripts at specified times.\nEnabled with a simple yaml configuration file.\nSave the following as main.yml in .github/workflows of your Github repository:\n\nname: Action\non:\n  schedule:\n    - cron: '30 22 * * 1-5'\njobs:\n  render:\n    runs-on: windows-latest\n    steps:\n      - uses: actions/checkout@v2\n      - name: Set up R\n        uses: r-lib/actions/setup-r@v1\n      - name: Install dependencies\n        run: |\n          install.packages(c(\"magrittr\", \"purrr\"), type = \"win.binary\")\n        shell: Rscript {0}\n      - name: Script\n        run: Rscript nameofscript.R\n      - name: Commit files\n        run: |\n          git config --local user.name github-actions\n          git config --local user.email \"actions@github.com\"\n          git add docs/*\n          git commit -am \"commit on $(date)\"\n          git push origin main\n        env:\n          REPO_KEY: ${{secrets.GITHUB_TOKEN}}\n          username: github-actions\n\nThis example cron job runs every Mon-Fri at 22.30.\nCustomize your R packages to install.\nMake sure to change nameofscript.R to your actual script name.\nAssumes your script writes files to the ‘docs’ directory, change if necessary.\nAssumes your repository branch is ‘main’, change if necessary.\nNote that this script is run on a Windows VM using Windows R binary packages. This is currently much faster than building a lot of dependencies on Linux (which is also prone to failure).\nTo generate R Markdown documents (or for that matter render a Distill website), you will want to add the following step after ‘Set up R’:\n\n      - name: Set up Pandoc\n        uses: r-lib/actions/setup-pandoc@v1\n\nReference\nThe Github Actions with R reference: https://orchid00.github.io/actions_sandbox/\n\n\n\n",
    "preview": "posts/05-ghactions/ghactions_files/figure-html5/index-1.png",
    "last_modified": "2021-09-24T13:03:26+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/03-rselenium/",
    "title": "R | Selenium",
    "description": "Programmatically drive a web browser",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-03",
    "categories": [
      "R"
    ],
    "contents": "\n\nContents\nUse case\nInitial setup\nRunning Selenium Webdriver\nRSelenium quickstart code\nReference\n\n\n\n                                                            sha256\n1 809e2e2a3967742faea6f9e11e0a4c533511f9710ac41812dcbcae3c78913cac\n\n\nShikokuchuo\nUse case\nWhenever you need to programmatically drive a web browser.\nMost often:\nto scrape information behind a login screen\nwhen the http server does not return a simple html document\nInitial setup\nPrerequisites: JRE or JDK installed on your system, Mozilla Firefox\nInstall the RSelenium package from CRAN:\n\n\ninstall.packages(\"RSelenium\")\n\n\n\nGo to https://selenium-release.storage.googleapis.com/index.html\nDownload selenium-server-standalone-4.0.0-alpha-2.jar (or whatever is the latest ‘selenium-server-standalone’ file)\nGo to https://github.com/mozilla/geckodriver\nDownload the latest Mozilla geckodriver release, and place in same directory as the jar file\nRunning Selenium Webdriver\nAt the terminal, first cd to the directory where your two new files are saved, then run:\n\njava -jar selenium-server-standalone-4.0.0-alpha-2.jar\n\nThe selenium server must be up and running before attempting to execute the R code below.\nRSelenium quickstart code\n\n\nlibrary(RSelenium)\nlibrary(keyring)\nlibrary(rvest)\nlibrary(magrittr)\n\n# Start Selenium Session\nremDr <- remoteDriver(\n  remoteServerAddr = \"localhost\",\n  port = 4444L,\n  browserName = \"firefox\"\n)\n\nremDr$open()\n\n# Navigate to login page\nremDr$navigate(\"https://website.com/login\")\nSys.sleep(5) # Give page time to load\n\n# Find 'username' element and send 'saved_user' as input\nwebElem1 <- remDr$findElement(using = \"xpath\", \"//input[@name = 'username']\")\nwebElem1$sendKeysToElement(list(key_get(\"saved_user\")))\n\n# Find 'password' element and send 'saved_pass' and 'enter' keystroke as input\nwebElem2 <- remDr$findElement(using = \"xpath\", \"//input[@name = 'password']\")\nwebElem2$sendKeysToElement(list(key_get(\"saved_pass\"), key = \"enter\"))\nSys.sleep(5) # Give page time to load\n\n# Navigate to desired page and download source\nremDr$navigate(\"https://website.com/somepage\")\nSys.sleep(5) # Give page time to load\nhtml <- remDr$getPageSource()[[1]] %>% read_html()\n\n# Use further rvest commands to extract required data\n# ...\n\n# End Selenium Session\nremDr$close()\n\n\n\nCustomise the URLs as required.\nCustomise the xpath to locate the desired input fields as they are actually named on your site.\n‘saved_user’ and ‘saved_pass’ are values already stored using the keyring package and retrieved here using the ‘key_get’ command. It is never a good idea to store plain text credentials in an R script.\nReference\nBasic vignette: https://docs.ropensci.org/RSelenium/articles/basics.html\n\n\n\n",
    "preview": "posts/03-rselenium/rselenium_files/figure-html5/index-1.png",
    "last_modified": "2021-09-24T13:02:55+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/02-resources/",
    "title": "Resources for global sustainability",
    "description": "A compendium",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-02",
    "categories": [
      "Resources",
      "Sustainability"
    ],
    "contents": "\n\nContents\nStockholm Resilience Center\nSvalbard Global Seed Vault\nThe National Academies of Sciences, Engineering, and Medicine\nOpenlearn, The Open University\nTED\n\n\n\n                                                            sha256\n1 3018cd1a5f671835e3116c2e2c6f937cf335b630cecc7de5d59b4059cff16999\n\n\nDawn over Shikokuchuo\nStockholm Resilience Center\nSustainability science for biosphere stewardship, Stockholm University\nVideo: Our future in the Anthropocene biosphere\n\n\nSvalbard Global Seed Vault\nSafeguarding Seeds for the Future\nEstablished and funded by the Norwegian Ministry of Agriculture and Food.\nProvides safe, free and long-term storage of seed duplicates from all genebanks and nations participating in the global community’s joint effort to ensure the world’s future food supply.\nThe facility serves a humanitarian purpose and is part of the international system for conserving plant genetic diversity guided by the UN organisation for Food and Agriculture (FAO).\nhttps://www.seedvault.no/\nThe National Academies of Sciences, Engineering, and Medicine\nMore than 100 leading scientists including many Nobel Prize winners issued a statement following two days of scientific deliberations at the first Nobel Prize Summit, 26-28 April 2021.\nExcerpts from the statement:\n\nGlobal heating and habitat loss amount to nothing less than a vast and\nuncontrolled experiment on Earth’s life-support system.\n\nTime is running out to prevent irreversible changes.\n\nThe remaining carbon budget for a 67% probability of not exceeding 1.5°C global\nwarming will be exhausted before 2030. \n\nGlobal sustainability offers the only viable path to human safety, equity,\nhealth, and progress.\n\nHumanity is waking up late to the challenges and opportunities of active\nplanetary stewardship. But we *are* waking up.\n\nFull text: https://www.nationalacademies.org/news/2021/04/nobel-prize-laureates-and-other-experts-issue-urgent-call-for-action-after-our-planet-our-future-summit\nOpenlearn, The Open University\nGreta Thunberg: A Year to change the World\nEncounters with some of the world’s leading scientists and economists allow the series to examine what the latest science tells us about what can be done to avert the worst effects of climate change.\nhttps://www.open.edu/openlearn/tv-radio-events/tv/greta-thunberg-year-change-the-world\nTED\nStephen Hawking\nQuestioning the universe  TED February 2008\n\n\n\n\n\n\n\nTranscript: 09:06 | Stephen Hawking: I think it quite likely that we are the only civilization within several hundred light years; otherwise we would have heard radio waves. The alternative is that civilizations don’t last very long, but destroy themselves.\n\nKatharine Hayhoe\nThe most important thing you can do to fight climate change: talk about it  TEDWomen November 2018, also featured at useR!2021 the R conference July 2021\n\n\n\n\n\n\n\n\n\n",
    "preview": "posts/02-resources/resources_files/figure-html5/index-1.png",
    "last_modified": "2021-09-24T13:02:39+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/01-authenticating/",
    "title": "Authenticating photography using cryptographic hashing",
    "description": "A proof of concept using R",
    "author": [
      {
        "name": "shikokuchuo",
        "url": {}
      }
    ],
    "date": "2021-05-01",
    "categories": [
      "Photography",
      "Cryptography"
    ],
    "contents": "\n\nContents\nReproducible R code and authentification\nAs applied to a digital photography workflow\n\nReproducible R code and authentification\nR is an open source programming language popular amongst statisticians and data scientists. The power of the R framework is enhanced through the tens of thousands of packages contributed by the open source community that extends and enhances R. 1\nThe below code is a simple proof of concept of using cryptographic hashing as a method for authentification of original photographic files. The code simply retrieves the files in a certain folder and loads them into R using the imager 2 package and plots them, here on the page, but it could easily be another output device such as writing to jpeg or pdf. At the same time, the original file is run through a sha256 cryptographic hash from the openssl 3 package. sha256 is a one-way algorithm that takes an input and generates a hexadecimal sequence 64 long. As the input file may be arbitrarily large, it can easily be seen that the information loss in arriving at the hash precludes the possibility of going in the other direction i.e. retrieving the original data from the hash. The properties of the hashing algorithm include that small changes to the input file can result in completely different hash values. The chances of collision i.e. two different data files generating the exact same hash is vanishingly small.\n\n\nphotos <- file.path(\"_images\", list.files(\"_images\"))\ndevelop <- function(x) {\n  plot(imager::load.image(x), axes = FALSE)\n  paste0(openssl::sha256(file(x)))\n}\npar(mar = c(0, 0, 0, 0))\ndata.frame(sha256 = do.call(rbind, lapply(photos, develop)))\n\n\n\n                                                            sha256\n1 cba0450d38b74f2585868d2aa026a96de735a8f73a54889366d62bbdfdcc8661\n2 a63b055e11765cf36fa065be413b0bb5deb89d6cfba0c9feac7b9946e9c76ece\n3 f06eb35ea2bea1166e3147d30a846069fa5fd969717185d3e27821cea9257999\n4 0e6cc2bf63313153c6f3aa3206a0dc1d3eb41e6a5a570b48ea5021e437672f99\n\n\nNote: sha256 hashes are of the original files. Saving and hashing the images on this page would produce completely different hashes.\nThe output image along with the sha256 hash of the original can then be published together. The photographer is then able to freely share their work, which does not then need to be downsized, degraded or watermarked, as long as the data of the original file has undergone some form of transformation (that is not trivially reversible) to produce the output. The hash is the proof of authenticity of the original, which only the original artist possesses.\nTo prove authorship, the artist just needs to run the above function again, which would produce the same output and same hash values, and is an example of the benefits of reproducibility in writing R code.\nAs applied to a digital photography workflow\nEquivalent to the example demonstrated here, the workflow of digital photographers is often to take a RAW camera file, and perform edits using photo processing software 4, before generating an output. Software generally keeps the RAW file intact as a form of “digital negative”, but adds the edits in a layer stored separately either as a “sidecar” file or in a database etc. depending on the software. Photographers often take the output and store a best quality version as their “master”.\nOur approach would differ in treating the RAW file as the “original”, which allows a high-quality output to then be published along with the sha256 of the RAW file. The artist retains the RAW file, along with the sidecar file and software that generates the output, as proof of authorship. This works of course only where the artist can ensure reproducibility of the output, and using open source software where the edits are stored transparently in a human-readable format would afford greater confidence in such a workflow.\n\nThe largest listing of packages may be found at The Comprehensive R Archive Network: https://cloud.r-project.org/↩︎\nimager R package: https://dahtah.github.io/imager/↩︎\nopenssl R package: https://github.com/jeroen/openssl↩︎\nA popular example of such photo-editing software is the open source Darktable https://www.darktable.org/↩︎\n",
    "preview": "posts/01-authenticating/authenticating_files/figure-html5/index-1.png",
    "last_modified": "2021-09-24T13:02:29+01:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
